2025-10-30 01:27:47 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-10-30 01:27:47 INFO  SparkContext:190 - Running Spark version 4.0.1
2025-10-30 01:27:47 INFO  SparkContext:190 - OS info Windows 11, 10.0, amd64
2025-10-30 01:27:47 INFO  SparkContext:190 - Java version 22.0.2
2025-10-30 01:27:47 INFO  ResourceUtils:184 - ==============================================================
2025-10-30 01:27:47 INFO  ResourceUtils:184 - No custom resources configured for spark.driver.
2025-10-30 01:27:47 INFO  ResourceUtils:184 - ==============================================================
2025-10-30 01:27:47 INFO  SparkContext:190 - Submitted application: LocalConnection
2025-10-30 01:27:47 INFO  ResourceProfile:190 - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-10-30 01:27:47 INFO  ResourceProfile:190 - Limiting resource is cpu
2025-10-30 01:27:47 INFO  ResourceProfileManager:190 - Added ResourceProfile id: 0
2025-10-30 01:27:47 INFO  SecurityManager:190 - Changing view acls to: user
2025-10-30 01:27:47 INFO  SecurityManager:190 - Changing modify acls to: user
2025-10-30 01:27:47 INFO  SecurityManager:190 - Changing view acls groups to: user
2025-10-30 01:27:47 INFO  SecurityManager:190 - Changing modify acls groups to: user
2025-10-30 01:27:47 INFO  SecurityManager:190 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: user groups with view permissions: EMPTY; users with modify permissions: user; groups with modify permissions: EMPTY; RPC SSL disabled
2025-10-30 01:27:48 INFO  Utils:190 - Successfully started service 'sparkDriver' on port 56418.
2025-10-30 01:27:48 INFO  SparkEnv:190 - Registering MapOutputTracker
2025-10-30 01:27:48 INFO  SparkEnv:190 - Registering BlockManagerMaster
2025-10-30 01:27:48 INFO  BlockManagerMasterEndpoint:190 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-10-30 01:27:48 INFO  BlockManagerMasterEndpoint:184 - BlockManagerMasterEndpoint up
2025-10-30 01:27:48 INFO  SparkEnv:190 - Registering BlockManagerMasterHeartbeat
2025-10-30 01:27:48 INFO  DiskBlockManager:190 - Created local directory at C:\Users\user\AppData\Local\Temp\blockmgr-b282d6ee-41a1-4cb0-99c5-04944e53c8b8
2025-10-30 01:27:48 INFO  SparkEnv:190 - Registering OutputCommitCoordinator
2025-10-30 01:27:48 INFO  JettyUtils:190 - Start Jetty 0.0.0.0:4040 for SparkUI
2025-10-30 01:27:48 INFO  Server:384 - jetty-11.0.24; built: 2024-08-26T18:11:22.448Z; git: 5dfc59a691b748796f922208956bd1f2794bcd16; jvm 22.0.2+9-70
2025-10-30 01:27:48 INFO  Server:439 - Started Server@104c717b{STARTING}[11.0.24,sto=30000] @2540ms
2025-10-30 01:27:48 INFO  AbstractConnector:376 - Started ServerConnector@12af3a25{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-10-30 01:27:48 INFO  Utils:190 - Successfully started service 'SparkUI' on port 4040.
2025-10-30 01:27:48 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@6b9baa9a{/,null,AVAILABLE,@Spark}
2025-10-30 01:27:48 INFO  SparkContext:190 - Added JAR C:\Users\user\AppData\Roaming\JetBrains\DataGrip2025.2\jdbc-drivers\PostgreSQL\42.7.3\org\postgresql\postgresql\42.7.3\postgresql-42.7.3.jar at spark://127.0.0.1:56418/jars/postgresql-42.7.3.jar with timestamp 1761776867684
2025-10-30 01:27:48 INFO  SecurityManager:190 - Changing view acls to: user
2025-10-30 01:27:48 INFO  SecurityManager:190 - Changing modify acls to: user
2025-10-30 01:27:48 INFO  SecurityManager:190 - Changing view acls groups to: user
2025-10-30 01:27:48 INFO  SecurityManager:190 - Changing modify acls groups to: user
2025-10-30 01:27:48 INFO  SecurityManager:190 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: user groups with view permissions: EMPTY; users with modify permissions: user; groups with modify permissions: EMPTY; RPC SSL disabled
2025-10-30 01:27:48 INFO  Executor:190 - Starting executor ID driver on host localhost
2025-10-30 01:27:48 INFO  Executor:190 - OS info Windows 11, 10.0, amd64
2025-10-30 01:27:48 INFO  Executor:190 - Java version 22.0.2
2025-10-30 01:27:48 INFO  Executor:190 - Starting executor with user classpath (userClassPathFirst = false): ''
2025-10-30 01:27:48 INFO  Executor:190 - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@1cf8353 for default.
2025-10-30 01:27:48 INFO  Executor:190 - Fetching spark://127.0.0.1:56418/jars/postgresql-42.7.3.jar with timestamp 1761776867684
2025-10-30 01:27:48 INFO  TransportClientFactory:155 - Successfully created connection to /127.0.0.1:56418 after 28 ms (0 ms spent in bootstraps)
2025-10-30 01:27:48 INFO  Utils:190 - Fetching spark://127.0.0.1:56418/jars/postgresql-42.7.3.jar to C:\Users\user\AppData\Local\Temp\spark-87990c91-8058-4771-bb4c-7932ffae29ce\userFiles-26615544-6c09-4a61-aebb-689bd0adc5d6\fetchFileTemp9079723932538252195.tmp
2025-10-30 01:27:49 INFO  Executor:190 - Adding file:/C:/Users/user/AppData/Local/Temp/spark-87990c91-8058-4771-bb4c-7932ffae29ce/userFiles-26615544-6c09-4a61-aebb-689bd0adc5d6/postgresql-42.7.3.jar to class loader default
2025-10-30 01:27:49 INFO  Utils:190 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56423.
2025-10-30 01:27:49 INFO  NettyBlockTransferService:155 - Server created on 127.0.0.1:56423
2025-10-30 01:27:49 INFO  BlockManager:190 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-10-30 01:27:49 INFO  BlockManagerMaster:190 - Registering BlockManager BlockManagerId(driver, 127.0.0.1, 56423, None)
2025-10-30 01:27:49 INFO  BlockManagerMasterEndpoint:190 - Registering block manager 127.0.0.1:56423 with 434.4 MiB RAM, BlockManagerId(driver, 127.0.0.1, 56423, None)
2025-10-30 01:27:49 INFO  BlockManagerMaster:190 - Registered BlockManager BlockManagerId(driver, 127.0.0.1, 56423, None)
2025-10-30 01:27:49 INFO  BlockManager:190 - Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 56423, None)
2025-10-30 01:27:49 INFO  ContextHandler:1123 - Stopped o.s.j.s.ServletContextHandler@6b9baa9a{/,null,STOPPED,@Spark}
2025-10-30 01:27:49 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4c75e679{/jobs,null,AVAILABLE,@Spark}
2025-10-30 01:27:49 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@566598e8{/jobs/json,null,AVAILABLE,@Spark}
2025-10-30 01:27:49 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@49f42031{/jobs/job,null,AVAILABLE,@Spark}
2025-10-30 01:27:49 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@697945a1{/jobs/job/json,null,AVAILABLE,@Spark}
2025-10-30 01:27:49 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@217c19aa{/stages,null,AVAILABLE,@Spark}
2025-10-30 01:27:49 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@185fd86c{/stages/json,null,AVAILABLE,@Spark}
2025-10-30 01:27:49 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@1a65145c{/stages/stage,null,AVAILABLE,@Spark}
2025-10-30 01:27:49 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@1fd4ebf{/stages/stage/json,null,AVAILABLE,@Spark}
2025-10-30 01:27:49 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@47d7c74e{/stages/pool,null,AVAILABLE,@Spark}
2025-10-30 01:27:49 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@705b7fef{/stages/pool/json,null,AVAILABLE,@Spark}
2025-10-30 01:27:49 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@6bdd33ec{/stages/taskThreadDump,null,AVAILABLE,@Spark}
2025-10-30 01:27:49 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@19276de1{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
2025-10-30 01:27:49 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@42adef20{/storage,null,AVAILABLE,@Spark}
2025-10-30 01:27:49 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@14d98ed3{/storage/json,null,AVAILABLE,@Spark}
2025-10-30 01:27:49 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@16560f96{/storage/rdd,null,AVAILABLE,@Spark}
2025-10-30 01:27:49 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@65951109{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-10-30 01:27:49 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@1ed6901{/environment,null,AVAILABLE,@Spark}
2025-10-30 01:27:49 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@648c1e88{/environment/json,null,AVAILABLE,@Spark}
2025-10-30 01:27:49 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@264ca065{/executors,null,AVAILABLE,@Spark}
2025-10-30 01:27:49 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@69587b7a{/executors/json,null,AVAILABLE,@Spark}
2025-10-30 01:27:49 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@7d6c1c20{/executors/threadDump,null,AVAILABLE,@Spark}
2025-10-30 01:27:49 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@182e0984{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-10-30 01:27:49 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@3d864bea{/executors/heapHistogram,null,AVAILABLE,@Spark}
2025-10-30 01:27:49 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@5eb831ab{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2025-10-30 01:27:49 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4798ff2e{/static,null,AVAILABLE,@Spark}
2025-10-30 01:27:49 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@2d03a0ea{/,null,AVAILABLE,@Spark}
2025-10-30 01:27:49 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@5e28a579{/api,null,AVAILABLE,@Spark}
2025-10-30 01:27:49 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@35477e5d{/metrics,null,AVAILABLE,@Spark}
2025-10-30 01:27:49 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@623122d3{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-10-30 01:27:49 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@52a36fd1{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-10-30 01:27:49 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4175fce3{/metrics/json,null,AVAILABLE,@Spark}
2025-10-30 01:27:51 INFO  SharedState:190 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-10-30 01:27:51 INFO  SharedState:190 - Warehouse path is 'file:/C:/Users/user/DataGripProjects/innowise_trainee/TASKS/task_5/spark-warehouse'.
2025-10-30 01:27:51 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@b134abe{/SQL,null,AVAILABLE,@Spark}
2025-10-30 01:27:51 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@7b66283{/SQL/json,null,AVAILABLE,@Spark}
2025-10-30 01:27:51 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@5d4fec1{/SQL/execution,null,AVAILABLE,@Spark}
2025-10-30 01:27:51 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@2858fdd6{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-10-30 01:27:51 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@690d468b{/static/sql,null,AVAILABLE,@Spark}
2025-10-30 01:27:55 INFO  SparkContext:184 - Invoking stop() from shutdown hook
2025-10-30 01:27:55 INFO  SparkContext:190 - SparkContext is stopping with exitCode 0 from run at Executors.java:572.
2025-10-30 01:27:55 INFO  Server:479 - Stopped Server@104c717b{STOPPING}[11.0.24,sto=30000]
2025-10-30 01:27:55 INFO  Server:135 - Shutdown Server@104c717b{STOPPING}[11.0.24,sto=30000]
2025-10-30 01:27:55 INFO  AbstractConnector:431 - Stopped Spark@12af3a25{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-10-30 01:27:55 INFO  SparkUI:190 - Stopped Spark web UI at http://127.0.0.1:4040
2025-10-30 01:27:55 INFO  MapOutputTrackerMasterEndpoint:184 - MapOutputTrackerMasterEndpoint stopped!
2025-10-30 01:27:55 INFO  MemoryStore:190 - MemoryStore started with capacity 434.4 MiB
2025-10-30 01:27:55 INFO  MemoryStore:184 - MemoryStore cleared
2025-10-30 01:27:55 INFO  BlockManager:184 - BlockManager stopped
2025-10-30 01:27:55 INFO  BlockManagerMaster:184 - BlockManagerMaster stopped
2025-10-30 01:27:55 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:184 - OutputCommitCoordinator stopped!
2025-10-30 01:27:55 INFO  SparkContext:184 - Successfully stopped SparkContext
2025-10-30 01:27:55 INFO  ShutdownHookManager:184 - Shutdown hook called
2025-10-30 01:27:55 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-e8300920-1645-4b78-967e-a728196ca043
2025-10-30 01:27:55 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-87990c91-8058-4771-bb4c-7932ffae29ce
2025-10-30 01:27:55 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-87990c91-8058-4771-bb4c-7932ffae29ce\pyspark-d3c7a6bf-6185-415a-acdb-0cab0d109dd6
2025-10-30 13:05:20 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-10-30 13:05:21 INFO  SparkContext:190 - Running Spark version 4.0.1
2025-10-30 13:05:21 INFO  SparkContext:190 - OS info Windows 11, 10.0, amd64
2025-10-30 13:05:21 INFO  SparkContext:190 - Java version 22.0.2
2025-10-30 13:05:21 INFO  ResourceUtils:184 - ==============================================================
2025-10-30 13:05:21 INFO  ResourceUtils:184 - No custom resources configured for spark.driver.
2025-10-30 13:05:21 INFO  ResourceUtils:184 - ==============================================================
2025-10-30 13:05:21 INFO  SparkContext:190 - Submitted application: LocalConnection
2025-10-30 13:05:21 INFO  ResourceProfile:190 - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-10-30 13:05:21 INFO  ResourceProfile:190 - Limiting resource is cpu
2025-10-30 13:05:21 INFO  ResourceProfileManager:190 - Added ResourceProfile id: 0
2025-10-30 13:05:21 INFO  SecurityManager:190 - Changing view acls to: user
2025-10-30 13:05:21 INFO  SecurityManager:190 - Changing modify acls to: user
2025-10-30 13:05:21 INFO  SecurityManager:190 - Changing view acls groups to: user
2025-10-30 13:05:21 INFO  SecurityManager:190 - Changing modify acls groups to: user
2025-10-30 13:05:21 INFO  SecurityManager:190 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: user groups with view permissions: EMPTY; users with modify permissions: user; groups with modify permissions: EMPTY; RPC SSL disabled
2025-10-30 13:05:21 INFO  Utils:190 - Successfully started service 'sparkDriver' on port 52232.
2025-10-30 13:05:21 INFO  SparkEnv:190 - Registering MapOutputTracker
2025-10-30 13:05:21 INFO  SparkEnv:190 - Registering BlockManagerMaster
2025-10-30 13:05:21 INFO  BlockManagerMasterEndpoint:190 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-10-30 13:05:21 INFO  BlockManagerMasterEndpoint:184 - BlockManagerMasterEndpoint up
2025-10-30 13:05:21 INFO  SparkEnv:190 - Registering BlockManagerMasterHeartbeat
2025-10-30 13:05:21 INFO  DiskBlockManager:190 - Created local directory at C:\Users\user\AppData\Local\Temp\blockmgr-2cb6f9fe-0c79-4a5a-8759-968eb0c90164
2025-10-30 13:05:21 INFO  SparkEnv:190 - Registering OutputCommitCoordinator
2025-10-30 13:05:22 INFO  JettyUtils:190 - Start Jetty 0.0.0.0:4040 for SparkUI
2025-10-30 13:05:22 INFO  Server:384 - jetty-11.0.24; built: 2024-08-26T18:11:22.448Z; git: 5dfc59a691b748796f922208956bd1f2794bcd16; jvm 22.0.2+9-70
2025-10-30 13:05:22 INFO  Server:439 - Started Server@104c717b{STARTING}[11.0.24,sto=30000] @6115ms
2025-10-30 13:05:22 INFO  AbstractConnector:376 - Started ServerConnector@5964168{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-10-30 13:05:22 INFO  Utils:190 - Successfully started service 'SparkUI' on port 4040.
2025-10-30 13:05:22 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@6b9baa9a{/,null,AVAILABLE,@Spark}
2025-10-30 13:05:22 INFO  SparkContext:190 - Added JAR C:\Users\user\AppData\Roaming\JetBrains\DataGrip2025.2\jdbc-drivers\PostgreSQL\42.7.3\org\postgresql\postgresql\42.7.3\postgresql-42.7.3.jar at spark://127.0.0.1:52232/jars/postgresql-42.7.3.jar with timestamp 1761818721164
2025-10-30 13:05:22 INFO  SecurityManager:190 - Changing view acls to: user
2025-10-30 13:05:22 INFO  SecurityManager:190 - Changing modify acls to: user
2025-10-30 13:05:22 INFO  SecurityManager:190 - Changing view acls groups to: user
2025-10-30 13:05:22 INFO  SecurityManager:190 - Changing modify acls groups to: user
2025-10-30 13:05:22 INFO  SecurityManager:190 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: user groups with view permissions: EMPTY; users with modify permissions: user; groups with modify permissions: EMPTY; RPC SSL disabled
2025-10-30 13:05:22 INFO  Executor:190 - Starting executor ID driver on host localhost
2025-10-30 13:05:22 INFO  Executor:190 - OS info Windows 11, 10.0, amd64
2025-10-30 13:05:22 INFO  Executor:190 - Java version 22.0.2
2025-10-30 13:05:22 INFO  Executor:190 - Starting executor with user classpath (userClassPathFirst = false): ''
2025-10-30 13:05:22 INFO  Executor:190 - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@1cf8353 for default.
2025-10-30 13:05:22 INFO  Executor:190 - Fetching spark://127.0.0.1:52232/jars/postgresql-42.7.3.jar with timestamp 1761818721164
2025-10-30 13:05:22 INFO  TransportClientFactory:155 - Successfully created connection to /127.0.0.1:52232 after 37 ms (0 ms spent in bootstraps)
2025-10-30 13:05:22 INFO  Utils:190 - Fetching spark://127.0.0.1:52232/jars/postgresql-42.7.3.jar to C:\Users\user\AppData\Local\Temp\spark-fef6f8d4-8a5b-4a44-9720-8e172d67838d\userFiles-0e01fa6e-302a-4854-99fd-b752736aa0ab\fetchFileTemp9815824992832609152.tmp
2025-10-30 13:05:23 INFO  Executor:190 - Adding file:/C:/Users/user/AppData/Local/Temp/spark-fef6f8d4-8a5b-4a44-9720-8e172d67838d/userFiles-0e01fa6e-302a-4854-99fd-b752736aa0ab/postgresql-42.7.3.jar to class loader default
2025-10-30 13:05:23 INFO  Utils:190 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52237.
2025-10-30 13:05:23 INFO  NettyBlockTransferService:155 - Server created on 127.0.0.1:52237
2025-10-30 13:05:23 INFO  BlockManager:190 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-10-30 13:05:23 INFO  BlockManagerMaster:190 - Registering BlockManager BlockManagerId(driver, 127.0.0.1, 52237, None)
2025-10-30 13:05:23 INFO  BlockManagerMasterEndpoint:190 - Registering block manager 127.0.0.1:52237 with 434.4 MiB RAM, BlockManagerId(driver, 127.0.0.1, 52237, None)
2025-10-30 13:05:23 INFO  BlockManagerMaster:190 - Registered BlockManager BlockManagerId(driver, 127.0.0.1, 52237, None)
2025-10-30 13:05:23 INFO  BlockManager:190 - Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 52237, None)
2025-10-30 13:05:23 INFO  ContextHandler:1123 - Stopped o.s.j.s.ServletContextHandler@6b9baa9a{/,null,STOPPED,@Spark}
2025-10-30 13:05:23 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4c75e679{/jobs,null,AVAILABLE,@Spark}
2025-10-30 13:05:23 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@566598e8{/jobs/json,null,AVAILABLE,@Spark}
2025-10-30 13:05:23 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@49f42031{/jobs/job,null,AVAILABLE,@Spark}
2025-10-30 13:05:23 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@697945a1{/jobs/job/json,null,AVAILABLE,@Spark}
2025-10-30 13:05:23 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@217c19aa{/stages,null,AVAILABLE,@Spark}
2025-10-30 13:05:23 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@185fd86c{/stages/json,null,AVAILABLE,@Spark}
2025-10-30 13:05:23 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@1a65145c{/stages/stage,null,AVAILABLE,@Spark}
2025-10-30 13:05:23 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@1fd4ebf{/stages/stage/json,null,AVAILABLE,@Spark}
2025-10-30 13:05:23 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@47d7c74e{/stages/pool,null,AVAILABLE,@Spark}
2025-10-30 13:05:23 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@705b7fef{/stages/pool/json,null,AVAILABLE,@Spark}
2025-10-30 13:05:23 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@6bdd33ec{/stages/taskThreadDump,null,AVAILABLE,@Spark}
2025-10-30 13:05:23 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@19276de1{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
2025-10-30 13:05:23 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@42adef20{/storage,null,AVAILABLE,@Spark}
2025-10-30 13:05:23 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@14d98ed3{/storage/json,null,AVAILABLE,@Spark}
2025-10-30 13:05:23 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@16560f96{/storage/rdd,null,AVAILABLE,@Spark}
2025-10-30 13:05:23 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@65951109{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-10-30 13:05:23 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@1ed6901{/environment,null,AVAILABLE,@Spark}
2025-10-30 13:05:23 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@648c1e88{/environment/json,null,AVAILABLE,@Spark}
2025-10-30 13:05:23 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@264ca065{/executors,null,AVAILABLE,@Spark}
2025-10-30 13:05:23 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@69587b7a{/executors/json,null,AVAILABLE,@Spark}
2025-10-30 13:05:23 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@7d6c1c20{/executors/threadDump,null,AVAILABLE,@Spark}
2025-10-30 13:05:23 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@182e0984{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-10-30 13:05:23 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@3d864bea{/executors/heapHistogram,null,AVAILABLE,@Spark}
2025-10-30 13:05:23 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@5eb831ab{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2025-10-30 13:05:23 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4798ff2e{/static,null,AVAILABLE,@Spark}
2025-10-30 13:05:23 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@2d03a0ea{/,null,AVAILABLE,@Spark}
2025-10-30 13:05:23 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@5e28a579{/api,null,AVAILABLE,@Spark}
2025-10-30 13:05:23 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@35477e5d{/metrics,null,AVAILABLE,@Spark}
2025-10-30 13:05:23 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@623122d3{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-10-30 13:05:23 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@52a36fd1{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-10-30 13:05:23 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4175fce3{/metrics/json,null,AVAILABLE,@Spark}
2025-10-30 13:05:26 INFO  SharedState:190 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-10-30 13:05:26 INFO  SharedState:190 - Warehouse path is 'file:/C:/Users/user/DataGripProjects/innowise_trainee/TASKS/task_5/spark-warehouse'.
2025-10-30 13:05:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@b134abe{/SQL,null,AVAILABLE,@Spark}
2025-10-30 13:05:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@7b66283{/SQL/json,null,AVAILABLE,@Spark}
2025-10-30 13:05:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@5d4fec1{/SQL/execution,null,AVAILABLE,@Spark}
2025-10-30 13:05:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@2858fdd6{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-10-30 13:05:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@690d468b{/static/sql,null,AVAILABLE,@Spark}
2025-10-30 13:05:43 INFO  CodeGenerator:190 - Code generated in 305.3051 ms
2025-10-30 13:05:43 INFO  CodeGenerator:190 - Code generated in 305.624 ms
2025-10-30 13:05:43 INFO  DAGScheduler:190 - Registering RDD 4 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 1
2025-10-30 13:05:43 INFO  DAGScheduler:190 - Got map stage job 0 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 13:05:43 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 0 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 13:05:43 INFO  DAGScheduler:190 - Parents of final stage: List()
2025-10-30 13:05:43 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 13:05:43 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[4] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 13:05:43 INFO  MemoryStore:190 - MemoryStore started with capacity 434.4 MiB
2025-10-30 13:05:43 INFO  MemoryStore:190 - Block broadcast_0 stored as values in memory (estimated size 15.9 KiB, free 434.4 MiB)
2025-10-30 13:05:43 INFO  MemoryStore:190 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 434.4 MiB)
2025-10-30 13:05:43 INFO  SparkContext:190 - Created broadcast 0 from broadcast at DAGScheduler.scala:1676
2025-10-30 13:05:43 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[4] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 13:05:44 INFO  TaskSchedulerImpl:190 - Adding task set 0.0 with 1 tasks resource profile 0
2025-10-30 13:05:44 INFO  DAGScheduler:190 - Registering RDD 5 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 0
2025-10-30 13:05:44 INFO  DAGScheduler:190 - Got map stage job 1 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 13:05:44 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 1 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 13:05:44 INFO  DAGScheduler:190 - Parents of final stage: List()
2025-10-30 13:05:44 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 13:05:44 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 13:05:44 INFO  MemoryStore:190 - Block broadcast_1 stored as values in memory (estimated size 15.8 KiB, free 434.4 MiB)
2025-10-30 13:05:44 INFO  MemoryStore:190 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.4 MiB)
2025-10-30 13:05:44 INFO  SparkContext:190 - Created broadcast 1 from broadcast at DAGScheduler.scala:1676
2025-10-30 13:05:44 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 13:05:44 INFO  TaskSchedulerImpl:190 - Adding task set 1.0 with 1 tasks resource profile 0
2025-10-30 13:05:44 INFO  TaskSetManager:190 - Starting task 0.0 in stage 0.0 (TID 0) (localhost,executor driver, partition 0, PROCESS_LOCAL, 9643 bytes)
2025-10-30 13:05:44 INFO  TaskSetManager:190 - Starting task 0.0 in stage 1.0 (TID 1) (localhost,executor driver, partition 0, PROCESS_LOCAL, 9643 bytes)
2025-10-30 13:05:44 INFO  Executor:190 - Running task 0.0 in stage 1.0 (TID 1)
2025-10-30 13:05:44 INFO  Executor:190 - Running task 0.0 in stage 0.0 (TID 0)
2025-10-30 13:05:44 INFO  CodeGenerator:190 - Code generated in 21.7004 ms
2025-10-30 13:05:44 INFO  CodeGenerator:190 - Code generated in 22.8854 ms
2025-10-30 13:05:44 INFO  CodeGenerator:190 - Code generated in 53.4217 ms
2025-10-30 13:05:44 INFO  CodeGenerator:190 - Code generated in 53.2896 ms
2025-10-30 13:05:44 INFO  SecurityManager:190 - Changing view acls to: user
2025-10-30 13:05:44 INFO  SecurityManager:190 - Changing modify acls to: user
2025-10-30 13:05:44 INFO  SecurityManager:190 - Changing view acls groups to: user
2025-10-30 13:05:44 INFO  SecurityManager:190 - Changing modify acls groups to: user
2025-10-30 13:05:44 INFO  SecurityManager:190 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: user groups with view permissions: EMPTY; users with modify permissions: user; groups with modify permissions: EMPTY; RPC SSL disabled
2025-10-30 13:05:44 INFO  JDBCRDD:184 - closed connection
2025-10-30 13:05:44 INFO  JDBCRDD:184 - closed connection
2025-10-30 13:05:44 INFO  Executor:190 - Finished task 0.0 in stage 1.0 (TID 1). 2107 bytes result sent to driver
2025-10-30 13:05:44 INFO  Executor:190 - Finished task 0.0 in stage 0.0 (TID 0). 2107 bytes result sent to driver
2025-10-30 13:05:44 INFO  TaskSetManager:190 - Finished task 0.0 in stage 0.0 (TID 0) in 596 ms on localhost (executor driver) (1/1)
2025-10-30 13:05:44 INFO  TaskSchedulerImpl:190 - Removed TaskSet 0.0 whose tasks have all completed, from pool
2025-10-30 13:05:44 INFO  TaskSetManager:190 - Finished task 0.0 in stage 1.0 (TID 1) in 568 ms on localhost (executor driver) (1/1)
2025-10-30 13:05:44 INFO  TaskSchedulerImpl:190 - Removed TaskSet 1.0 whose tasks have all completed, from pool
2025-10-30 13:05:44 INFO  DAGScheduler:190 - ShuffleMapStage 0 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 970 ms
2025-10-30 13:05:44 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 13:05:44 INFO  DAGScheduler:190 - running: HashSet(ShuffleMapStage 1)
2025-10-30 13:05:44 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 13:05:44 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 13:05:44 INFO  DAGScheduler:190 - ShuffleMapStage 1 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 630 ms
2025-10-30 13:05:44 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 13:05:44 INFO  DAGScheduler:190 - running: HashSet()
2025-10-30 13:05:44 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 13:05:44 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 13:05:44 INFO  ShufflePartitionsUtil:190 - For shuffle(0, 1, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 13:05:44 INFO  CodeGenerator:190 - Code generated in 100.7248 ms
2025-10-30 13:05:45 INFO  CodeGenerator:190 - Code generated in 15.156 ms
2025-10-30 13:05:45 INFO  CodeGenerator:190 - Code generated in 12.7304 ms
2025-10-30 13:05:45 INFO  DAGScheduler:190 - Registering RDD 12 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 2
2025-10-30 13:05:45 INFO  DAGScheduler:190 - Got map stage job 2 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 13:05:45 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 4 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 13:05:45 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 2, ShuffleMapStage 3)
2025-10-30 13:05:45 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 13:05:45 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 4 (MapPartitionsRDD[12] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 13:05:45 INFO  MemoryStore:190 - Block broadcast_2 stored as values in memory (estimated size 56.3 KiB, free 434.3 MiB)
2025-10-30 13:05:45 INFO  MemoryStore:190 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 434.3 MiB)
2025-10-30 13:05:45 INFO  SparkContext:190 - Created broadcast 2 from broadcast at DAGScheduler.scala:1676
2025-10-30 13:05:45 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[12] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 13:05:45 INFO  TaskSchedulerImpl:190 - Adding task set 4.0 with 1 tasks resource profile 0
2025-10-30 13:05:45 INFO  TaskSetManager:190 - Starting task 0.0 in stage 4.0 (TID 2) (localhost,executor driver, partition 0, ANY, 10295 bytes)
2025-10-30 13:05:45 INFO  Executor:190 - Running task 0.0 in stage 4.0 (TID 2)
2025-10-30 13:05:45 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (7.3 KiB) non-empty blocks including 1 (7.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 13:05:45 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 24 ms
2025-10-30 13:05:45 INFO  CodeGenerator:190 - Code generated in 13.0797 ms
2025-10-30 13:05:45 INFO  CodeGenerator:190 - Code generated in 37.9657 ms
2025-10-30 13:05:45 INFO  CodeGenerator:190 - Code generated in 9.6052 ms
2025-10-30 13:05:45 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (1122.0 B) non-empty blocks including 1 (1122.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 13:05:45 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 1 ms
2025-10-30 13:05:45 INFO  CodeGenerator:190 - Code generated in 10.1895 ms
2025-10-30 13:05:45 INFO  CodeGenerator:190 - Code generated in 10.6028 ms
2025-10-30 13:05:45 INFO  CodeGenerator:190 - Code generated in 7.9423 ms
2025-10-30 13:05:45 INFO  CodeGenerator:190 - Code generated in 60.2754 ms
2025-10-30 13:05:45 INFO  CodeGenerator:190 - Code generated in 17.9274 ms
2025-10-30 13:05:45 INFO  CodeGenerator:190 - Code generated in 4.9645 ms
2025-10-30 13:05:45 INFO  CodeGenerator:190 - Code generated in 5.4669 ms
2025-10-30 13:05:45 INFO  CodeGenerator:190 - Code generated in 14.9407 ms
2025-10-30 13:05:45 INFO  Executor:190 - Finished task 0.0 in stage 4.0 (TID 2). 6559 bytes result sent to driver
2025-10-30 13:05:45 INFO  TaskSetManager:190 - Finished task 0.0 in stage 4.0 (TID 2) in 502 ms on localhost (executor driver) (1/1)
2025-10-30 13:05:45 INFO  TaskSchedulerImpl:190 - Removed TaskSet 4.0 whose tasks have all completed, from pool
2025-10-30 13:05:45 INFO  DAGScheduler:190 - ShuffleMapStage 4 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 522 ms
2025-10-30 13:05:45 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 13:05:45 INFO  DAGScheduler:190 - running: HashSet()
2025-10-30 13:05:45 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 13:05:45 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 13:05:45 INFO  ShufflePartitionsUtil:190 - For shuffle(2, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 13:05:45 INFO  CodeGenerator:190 - Code generated in 7.2882 ms
2025-10-30 13:05:45 INFO  HashAggregateExec:190 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-10-30 13:05:45 INFO  CodeGenerator:190 - Code generated in 16.299 ms
2025-10-30 13:05:45 INFO  SparkContext:190 - Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 13:05:45 INFO  DAGScheduler:190 - Got job 3 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 13:05:45 INFO  DAGScheduler:190 - Final stage: ResultStage 8 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 13:05:45 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 7)
2025-10-30 13:05:45 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 13:05:45 INFO  DAGScheduler:190 - Submitting ResultStage 8 (MapPartitionsRDD[16] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 13:05:45 INFO  MemoryStore:190 - Block broadcast_3 stored as values in memory (estimated size 51.1 KiB, free 434.3 MiB)
2025-10-30 13:05:45 INFO  MemoryStore:190 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 21.8 KiB, free 434.3 MiB)
2025-10-30 13:05:45 INFO  SparkContext:190 - Created broadcast 3 from broadcast at DAGScheduler.scala:1676
2025-10-30 13:05:45 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[16] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 13:05:45 INFO  TaskSchedulerImpl:190 - Adding task set 8.0 with 1 tasks resource profile 0
2025-10-30 13:05:45 INFO  TaskSetManager:190 - Starting task 0.0 in stage 8.0 (TID 3) (localhost,executor driver, partition 0, ANY, 9808 bytes)
2025-10-30 13:05:45 INFO  Executor:190 - Running task 0.0 in stage 8.0 (TID 3)
2025-10-30 13:05:45 INFO  CodeGenerator:190 - Code generated in 7.0344 ms
2025-10-30 13:05:45 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (1168.0 B) non-empty blocks including 1 (1168.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 13:05:45 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 1 ms
2025-10-30 13:05:45 INFO  CodeGenerator:190 - Code generated in 15.2962 ms
2025-10-30 13:05:45 INFO  Executor:190 - Finished task 0.0 in stage 8.0 (TID 3). 8353 bytes result sent to driver
2025-10-30 13:05:45 INFO  TaskSetManager:190 - Finished task 0.0 in stage 8.0 (TID 3) in 128 ms on localhost (executor driver) (1/1)
2025-10-30 13:05:45 INFO  TaskSchedulerImpl:190 - Removed TaskSet 8.0 whose tasks have all completed, from pool
2025-10-30 13:05:45 INFO  DAGScheduler:190 - ResultStage 8 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 142 ms
2025-10-30 13:05:45 INFO  DAGScheduler:190 - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-10-30 13:05:45 INFO  TaskSchedulerImpl:190 - Canceling stage 8
2025-10-30 13:05:45 INFO  TaskSchedulerImpl:190 - Killing all running tasks in stage 8: Stage finished
2025-10-30 13:05:45 INFO  DAGScheduler:190 - Job 3 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 164.4228 ms
2025-10-30 13:05:45 INFO  CodeGenerator:190 - Code generated in 13.9882 ms
2025-10-30 13:05:46 INFO  CodeGenerator:190 - Code generated in 9.3815 ms
2025-10-30 13:06:30 INFO  SparkContext:184 - Invoking stop() from shutdown hook
2025-10-30 13:06:30 INFO  SparkContext:190 - SparkContext is stopping with exitCode 0 from run at Executors.java:572.
2025-10-30 13:06:30 INFO  Server:479 - Stopped Server@104c717b{STOPPING}[11.0.24,sto=30000]
2025-10-30 13:06:30 INFO  Server:135 - Shutdown Server@104c717b{STOPPING}[11.0.24,sto=30000]
2025-10-30 13:06:30 INFO  AbstractConnector:431 - Stopped Spark@5964168{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-10-30 13:06:30 INFO  SparkUI:190 - Stopped Spark web UI at http://127.0.0.1:4040
2025-10-30 13:06:30 INFO  MapOutputTrackerMasterEndpoint:184 - MapOutputTrackerMasterEndpoint stopped!
2025-10-30 13:06:30 INFO  MemoryStore:184 - MemoryStore cleared
2025-10-30 13:06:30 INFO  BlockManager:184 - BlockManager stopped
2025-10-30 13:06:30 INFO  BlockManagerMaster:184 - BlockManagerMaster stopped
2025-10-30 13:06:30 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:184 - OutputCommitCoordinator stopped!
2025-10-30 13:06:30 WARN  SparkEnv:258 - Exception while deleting Spark temp dir: C:\Users\user\AppData\Local\Temp\spark-fef6f8d4-8a5b-4a44-9720-8e172d67838d\userFiles-0e01fa6e-302a-4854-99fd-b752736aa0ab
java.io.IOException: Failed to delete: C:\Users\user\AppData\Local\Temp\spark-fef6f8d4-8a5b-4a44-9720-8e172d67838d\userFiles-0e01fa6e-302a-4854-99fd-b752736aa0ab\postgresql-42.7.3.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:155) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:131) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2395) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2297) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at scala.util.Try$.apply(Try.scala:217) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:1570) [?:?]
2025-10-30 13:06:30 INFO  SparkContext:184 - Successfully stopped SparkContext
2025-10-30 13:06:30 INFO  ShutdownHookManager:184 - Shutdown hook called
2025-10-30 13:06:30 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\artifacts-087bdab8-c243-4593-8013-45362057acdb
2025-10-30 13:06:30 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-fef6f8d4-8a5b-4a44-9720-8e172d67838d
2025-10-30 13:06:30 ERROR ShutdownHookManager:278 - Exception while deleting Spark temp dir: C:\Users\user\AppData\Local\Temp\spark-fef6f8d4-8a5b-4a44-9720-8e172d67838d
java.io.IOException: Failed to delete: C:\Users\user\AppData\Local\Temp\spark-fef6f8d4-8a5b-4a44-9720-8e172d67838d\userFiles-0e01fa6e-302a-4854-99fd-b752736aa0ab\postgresql-42.7.3.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:155) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:70) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:67) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:67) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at scala.util.Try$.apply(Try.scala:217) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:1570) [?:?]
2025-10-30 13:06:30 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-fef6f8d4-8a5b-4a44-9720-8e172d67838d\pyspark-2aa643b6-5eaf-4cf4-800d-a796ebff6129
2025-10-30 13:06:30 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-8f6a483b-0181-40aa-81f3-a697dab93f6e
2025-10-30 13:06:30 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-fef6f8d4-8a5b-4a44-9720-8e172d67838d\userFiles-0e01fa6e-302a-4854-99fd-b752736aa0ab
2025-10-30 13:06:30 ERROR ShutdownHookManager:278 - Exception while deleting Spark temp dir: C:\Users\user\AppData\Local\Temp\spark-fef6f8d4-8a5b-4a44-9720-8e172d67838d\userFiles-0e01fa6e-302a-4854-99fd-b752736aa0ab
java.io.IOException: Failed to delete: C:\Users\user\AppData\Local\Temp\spark-fef6f8d4-8a5b-4a44-9720-8e172d67838d\userFiles-0e01fa6e-302a-4854-99fd-b752736aa0ab\postgresql-42.7.3.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:155) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:70) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:67) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:67) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at scala.util.Try$.apply(Try.scala:217) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:1570) [?:?]
2025-10-30 23:07:42 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-10-30 23:07:43 INFO  SparkContext:190 - Running Spark version 4.0.1
2025-10-30 23:07:43 INFO  SparkContext:190 - OS info Windows 11, 10.0, amd64
2025-10-30 23:07:43 INFO  SparkContext:190 - Java version 22.0.2
2025-10-30 23:07:43 INFO  ResourceUtils:184 - ==============================================================
2025-10-30 23:07:43 INFO  ResourceUtils:184 - No custom resources configured for spark.driver.
2025-10-30 23:07:43 INFO  ResourceUtils:184 - ==============================================================
2025-10-30 23:07:43 INFO  SparkContext:190 - Submitted application: LocalConnection
2025-10-30 23:07:43 INFO  ResourceProfile:190 - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-10-30 23:07:43 INFO  ResourceProfile:190 - Limiting resource is cpu
2025-10-30 23:07:43 INFO  ResourceProfileManager:190 - Added ResourceProfile id: 0
2025-10-30 23:07:43 INFO  SecurityManager:190 - Changing view acls to: user
2025-10-30 23:07:43 INFO  SecurityManager:190 - Changing modify acls to: user
2025-10-30 23:07:43 INFO  SecurityManager:190 - Changing view acls groups to: user
2025-10-30 23:07:43 INFO  SecurityManager:190 - Changing modify acls groups to: user
2025-10-30 23:07:43 INFO  SecurityManager:190 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: user groups with view permissions: EMPTY; users with modify permissions: user; groups with modify permissions: EMPTY; RPC SSL disabled
2025-10-30 23:07:43 INFO  Utils:190 - Successfully started service 'sparkDriver' on port 52327.
2025-10-30 23:07:43 INFO  SparkEnv:190 - Registering MapOutputTracker
2025-10-30 23:07:43 INFO  SparkEnv:190 - Registering BlockManagerMaster
2025-10-30 23:07:43 INFO  BlockManagerMasterEndpoint:190 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-10-30 23:07:43 INFO  BlockManagerMasterEndpoint:184 - BlockManagerMasterEndpoint up
2025-10-30 23:07:43 INFO  SparkEnv:190 - Registering BlockManagerMasterHeartbeat
2025-10-30 23:07:43 INFO  DiskBlockManager:190 - Created local directory at C:\Users\user\AppData\Local\Temp\blockmgr-90508e76-2828-4645-9fb5-c7b159b6b5eb
2025-10-30 23:07:43 INFO  SparkEnv:190 - Registering OutputCommitCoordinator
2025-10-30 23:07:43 INFO  JettyUtils:190 - Start Jetty 0.0.0.0:4040 for SparkUI
2025-10-30 23:07:44 INFO  Server:384 - jetty-11.0.24; built: 2024-08-26T18:11:22.448Z; git: 5dfc59a691b748796f922208956bd1f2794bcd16; jvm 22.0.2+9-70
2025-10-30 23:07:44 INFO  Server:439 - Started Server@382351f5{STARTING}[11.0.24,sto=30000] @6118ms
2025-10-30 23:07:44 INFO  AbstractConnector:376 - Started ServerConnector@5964168{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-10-30 23:07:44 INFO  Utils:190 - Successfully started service 'SparkUI' on port 4040.
2025-10-30 23:07:44 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@57f2540d{/,null,AVAILABLE,@Spark}
2025-10-30 23:07:44 INFO  SparkContext:190 - Added JAR C:\Users\user\AppData\Roaming\JetBrains\DataGrip2025.2\jdbc-drivers\PostgreSQL\42.7.3\org\postgresql\postgresql\42.7.3\postgresql-42.7.3.jar at spark://127.0.0.1:52327/jars/postgresql-42.7.3.jar with timestamp 1761854863142
2025-10-30 23:07:44 INFO  SecurityManager:190 - Changing view acls to: user
2025-10-30 23:07:44 INFO  SecurityManager:190 - Changing modify acls to: user
2025-10-30 23:07:44 INFO  SecurityManager:190 - Changing view acls groups to: user
2025-10-30 23:07:44 INFO  SecurityManager:190 - Changing modify acls groups to: user
2025-10-30 23:07:44 INFO  SecurityManager:190 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: user groups with view permissions: EMPTY; users with modify permissions: user; groups with modify permissions: EMPTY; RPC SSL disabled
2025-10-30 23:07:44 INFO  Executor:190 - Starting executor ID driver on host localhost
2025-10-30 23:07:44 INFO  Executor:190 - OS info Windows 11, 10.0, amd64
2025-10-30 23:07:44 INFO  Executor:190 - Java version 22.0.2
2025-10-30 23:07:44 INFO  Executor:190 - Starting executor with user classpath (userClassPathFirst = false): ''
2025-10-30 23:07:44 INFO  Executor:190 - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@dcbec02 for default.
2025-10-30 23:07:44 INFO  Executor:190 - Fetching spark://127.0.0.1:52327/jars/postgresql-42.7.3.jar with timestamp 1761854863142
2025-10-30 23:07:44 INFO  TransportClientFactory:155 - Successfully created connection to /127.0.0.1:52327 after 36 ms (0 ms spent in bootstraps)
2025-10-30 23:07:44 INFO  Utils:190 - Fetching spark://127.0.0.1:52327/jars/postgresql-42.7.3.jar to C:\Users\user\AppData\Local\Temp\spark-97e898d2-ef92-43fd-82fd-2a3cf989563a\userFiles-96c83cf4-f340-4d87-b246-853a5b91fa65\fetchFileTemp17919092359255661435.tmp
2025-10-30 23:07:44 INFO  Executor:190 - Adding file:/C:/Users/user/AppData/Local/Temp/spark-97e898d2-ef92-43fd-82fd-2a3cf989563a/userFiles-96c83cf4-f340-4d87-b246-853a5b91fa65/postgresql-42.7.3.jar to class loader default
2025-10-30 23:07:44 INFO  Utils:190 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52334.
2025-10-30 23:07:44 INFO  NettyBlockTransferService:155 - Server created on 127.0.0.1:52334
2025-10-30 23:07:44 INFO  BlockManager:190 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-10-30 23:07:44 INFO  BlockManagerMaster:190 - Registering BlockManager BlockManagerId(driver, 127.0.0.1, 52334, None)
2025-10-30 23:07:44 INFO  BlockManagerMasterEndpoint:190 - Registering block manager 127.0.0.1:52334 with 434.4 MiB RAM, BlockManagerId(driver, 127.0.0.1, 52334, None)
2025-10-30 23:07:44 INFO  BlockManagerMaster:190 - Registered BlockManager BlockManagerId(driver, 127.0.0.1, 52334, None)
2025-10-30 23:07:44 INFO  BlockManager:190 - Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 52334, None)
2025-10-30 23:07:44 INFO  ContextHandler:1123 - Stopped o.s.j.s.ServletContextHandler@57f2540d{/,null,STOPPED,@Spark}
2025-10-30 23:07:44 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@66e3fbac{/jobs,null,AVAILABLE,@Spark}
2025-10-30 23:07:44 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@58e99a4b{/jobs/json,null,AVAILABLE,@Spark}
2025-10-30 23:07:44 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@2ff028af{/jobs/job,null,AVAILABLE,@Spark}
2025-10-30 23:07:44 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@3fe2e2c7{/jobs/job/json,null,AVAILABLE,@Spark}
2025-10-30 23:07:44 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@7b9e604d{/stages,null,AVAILABLE,@Spark}
2025-10-30 23:07:44 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@10bd5c3e{/stages/json,null,AVAILABLE,@Spark}
2025-10-30 23:07:44 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@612d2546{/stages/stage,null,AVAILABLE,@Spark}
2025-10-30 23:07:44 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@28701689{/stages/stage/json,null,AVAILABLE,@Spark}
2025-10-30 23:07:44 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@403d47d{/stages/pool,null,AVAILABLE,@Spark}
2025-10-30 23:07:44 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@493e82b5{/stages/pool/json,null,AVAILABLE,@Spark}
2025-10-30 23:07:44 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@39df9d2f{/stages/taskThreadDump,null,AVAILABLE,@Spark}
2025-10-30 23:07:44 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@7548a69c{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
2025-10-30 23:07:44 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@3bfd2ca9{/storage,null,AVAILABLE,@Spark}
2025-10-30 23:07:44 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@36a241b7{/storage/json,null,AVAILABLE,@Spark}
2025-10-30 23:07:44 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@6dead788{/storage/rdd,null,AVAILABLE,@Spark}
2025-10-30 23:07:44 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@3c274725{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-10-30 23:07:44 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@3931e0f0{/environment,null,AVAILABLE,@Spark}
2025-10-30 23:07:44 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@47eec33e{/environment/json,null,AVAILABLE,@Spark}
2025-10-30 23:07:44 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@125c59ed{/executors,null,AVAILABLE,@Spark}
2025-10-30 23:07:44 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@57cacd4a{/executors/json,null,AVAILABLE,@Spark}
2025-10-30 23:07:44 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@636ecfc3{/executors/threadDump,null,AVAILABLE,@Spark}
2025-10-30 23:07:44 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@64696773{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-10-30 23:07:44 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@9e24607{/executors/heapHistogram,null,AVAILABLE,@Spark}
2025-10-30 23:07:44 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@140a953{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2025-10-30 23:07:44 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@3a5a0845{/static,null,AVAILABLE,@Spark}
2025-10-30 23:07:44 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@6d3872d9{/,null,AVAILABLE,@Spark}
2025-10-30 23:07:44 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@6d165ea9{/api,null,AVAILABLE,@Spark}
2025-10-30 23:07:44 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@32944926{/metrics,null,AVAILABLE,@Spark}
2025-10-30 23:07:44 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4040233a{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-10-30 23:07:44 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@63b28384{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-10-30 23:07:44 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@6b419fcb{/metrics/json,null,AVAILABLE,@Spark}
2025-10-30 23:07:48 INFO  SharedState:190 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-10-30 23:07:48 INFO  SharedState:190 - Warehouse path is 'file:/C:/Users/user/DataGripProjects/innowise_trainee/TASKS/task_5/spark-warehouse'.
2025-10-30 23:07:48 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@6f0ee34e{/SQL,null,AVAILABLE,@Spark}
2025-10-30 23:07:48 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@32a17907{/SQL/json,null,AVAILABLE,@Spark}
2025-10-30 23:07:48 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@446421db{/SQL/execution,null,AVAILABLE,@Spark}
2025-10-30 23:07:48 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@2cd260ab{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-10-30 23:07:48 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@61fed771{/static/sql,null,AVAILABLE,@Spark}
2025-10-30 23:08:57 INFO  SparkContext:184 - Invoking stop() from shutdown hook
2025-10-30 23:08:57 INFO  SparkContext:190 - SparkContext is stopping with exitCode 0 from run at Executors.java:572.
2025-10-30 23:08:57 INFO  Server:479 - Stopped Server@382351f5{STOPPING}[11.0.24,sto=30000]
2025-10-30 23:08:57 INFO  Server:135 - Shutdown Server@382351f5{STOPPING}[11.0.24,sto=30000]
2025-10-30 23:08:57 INFO  AbstractConnector:431 - Stopped Spark@5964168{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-10-30 23:08:57 INFO  SparkUI:190 - Stopped Spark web UI at http://127.0.0.1:4040
2025-10-30 23:08:57 INFO  MapOutputTrackerMasterEndpoint:184 - MapOutputTrackerMasterEndpoint stopped!
2025-10-30 23:08:57 INFO  MemoryStore:190 - MemoryStore started with capacity 434.4 MiB
2025-10-30 23:08:57 INFO  MemoryStore:184 - MemoryStore cleared
2025-10-30 23:08:57 INFO  BlockManager:184 - BlockManager stopped
2025-10-30 23:09:11 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-10-30 23:09:12 INFO  SparkContext:190 - Running Spark version 4.0.1
2025-10-30 23:09:12 INFO  SparkContext:190 - OS info Windows 11, 10.0, amd64
2025-10-30 23:09:12 INFO  SparkContext:190 - Java version 22.0.2
2025-10-30 23:09:12 INFO  ResourceUtils:184 - ==============================================================
2025-10-30 23:09:12 INFO  ResourceUtils:184 - No custom resources configured for spark.driver.
2025-10-30 23:09:12 INFO  ResourceUtils:184 - ==============================================================
2025-10-30 23:09:12 INFO  SparkContext:190 - Submitted application: LocalConnection
2025-10-30 23:09:12 INFO  ResourceProfile:190 - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-10-30 23:09:12 INFO  ResourceProfile:190 - Limiting resource is cpu
2025-10-30 23:09:12 INFO  ResourceProfileManager:190 - Added ResourceProfile id: 0
2025-10-30 23:09:12 INFO  SecurityManager:190 - Changing view acls to: user
2025-10-30 23:09:12 INFO  SecurityManager:190 - Changing modify acls to: user
2025-10-30 23:09:12 INFO  SecurityManager:190 - Changing view acls groups to: user
2025-10-30 23:09:12 INFO  SecurityManager:190 - Changing modify acls groups to: user
2025-10-30 23:09:12 INFO  SecurityManager:190 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: user groups with view permissions: EMPTY; users with modify permissions: user; groups with modify permissions: EMPTY; RPC SSL disabled
2025-10-30 23:09:12 INFO  Utils:190 - Successfully started service 'sparkDriver' on port 63656.
2025-10-30 23:09:12 INFO  SparkEnv:190 - Registering MapOutputTracker
2025-10-30 23:09:12 INFO  SparkEnv:190 - Registering BlockManagerMaster
2025-10-30 23:09:12 INFO  BlockManagerMasterEndpoint:190 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-10-30 23:09:12 INFO  BlockManagerMasterEndpoint:184 - BlockManagerMasterEndpoint up
2025-10-30 23:09:12 INFO  SparkEnv:190 - Registering BlockManagerMasterHeartbeat
2025-10-30 23:09:12 INFO  DiskBlockManager:190 - Created local directory at C:\Users\user\AppData\Local\Temp\blockmgr-634d1194-22f6-450a-a928-1e82d901de6e
2025-10-30 23:09:12 INFO  SparkEnv:190 - Registering OutputCommitCoordinator
2025-10-30 23:09:12 INFO  JettyUtils:190 - Start Jetty 0.0.0.0:4040 for SparkUI
2025-10-30 23:09:12 INFO  Server:384 - jetty-11.0.24; built: 2024-08-26T18:11:22.448Z; git: 5dfc59a691b748796f922208956bd1f2794bcd16; jvm 22.0.2+9-70
2025-10-30 23:09:12 INFO  Server:439 - Started Server@104c717b{STARTING}[11.0.24,sto=30000] @2573ms
2025-10-30 23:09:12 INFO  AbstractConnector:376 - Started ServerConnector@72112998{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-10-30 23:09:12 INFO  Utils:190 - Successfully started service 'SparkUI' on port 4040.
2025-10-30 23:09:12 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@6b9baa9a{/,null,AVAILABLE,@Spark}
2025-10-30 23:09:12 INFO  SparkContext:190 - Added JAR C:\Users\user\AppData\Roaming\JetBrains\DataGrip2025.2\jdbc-drivers\PostgreSQL\42.7.3\org\postgresql\postgresql\42.7.3\postgresql-42.7.3.jar at spark://127.0.0.1:63656/jars/postgresql-42.7.3.jar with timestamp 1761854952153
2025-10-30 23:09:12 INFO  SecurityManager:190 - Changing view acls to: user
2025-10-30 23:09:12 INFO  SecurityManager:190 - Changing modify acls to: user
2025-10-30 23:09:12 INFO  SecurityManager:190 - Changing view acls groups to: user
2025-10-30 23:09:12 INFO  SecurityManager:190 - Changing modify acls groups to: user
2025-10-30 23:09:12 INFO  SecurityManager:190 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: user groups with view permissions: EMPTY; users with modify permissions: user; groups with modify permissions: EMPTY; RPC SSL disabled
2025-10-30 23:09:13 INFO  Executor:190 - Starting executor ID driver on host localhost
2025-10-30 23:09:13 INFO  Executor:190 - OS info Windows 11, 10.0, amd64
2025-10-30 23:09:13 INFO  Executor:190 - Java version 22.0.2
2025-10-30 23:09:13 INFO  Executor:190 - Starting executor with user classpath (userClassPathFirst = false): ''
2025-10-30 23:09:13 INFO  Executor:190 - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@1cf8353 for default.
2025-10-30 23:09:13 INFO  Executor:190 - Fetching spark://127.0.0.1:63656/jars/postgresql-42.7.3.jar with timestamp 1761854952153
2025-10-30 23:09:13 INFO  TransportClientFactory:155 - Successfully created connection to /127.0.0.1:63656 after 28 ms (0 ms spent in bootstraps)
2025-10-30 23:09:13 INFO  Utils:190 - Fetching spark://127.0.0.1:63656/jars/postgresql-42.7.3.jar to C:\Users\user\AppData\Local\Temp\spark-98f300ea-3223-4df5-9e57-7a0ec9de58ef\userFiles-f76650a9-175c-423b-9b15-4f33ba098c3c\fetchFileTemp10193846419764928294.tmp
2025-10-30 23:09:13 INFO  Executor:190 - Adding file:/C:/Users/user/AppData/Local/Temp/spark-98f300ea-3223-4df5-9e57-7a0ec9de58ef/userFiles-f76650a9-175c-423b-9b15-4f33ba098c3c/postgresql-42.7.3.jar to class loader default
2025-10-30 23:09:13 INFO  Utils:190 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63661.
2025-10-30 23:09:13 INFO  NettyBlockTransferService:155 - Server created on 127.0.0.1:63661
2025-10-30 23:09:13 INFO  BlockManager:190 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-10-30 23:09:13 INFO  BlockManagerMaster:190 - Registering BlockManager BlockManagerId(driver, 127.0.0.1, 63661, None)
2025-10-30 23:09:13 INFO  BlockManagerMasterEndpoint:190 - Registering block manager 127.0.0.1:63661 with 434.4 MiB RAM, BlockManagerId(driver, 127.0.0.1, 63661, None)
2025-10-30 23:09:13 INFO  BlockManagerMaster:190 - Registered BlockManager BlockManagerId(driver, 127.0.0.1, 63661, None)
2025-10-30 23:09:13 INFO  BlockManager:190 - Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 63661, None)
2025-10-30 23:09:13 INFO  ContextHandler:1123 - Stopped o.s.j.s.ServletContextHandler@6b9baa9a{/,null,STOPPED,@Spark}
2025-10-30 23:09:13 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4c75e679{/jobs,null,AVAILABLE,@Spark}
2025-10-30 23:09:13 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@566598e8{/jobs/json,null,AVAILABLE,@Spark}
2025-10-30 23:09:13 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@49f42031{/jobs/job,null,AVAILABLE,@Spark}
2025-10-30 23:09:13 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@697945a1{/jobs/job/json,null,AVAILABLE,@Spark}
2025-10-30 23:09:13 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@217c19aa{/stages,null,AVAILABLE,@Spark}
2025-10-30 23:09:13 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@185fd86c{/stages/json,null,AVAILABLE,@Spark}
2025-10-30 23:09:13 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@1a65145c{/stages/stage,null,AVAILABLE,@Spark}
2025-10-30 23:09:13 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@1fd4ebf{/stages/stage/json,null,AVAILABLE,@Spark}
2025-10-30 23:09:13 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@47d7c74e{/stages/pool,null,AVAILABLE,@Spark}
2025-10-30 23:09:13 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@705b7fef{/stages/pool/json,null,AVAILABLE,@Spark}
2025-10-30 23:09:13 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@6bdd33ec{/stages/taskThreadDump,null,AVAILABLE,@Spark}
2025-10-30 23:09:13 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@19276de1{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
2025-10-30 23:09:13 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@42adef20{/storage,null,AVAILABLE,@Spark}
2025-10-30 23:09:13 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@14d98ed3{/storage/json,null,AVAILABLE,@Spark}
2025-10-30 23:09:13 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@16560f96{/storage/rdd,null,AVAILABLE,@Spark}
2025-10-30 23:09:13 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@65951109{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-10-30 23:09:13 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@1ed6901{/environment,null,AVAILABLE,@Spark}
2025-10-30 23:09:13 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@648c1e88{/environment/json,null,AVAILABLE,@Spark}
2025-10-30 23:09:13 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@264ca065{/executors,null,AVAILABLE,@Spark}
2025-10-30 23:09:13 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@69587b7a{/executors/json,null,AVAILABLE,@Spark}
2025-10-30 23:09:13 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@7d6c1c20{/executors/threadDump,null,AVAILABLE,@Spark}
2025-10-30 23:09:13 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@182e0984{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-10-30 23:09:13 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@3d864bea{/executors/heapHistogram,null,AVAILABLE,@Spark}
2025-10-30 23:09:13 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@5eb831ab{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2025-10-30 23:09:13 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4798ff2e{/static,null,AVAILABLE,@Spark}
2025-10-30 23:09:13 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@2d03a0ea{/,null,AVAILABLE,@Spark}
2025-10-30 23:09:13 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@5e28a579{/api,null,AVAILABLE,@Spark}
2025-10-30 23:09:13 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@35477e5d{/metrics,null,AVAILABLE,@Spark}
2025-10-30 23:09:13 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@623122d3{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-10-30 23:09:13 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@52a36fd1{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-10-30 23:09:13 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4175fce3{/metrics/json,null,AVAILABLE,@Spark}
2025-10-30 23:09:15 INFO  SharedState:190 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-10-30 23:09:15 INFO  SharedState:190 - Warehouse path is 'file:/C:/Users/user/DataGripProjects/innowise_trainee/TASKS/task_5/spark-warehouse'.
2025-10-30 23:09:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@2894796b{/SQL,null,AVAILABLE,@Spark}
2025-10-30 23:09:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@3a965ee0{/SQL/json,null,AVAILABLE,@Spark}
2025-10-30 23:09:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@2258ab5f{/SQL/execution,null,AVAILABLE,@Spark}
2025-10-30 23:09:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@2e744ff0{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-10-30 23:09:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@1527360c{/static/sql,null,AVAILABLE,@Spark}
2025-10-30 23:10:07 INFO  SparkContext:184 - Invoking stop() from shutdown hook
2025-10-30 23:10:07 INFO  SparkContext:190 - SparkContext is stopping with exitCode 0 from run at Executors.java:572.
2025-10-30 23:10:07 INFO  Server:479 - Stopped Server@104c717b{STOPPING}[11.0.24,sto=30000]
2025-10-30 23:10:07 INFO  Server:135 - Shutdown Server@104c717b{STOPPING}[11.0.24,sto=30000]
2025-10-30 23:10:07 INFO  AbstractConnector:431 - Stopped Spark@72112998{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-10-30 23:10:07 INFO  SparkUI:190 - Stopped Spark web UI at http://127.0.0.1:4040
2025-10-30 23:10:07 INFO  MapOutputTrackerMasterEndpoint:184 - MapOutputTrackerMasterEndpoint stopped!
2025-10-30 23:10:07 INFO  MemoryStore:190 - MemoryStore started with capacity 434.4 MiB
2025-10-30 23:10:07 INFO  MemoryStore:184 - MemoryStore cleared
2025-10-30 23:10:07 INFO  BlockManager:184 - BlockManager stopped
2025-10-30 23:10:07 INFO  BlockManagerMaster:184 - BlockManagerMaster stopped
2025-10-30 23:10:07 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:184 - OutputCommitCoordinator stopped!
2025-10-30 23:10:07 INFO  SparkContext:184 - Successfully stopped SparkContext
2025-10-30 23:10:07 INFO  ShutdownHookManager:184 - Shutdown hook called
2025-10-30 23:10:07 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-dc350f3c-bc26-4b58-85d9-85782a6726bb
2025-10-30 23:10:07 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-98f300ea-3223-4df5-9e57-7a0ec9de58ef
2025-10-30 23:10:07 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-98f300ea-3223-4df5-9e57-7a0ec9de58ef\pyspark-9e4d9c86-b36b-4686-9ac3-01e992dedf97
2025-10-30 23:10:13 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-10-30 23:10:13 INFO  SparkContext:190 - Running Spark version 4.0.1
2025-10-30 23:10:13 INFO  SparkContext:190 - OS info Windows 11, 10.0, amd64
2025-10-30 23:10:13 INFO  SparkContext:190 - Java version 22.0.2
2025-10-30 23:10:13 INFO  ResourceUtils:184 - ==============================================================
2025-10-30 23:10:13 INFO  ResourceUtils:184 - No custom resources configured for spark.driver.
2025-10-30 23:10:13 INFO  ResourceUtils:184 - ==============================================================
2025-10-30 23:10:13 INFO  SparkContext:190 - Submitted application: LocalConnection
2025-10-30 23:10:13 INFO  ResourceProfile:190 - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-10-30 23:10:13 INFO  ResourceProfile:190 - Limiting resource is cpu
2025-10-30 23:10:13 INFO  ResourceProfileManager:190 - Added ResourceProfile id: 0
2025-10-30 23:10:13 INFO  SecurityManager:190 - Changing view acls to: user
2025-10-30 23:10:13 INFO  SecurityManager:190 - Changing modify acls to: user
2025-10-30 23:10:13 INFO  SecurityManager:190 - Changing view acls groups to: user
2025-10-30 23:10:13 INFO  SecurityManager:190 - Changing modify acls groups to: user
2025-10-30 23:10:13 INFO  SecurityManager:190 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: user groups with view permissions: EMPTY; users with modify permissions: user; groups with modify permissions: EMPTY; RPC SSL disabled
2025-10-30 23:10:14 INFO  Utils:190 - Successfully started service 'sparkDriver' on port 56597.
2025-10-30 23:10:14 INFO  SparkEnv:190 - Registering MapOutputTracker
2025-10-30 23:10:14 INFO  SparkEnv:190 - Registering BlockManagerMaster
2025-10-30 23:10:14 INFO  BlockManagerMasterEndpoint:190 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-10-30 23:10:14 INFO  BlockManagerMasterEndpoint:184 - BlockManagerMasterEndpoint up
2025-10-30 23:10:14 INFO  SparkEnv:190 - Registering BlockManagerMasterHeartbeat
2025-10-30 23:10:14 INFO  DiskBlockManager:190 - Created local directory at C:\Users\user\AppData\Local\Temp\blockmgr-a906570a-3389-4638-8003-420c41da5578
2025-10-30 23:10:14 INFO  SparkEnv:190 - Registering OutputCommitCoordinator
2025-10-30 23:10:14 INFO  JettyUtils:190 - Start Jetty 0.0.0.0:4040 for SparkUI
2025-10-30 23:10:14 INFO  Server:384 - jetty-11.0.24; built: 2024-08-26T18:11:22.448Z; git: 5dfc59a691b748796f922208956bd1f2794bcd16; jvm 22.0.2+9-70
2025-10-30 23:10:14 INFO  Server:439 - Started Server@104c717b{STARTING}[11.0.24,sto=30000] @3736ms
2025-10-30 23:10:14 INFO  AbstractConnector:376 - Started ServerConnector@27ee1595{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-10-30 23:10:14 INFO  Utils:190 - Successfully started service 'SparkUI' on port 4040.
2025-10-30 23:10:14 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@6b9baa9a{/,null,AVAILABLE,@Spark}
2025-10-30 23:10:14 INFO  SparkContext:190 - Added JAR C:\Users\user\AppData\Roaming\JetBrains\DataGrip2025.2\jdbc-drivers\PostgreSQL\42.7.3\org\postgresql\postgresql\42.7.3\postgresql-42.7.3.jar at spark://127.0.0.1:56597/jars/postgresql-42.7.3.jar with timestamp 1761855013592
2025-10-30 23:10:14 INFO  SecurityManager:190 - Changing view acls to: user
2025-10-30 23:10:14 INFO  SecurityManager:190 - Changing modify acls to: user
2025-10-30 23:10:14 INFO  SecurityManager:190 - Changing view acls groups to: user
2025-10-30 23:10:14 INFO  SecurityManager:190 - Changing modify acls groups to: user
2025-10-30 23:10:14 INFO  SecurityManager:190 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: user groups with view permissions: EMPTY; users with modify permissions: user; groups with modify permissions: EMPTY; RPC SSL disabled
2025-10-30 23:10:14 INFO  Executor:190 - Starting executor ID driver on host localhost
2025-10-30 23:10:14 INFO  Executor:190 - OS info Windows 11, 10.0, amd64
2025-10-30 23:10:14 INFO  Executor:190 - Java version 22.0.2
2025-10-30 23:10:14 INFO  Executor:190 - Starting executor with user classpath (userClassPathFirst = false): ''
2025-10-30 23:10:14 INFO  Executor:190 - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@1cf8353 for default.
2025-10-30 23:10:14 INFO  Executor:190 - Fetching spark://127.0.0.1:56597/jars/postgresql-42.7.3.jar with timestamp 1761855013592
2025-10-30 23:10:15 INFO  TransportClientFactory:155 - Successfully created connection to /127.0.0.1:56597 after 40 ms (0 ms spent in bootstraps)
2025-10-30 23:10:15 INFO  Utils:190 - Fetching spark://127.0.0.1:56597/jars/postgresql-42.7.3.jar to C:\Users\user\AppData\Local\Temp\spark-a72035ab-90d8-412b-8144-a54ea0ed344f\userFiles-8d7775d9-534b-42f2-89d6-db4259f1b919\fetchFileTemp5965257665228606514.tmp
2025-10-30 23:10:15 INFO  Executor:190 - Adding file:/C:/Users/user/AppData/Local/Temp/spark-a72035ab-90d8-412b-8144-a54ea0ed344f/userFiles-8d7775d9-534b-42f2-89d6-db4259f1b919/postgresql-42.7.3.jar to class loader default
2025-10-30 23:10:15 INFO  Utils:190 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56603.
2025-10-30 23:10:15 INFO  NettyBlockTransferService:155 - Server created on 127.0.0.1:56603
2025-10-30 23:10:15 INFO  BlockManager:190 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-10-30 23:10:15 INFO  BlockManagerMaster:190 - Registering BlockManager BlockManagerId(driver, 127.0.0.1, 56603, None)
2025-10-30 23:10:15 INFO  BlockManagerMasterEndpoint:190 - Registering block manager 127.0.0.1:56603 with 434.4 MiB RAM, BlockManagerId(driver, 127.0.0.1, 56603, None)
2025-10-30 23:10:15 INFO  BlockManagerMaster:190 - Registered BlockManager BlockManagerId(driver, 127.0.0.1, 56603, None)
2025-10-30 23:10:15 INFO  BlockManager:190 - Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 56603, None)
2025-10-30 23:10:15 INFO  ContextHandler:1123 - Stopped o.s.j.s.ServletContextHandler@6b9baa9a{/,null,STOPPED,@Spark}
2025-10-30 23:10:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4c75e679{/jobs,null,AVAILABLE,@Spark}
2025-10-30 23:10:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@566598e8{/jobs/json,null,AVAILABLE,@Spark}
2025-10-30 23:10:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@49f42031{/jobs/job,null,AVAILABLE,@Spark}
2025-10-30 23:10:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@697945a1{/jobs/job/json,null,AVAILABLE,@Spark}
2025-10-30 23:10:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@217c19aa{/stages,null,AVAILABLE,@Spark}
2025-10-30 23:10:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@185fd86c{/stages/json,null,AVAILABLE,@Spark}
2025-10-30 23:10:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@1a65145c{/stages/stage,null,AVAILABLE,@Spark}
2025-10-30 23:10:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@1fd4ebf{/stages/stage/json,null,AVAILABLE,@Spark}
2025-10-30 23:10:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@47d7c74e{/stages/pool,null,AVAILABLE,@Spark}
2025-10-30 23:10:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@705b7fef{/stages/pool/json,null,AVAILABLE,@Spark}
2025-10-30 23:10:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@6bdd33ec{/stages/taskThreadDump,null,AVAILABLE,@Spark}
2025-10-30 23:10:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@19276de1{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
2025-10-30 23:10:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@42adef20{/storage,null,AVAILABLE,@Spark}
2025-10-30 23:10:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@14d98ed3{/storage/json,null,AVAILABLE,@Spark}
2025-10-30 23:10:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@16560f96{/storage/rdd,null,AVAILABLE,@Spark}
2025-10-30 23:10:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@65951109{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-10-30 23:10:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@1ed6901{/environment,null,AVAILABLE,@Spark}
2025-10-30 23:10:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@648c1e88{/environment/json,null,AVAILABLE,@Spark}
2025-10-30 23:10:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@264ca065{/executors,null,AVAILABLE,@Spark}
2025-10-30 23:10:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@69587b7a{/executors/json,null,AVAILABLE,@Spark}
2025-10-30 23:10:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@7d6c1c20{/executors/threadDump,null,AVAILABLE,@Spark}
2025-10-30 23:10:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@182e0984{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-10-30 23:10:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@3d864bea{/executors/heapHistogram,null,AVAILABLE,@Spark}
2025-10-30 23:10:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@5eb831ab{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2025-10-30 23:10:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4798ff2e{/static,null,AVAILABLE,@Spark}
2025-10-30 23:10:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@2d03a0ea{/,null,AVAILABLE,@Spark}
2025-10-30 23:10:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@5e28a579{/api,null,AVAILABLE,@Spark}
2025-10-30 23:10:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@35477e5d{/metrics,null,AVAILABLE,@Spark}
2025-10-30 23:10:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@623122d3{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-10-30 23:10:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@52a36fd1{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-10-30 23:10:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4175fce3{/metrics/json,null,AVAILABLE,@Spark}
2025-10-30 23:10:18 INFO  SharedState:190 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-10-30 23:10:18 INFO  SharedState:190 - Warehouse path is 'file:/C:/Users/user/DataGripProjects/innowise_trainee/TASKS/task_5/spark-warehouse'.
2025-10-30 23:10:18 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@b134abe{/SQL,null,AVAILABLE,@Spark}
2025-10-30 23:10:18 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@7b66283{/SQL/json,null,AVAILABLE,@Spark}
2025-10-30 23:10:18 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@5d4fec1{/SQL/execution,null,AVAILABLE,@Spark}
2025-10-30 23:10:18 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@2858fdd6{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-10-30 23:10:18 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@690d468b{/static/sql,null,AVAILABLE,@Spark}
2025-10-30 23:10:28 INFO  CodeGenerator:190 - Code generated in 164.4866 ms
2025-10-30 23:10:28 INFO  CodeGenerator:190 - Code generated in 164.487 ms
2025-10-30 23:10:28 INFO  DAGScheduler:190 - Registering RDD 5 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 1
2025-10-30 23:10:28 INFO  DAGScheduler:190 - Got map stage job 1 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:10:28 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 0 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:10:28 INFO  DAGScheduler:190 - Parents of final stage: List()
2025-10-30 23:10:28 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:10:28 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:10:28 INFO  MemoryStore:190 - MemoryStore started with capacity 434.4 MiB
2025-10-30 23:10:28 INFO  MemoryStore:190 - Block broadcast_0 stored as values in memory (estimated size 15.8 KiB, free 434.4 MiB)
2025-10-30 23:10:28 INFO  MemoryStore:190 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.4 MiB)
2025-10-30 23:10:28 INFO  SparkContext:190 - Created broadcast 0 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:10:28 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:10:28 INFO  TaskSchedulerImpl:190 - Adding task set 0.0 with 1 tasks resource profile 0
2025-10-30 23:10:28 INFO  DAGScheduler:190 - Registering RDD 4 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 0
2025-10-30 23:10:28 INFO  DAGScheduler:190 - Got map stage job 0 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:10:28 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 1 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:10:28 INFO  DAGScheduler:190 - Parents of final stage: List()
2025-10-30 23:10:28 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:10:28 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 1 (MapPartitionsRDD[4] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:10:28 INFO  MemoryStore:190 - Block broadcast_1 stored as values in memory (estimated size 15.9 KiB, free 434.4 MiB)
2025-10-30 23:10:28 INFO  MemoryStore:190 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 434.4 MiB)
2025-10-30 23:10:28 INFO  SparkContext:190 - Created broadcast 1 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:10:28 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[4] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:10:28 INFO  TaskSchedulerImpl:190 - Adding task set 1.0 with 1 tasks resource profile 0
2025-10-30 23:10:28 INFO  TaskSetManager:190 - Starting task 0.0 in stage 0.0 (TID 0) (localhost,executor driver, partition 0, PROCESS_LOCAL, 9643 bytes)
2025-10-30 23:10:28 INFO  TaskSetManager:190 - Starting task 0.0 in stage 1.0 (TID 1) (localhost,executor driver, partition 0, PROCESS_LOCAL, 9643 bytes)
2025-10-30 23:10:28 INFO  Executor:190 - Running task 0.0 in stage 1.0 (TID 1)
2025-10-30 23:10:28 INFO  Executor:190 - Running task 0.0 in stage 0.0 (TID 0)
2025-10-30 23:10:28 INFO  CodeGenerator:190 - Code generated in 13.4483 ms
2025-10-30 23:10:28 INFO  CodeGenerator:190 - Code generated in 13.4485 ms
2025-10-30 23:10:28 INFO  CodeGenerator:190 - Code generated in 25.4333 ms
2025-10-30 23:10:28 INFO  CodeGenerator:190 - Code generated in 25.4764 ms
2025-10-30 23:10:28 INFO  SecurityManager:190 - Changing view acls to: user
2025-10-30 23:10:28 INFO  SecurityManager:190 - Changing modify acls to: user
2025-10-30 23:10:28 INFO  SecurityManager:190 - Changing view acls groups to: user
2025-10-30 23:10:28 INFO  SecurityManager:190 - Changing modify acls groups to: user
2025-10-30 23:10:28 INFO  SecurityManager:190 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: user groups with view permissions: EMPTY; users with modify permissions: user; groups with modify permissions: EMPTY; RPC SSL disabled
2025-10-30 23:10:28 INFO  JDBCRDD:184 - closed connection
2025-10-30 23:10:28 INFO  JDBCRDD:184 - closed connection
2025-10-30 23:10:28 INFO  Executor:190 - Finished task 0.0 in stage 0.0 (TID 0). 2107 bytes result sent to driver
2025-10-30 23:10:28 INFO  Executor:190 - Finished task 0.0 in stage 1.0 (TID 1). 2107 bytes result sent to driver
2025-10-30 23:10:28 INFO  TaskSetManager:190 - Finished task 0.0 in stage 0.0 (TID 0) in 414 ms on localhost (executor driver) (1/1)
2025-10-30 23:10:28 INFO  TaskSchedulerImpl:190 - Removed TaskSet 0.0 whose tasks have all completed, from pool
2025-10-30 23:10:28 INFO  TaskSetManager:190 - Finished task 0.0 in stage 1.0 (TID 1) in 399 ms on localhost (executor driver) (1/1)
2025-10-30 23:10:28 INFO  TaskSchedulerImpl:190 - Removed TaskSet 1.0 whose tasks have all completed, from pool
2025-10-30 23:10:28 INFO  DAGScheduler:190 - ShuffleMapStage 0 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 678 ms
2025-10-30 23:10:28 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:10:28 INFO  DAGScheduler:190 - running: HashSet(ShuffleMapStage 1)
2025-10-30 23:10:28 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:10:28 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:10:28 INFO  DAGScheduler:190 - ShuffleMapStage 1 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 444 ms
2025-10-30 23:10:28 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:10:28 INFO  DAGScheduler:190 - running: HashSet()
2025-10-30 23:10:28 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:10:28 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:10:28 INFO  ShufflePartitionsUtil:190 - For shuffle(1, 0, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:10:29 INFO  CodeGenerator:190 - Code generated in 82.5993 ms
2025-10-30 23:10:29 INFO  CodeGenerator:190 - Code generated in 13.1115 ms
2025-10-30 23:10:29 INFO  CodeGenerator:190 - Code generated in 15.4885 ms
2025-10-30 23:10:29 INFO  DAGScheduler:190 - Registering RDD 12 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 2
2025-10-30 23:10:29 INFO  DAGScheduler:190 - Got map stage job 2 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:10:29 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 4 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:10:29 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 2, ShuffleMapStage 3)
2025-10-30 23:10:29 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:10:29 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 4 (MapPartitionsRDD[12] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:10:29 INFO  MemoryStore:190 - Block broadcast_2 stored as values in memory (estimated size 56.3 KiB, free 434.3 MiB)
2025-10-30 23:10:29 INFO  MemoryStore:190 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 434.3 MiB)
2025-10-30 23:10:29 INFO  SparkContext:190 - Created broadcast 2 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:10:29 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[12] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:10:29 INFO  TaskSchedulerImpl:190 - Adding task set 4.0 with 1 tasks resource profile 0
2025-10-30 23:10:29 INFO  TaskSetManager:190 - Starting task 0.0 in stage 4.0 (TID 2) (localhost,executor driver, partition 0, ANY, 10295 bytes)
2025-10-30 23:10:29 INFO  Executor:190 - Running task 0.0 in stage 4.0 (TID 2)
2025-10-30 23:10:29 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (7.3 KiB) non-empty blocks including 1 (7.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:10:29 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 20 ms
2025-10-30 23:10:29 INFO  CodeGenerator:190 - Code generated in 12.1462 ms
2025-10-30 23:10:29 INFO  CodeGenerator:190 - Code generated in 50.5701 ms
2025-10-30 23:10:29 INFO  CodeGenerator:190 - Code generated in 9.338 ms
2025-10-30 23:10:29 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (1122.0 B) non-empty blocks including 1 (1122.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:10:29 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 1 ms
2025-10-30 23:10:29 INFO  CodeGenerator:190 - Code generated in 10.7117 ms
2025-10-30 23:10:29 INFO  CodeGenerator:190 - Code generated in 7.1497 ms
2025-10-30 23:10:29 INFO  CodeGenerator:190 - Code generated in 6.2361 ms
2025-10-30 23:10:29 INFO  CodeGenerator:190 - Code generated in 34.8562 ms
2025-10-30 23:10:29 INFO  CodeGenerator:190 - Code generated in 16.4713 ms
2025-10-30 23:10:29 INFO  CodeGenerator:190 - Code generated in 4.749 ms
2025-10-30 23:10:29 INFO  CodeGenerator:190 - Code generated in 11.45 ms
2025-10-30 23:10:29 INFO  CodeGenerator:190 - Code generated in 9.1433 ms
2025-10-30 23:10:29 INFO  Executor:190 - Finished task 0.0 in stage 4.0 (TID 2). 6559 bytes result sent to driver
2025-10-30 23:10:29 INFO  TaskSetManager:190 - Finished task 0.0 in stage 4.0 (TID 2) in 472 ms on localhost (executor driver) (1/1)
2025-10-30 23:10:29 INFO  TaskSchedulerImpl:190 - Removed TaskSet 4.0 whose tasks have all completed, from pool
2025-10-30 23:10:29 INFO  DAGScheduler:190 - ShuffleMapStage 4 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 493 ms
2025-10-30 23:10:29 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:10:29 INFO  DAGScheduler:190 - running: HashSet()
2025-10-30 23:10:29 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:10:29 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:10:29 INFO  ShufflePartitionsUtil:190 - For shuffle(2, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:10:29 INFO  CodeGenerator:190 - Code generated in 6.6937 ms
2025-10-30 23:10:29 INFO  HashAggregateExec:190 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-10-30 23:10:29 INFO  CodeGenerator:190 - Code generated in 17.2052 ms
2025-10-30 23:10:29 INFO  SparkContext:190 - Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:10:29 INFO  DAGScheduler:190 - Got job 3 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:10:29 INFO  DAGScheduler:190 - Final stage: ResultStage 8 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:10:29 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 7)
2025-10-30 23:10:29 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:10:29 INFO  DAGScheduler:190 - Submitting ResultStage 8 (MapPartitionsRDD[16] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:10:29 INFO  MemoryStore:190 - Block broadcast_3 stored as values in memory (estimated size 51.1 KiB, free 434.3 MiB)
2025-10-30 23:10:29 INFO  MemoryStore:190 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 21.8 KiB, free 434.3 MiB)
2025-10-30 23:10:29 INFO  SparkContext:190 - Created broadcast 3 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:10:29 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[16] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:10:29 INFO  TaskSchedulerImpl:190 - Adding task set 8.0 with 1 tasks resource profile 0
2025-10-30 23:10:29 INFO  TaskSetManager:190 - Starting task 0.0 in stage 8.0 (TID 3) (localhost,executor driver, partition 0, ANY, 9808 bytes)
2025-10-30 23:10:29 INFO  Executor:190 - Running task 0.0 in stage 8.0 (TID 3)
2025-10-30 23:10:30 INFO  CodeGenerator:190 - Code generated in 8.0134 ms
2025-10-30 23:10:30 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (1168.0 B) non-empty blocks including 1 (1168.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:10:30 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 1 ms
2025-10-30 23:10:30 INFO  CodeGenerator:190 - Code generated in 16.9122 ms
2025-10-30 23:10:30 INFO  Executor:190 - Finished task 0.0 in stage 8.0 (TID 3). 8353 bytes result sent to driver
2025-10-30 23:10:30 INFO  TaskSetManager:190 - Finished task 0.0 in stage 8.0 (TID 3) in 105 ms on localhost (executor driver) (1/1)
2025-10-30 23:10:30 INFO  TaskSchedulerImpl:190 - Removed TaskSet 8.0 whose tasks have all completed, from pool
2025-10-30 23:10:30 INFO  DAGScheduler:190 - ResultStage 8 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 119 ms
2025-10-30 23:10:30 INFO  DAGScheduler:190 - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-10-30 23:10:30 INFO  TaskSchedulerImpl:190 - Canceling stage 8
2025-10-30 23:10:30 INFO  TaskSchedulerImpl:190 - Killing all running tasks in stage 8: Stage finished
2025-10-30 23:10:30 INFO  DAGScheduler:190 - Job 3 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 139.6385 ms
2025-10-30 23:10:30 INFO  CodeGenerator:190 - Code generated in 8.7563 ms
2025-10-30 23:10:30 INFO  CodeGenerator:190 - Code generated in 12.4792 ms
2025-10-30 23:10:32 INFO  DAGScheduler:190 - Registering RDD 21 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 3
2025-10-30 23:10:32 INFO  DAGScheduler:190 - Got map stage job 4 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:10:32 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 9 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:10:32 INFO  DAGScheduler:190 - Parents of final stage: List()
2025-10-30 23:10:32 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:10:32 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 9 (MapPartitionsRDD[21] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:10:32 INFO  MemoryStore:190 - Block broadcast_4 stored as values in memory (estimated size 15.8 KiB, free 434.4 MiB)
2025-10-30 23:10:32 INFO  MemoryStore:190 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.4 MiB)
2025-10-30 23:10:32 INFO  SparkContext:190 - Created broadcast 4 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:10:32 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[21] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:10:32 INFO  TaskSchedulerImpl:190 - Adding task set 9.0 with 1 tasks resource profile 0
2025-10-30 23:10:32 INFO  DAGScheduler:190 - Registering RDD 22 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 4
2025-10-30 23:10:32 INFO  DAGScheduler:190 - Got map stage job 5 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:10:32 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 10 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:10:32 INFO  DAGScheduler:190 - Parents of final stage: List()
2025-10-30 23:10:32 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:10:32 INFO  TaskSetManager:190 - Starting task 0.0 in stage 9.0 (TID 4) (localhost,executor driver, partition 0, PROCESS_LOCAL, 9643 bytes)
2025-10-30 23:10:32 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 10 (MapPartitionsRDD[22] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:10:32 INFO  Executor:190 - Running task 0.0 in stage 9.0 (TID 4)
2025-10-30 23:10:32 INFO  MemoryStore:190 - Block broadcast_5 stored as values in memory (estimated size 15.9 KiB, free 434.4 MiB)
2025-10-30 23:10:32 INFO  MemoryStore:190 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 434.4 MiB)
2025-10-30 23:10:32 INFO  SparkContext:190 - Created broadcast 5 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:10:32 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[22] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:10:32 INFO  TaskSchedulerImpl:190 - Adding task set 10.0 with 1 tasks resource profile 0
2025-10-30 23:10:32 INFO  TaskSetManager:190 - Starting task 0.0 in stage 10.0 (TID 5) (localhost,executor driver, partition 0, PROCESS_LOCAL, 9643 bytes)
2025-10-30 23:10:32 INFO  Executor:190 - Running task 0.0 in stage 10.0 (TID 5)
2025-10-30 23:10:32 INFO  JDBCRDD:184 - closed connection
2025-10-30 23:10:32 INFO  JDBCRDD:184 - closed connection
2025-10-30 23:10:32 INFO  Executor:190 - Finished task 0.0 in stage 9.0 (TID 4). 2021 bytes result sent to driver
2025-10-30 23:10:32 INFO  TaskSetManager:190 - Finished task 0.0 in stage 9.0 (TID 4) in 56 ms on localhost (executor driver) (1/1)
2025-10-30 23:10:32 INFO  TaskSchedulerImpl:190 - Removed TaskSet 9.0 whose tasks have all completed, from pool
2025-10-30 23:10:32 INFO  Executor:190 - Finished task 0.0 in stage 10.0 (TID 5). 2021 bytes result sent to driver
2025-10-30 23:10:32 INFO  DAGScheduler:190 - ShuffleMapStage 9 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 61 ms
2025-10-30 23:10:32 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:10:32 INFO  DAGScheduler:190 - running: HashSet(ShuffleMapStage 10)
2025-10-30 23:10:32 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:10:32 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:10:32 INFO  TaskSetManager:190 - Finished task 0.0 in stage 10.0 (TID 5) in 53 ms on localhost (executor driver) (1/1)
2025-10-30 23:10:32 INFO  TaskSchedulerImpl:190 - Removed TaskSet 10.0 whose tasks have all completed, from pool
2025-10-30 23:10:32 INFO  DAGScheduler:190 - ShuffleMapStage 10 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 59 ms
2025-10-30 23:10:32 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:10:32 INFO  DAGScheduler:190 - running: HashSet()
2025-10-30 23:10:32 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:10:32 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:10:32 INFO  ShufflePartitionsUtil:190 - For shuffle(3, 4, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:10:32 INFO  DAGScheduler:190 - Registering RDD 29 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 5
2025-10-30 23:10:32 INFO  DAGScheduler:190 - Got map stage job 6 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:10:32 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 13 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:10:32 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 11, ShuffleMapStage 12)
2025-10-30 23:10:32 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:10:32 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 13 (MapPartitionsRDD[29] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:10:32 INFO  MemoryStore:190 - Block broadcast_6 stored as values in memory (estimated size 56.3 KiB, free 434.3 MiB)
2025-10-30 23:10:32 INFO  MemoryStore:190 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 434.3 MiB)
2025-10-30 23:10:32 INFO  SparkContext:190 - Created broadcast 6 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:10:32 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[29] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:10:32 INFO  TaskSchedulerImpl:190 - Adding task set 13.0 with 1 tasks resource profile 0
2025-10-30 23:10:32 INFO  TaskSetManager:190 - Starting task 0.0 in stage 13.0 (TID 6) (localhost,executor driver, partition 0, ANY, 10295 bytes)
2025-10-30 23:10:32 INFO  Executor:190 - Running task 0.0 in stage 13.0 (TID 6)
2025-10-30 23:10:32 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (7.3 KiB) non-empty blocks including 1 (7.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:10:32 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 0 ms
2025-10-30 23:10:32 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (1122.0 B) non-empty blocks including 1 (1122.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:10:32 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 1 ms
2025-10-30 23:10:32 INFO  Executor:190 - Finished task 0.0 in stage 13.0 (TID 6). 6516 bytes result sent to driver
2025-10-30 23:10:32 INFO  TaskSetManager:190 - Finished task 0.0 in stage 13.0 (TID 6) in 81 ms on localhost (executor driver) (1/1)
2025-10-30 23:10:32 INFO  TaskSchedulerImpl:190 - Removed TaskSet 13.0 whose tasks have all completed, from pool
2025-10-30 23:10:32 INFO  DAGScheduler:190 - ShuffleMapStage 13 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 88 ms
2025-10-30 23:10:32 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:10:32 INFO  DAGScheduler:190 - running: HashSet()
2025-10-30 23:10:32 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:10:32 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:10:32 INFO  ShufflePartitionsUtil:190 - For shuffle(5, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:10:32 INFO  HashAggregateExec:190 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-10-30 23:10:32 INFO  SparkContext:190 - Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:10:32 INFO  DAGScheduler:190 - Got job 7 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:10:32 INFO  DAGScheduler:190 - Final stage: ResultStage 17 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:10:32 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 16)
2025-10-30 23:10:32 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:10:32 INFO  DAGScheduler:190 - Submitting ResultStage 17 (MapPartitionsRDD[33] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:10:32 INFO  MemoryStore:190 - Block broadcast_7 stored as values in memory (estimated size 51.1 KiB, free 434.2 MiB)
2025-10-30 23:10:32 INFO  MemoryStore:190 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 21.8 KiB, free 434.2 MiB)
2025-10-30 23:10:32 INFO  SparkContext:190 - Created broadcast 7 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:10:32 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[33] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:10:32 INFO  TaskSchedulerImpl:190 - Adding task set 17.0 with 1 tasks resource profile 0
2025-10-30 23:10:32 INFO  TaskSetManager:190 - Starting task 0.0 in stage 17.0 (TID 7) (localhost,executor driver, partition 0, ANY, 9808 bytes)
2025-10-30 23:10:32 INFO  Executor:190 - Running task 0.0 in stage 17.0 (TID 7)
2025-10-30 23:10:32 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (1168.0 B) non-empty blocks including 1 (1168.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:10:32 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 1 ms
2025-10-30 23:10:32 INFO  Executor:190 - Finished task 0.0 in stage 17.0 (TID 7). 8353 bytes result sent to driver
2025-10-30 23:10:32 INFO  TaskSetManager:190 - Finished task 0.0 in stage 17.0 (TID 7) in 25 ms on localhost (executor driver) (1/1)
2025-10-30 23:10:32 INFO  TaskSchedulerImpl:190 - Removed TaskSet 17.0 whose tasks have all completed, from pool
2025-10-30 23:10:32 INFO  DAGScheduler:190 - ResultStage 17 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 42 ms
2025-10-30 23:10:32 INFO  DAGScheduler:190 - Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
2025-10-30 23:10:32 INFO  TaskSchedulerImpl:190 - Canceling stage 17
2025-10-30 23:10:32 INFO  TaskSchedulerImpl:190 - Killing all running tasks in stage 17: Stage finished
2025-10-30 23:10:32 INFO  DAGScheduler:190 - Job 7 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 48.0983 ms
2025-10-30 23:11:03 INFO  SparkContext:184 - Invoking stop() from shutdown hook
2025-10-30 23:11:03 INFO  SparkContext:190 - SparkContext is stopping with exitCode 0 from run at Executors.java:572.
2025-10-30 23:11:03 INFO  Server:479 - Stopped Server@104c717b{STOPPING}[11.0.24,sto=30000]
2025-10-30 23:11:03 INFO  Server:135 - Shutdown Server@104c717b{STOPPING}[11.0.24,sto=30000]
2025-10-30 23:11:03 INFO  AbstractConnector:431 - Stopped Spark@27ee1595{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-10-30 23:11:03 INFO  SparkUI:190 - Stopped Spark web UI at http://127.0.0.1:4040
2025-10-30 23:11:03 INFO  MapOutputTrackerMasterEndpoint:184 - MapOutputTrackerMasterEndpoint stopped!
2025-10-30 23:11:03 INFO  MemoryStore:184 - MemoryStore cleared
2025-10-30 23:11:03 INFO  BlockManager:184 - BlockManager stopped
2025-10-30 23:11:04 INFO  BlockManagerMaster:184 - BlockManagerMaster stopped
2025-10-30 23:11:04 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:184 - OutputCommitCoordinator stopped!
2025-10-30 23:11:04 WARN  SparkEnv:258 - Exception while deleting Spark temp dir: C:\Users\user\AppData\Local\Temp\spark-a72035ab-90d8-412b-8144-a54ea0ed344f\userFiles-8d7775d9-534b-42f2-89d6-db4259f1b919
java.io.IOException: Failed to delete: C:\Users\user\AppData\Local\Temp\spark-a72035ab-90d8-412b-8144-a54ea0ed344f\userFiles-8d7775d9-534b-42f2-89d6-db4259f1b919\postgresql-42.7.3.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:155) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:131) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2395) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2297) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at scala.util.Try$.apply(Try.scala:217) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:1570) [?:?]
2025-10-30 23:11:04 INFO  SparkContext:184 - Successfully stopped SparkContext
2025-10-30 23:11:04 INFO  ShutdownHookManager:184 - Shutdown hook called
2025-10-30 23:11:04 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-cd0c525c-ad91-478f-8fbf-abfd6aaf2aa2
2025-10-30 23:11:04 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-a72035ab-90d8-412b-8144-a54ea0ed344f\userFiles-8d7775d9-534b-42f2-89d6-db4259f1b919
2025-10-30 23:11:04 ERROR ShutdownHookManager:278 - Exception while deleting Spark temp dir: C:\Users\user\AppData\Local\Temp\spark-a72035ab-90d8-412b-8144-a54ea0ed344f\userFiles-8d7775d9-534b-42f2-89d6-db4259f1b919
java.io.IOException: Failed to delete: C:\Users\user\AppData\Local\Temp\spark-a72035ab-90d8-412b-8144-a54ea0ed344f\userFiles-8d7775d9-534b-42f2-89d6-db4259f1b919\postgresql-42.7.3.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:155) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:70) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:67) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:67) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at scala.util.Try$.apply(Try.scala:217) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:1570) [?:?]
2025-10-30 23:11:04 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\artifacts-1f787232-a1f8-4334-993a-94aeae1b82d4
2025-10-30 23:11:04 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-a72035ab-90d8-412b-8144-a54ea0ed344f
2025-10-30 23:11:04 ERROR ShutdownHookManager:278 - Exception while deleting Spark temp dir: C:\Users\user\AppData\Local\Temp\spark-a72035ab-90d8-412b-8144-a54ea0ed344f
java.io.IOException: Failed to delete: C:\Users\user\AppData\Local\Temp\spark-a72035ab-90d8-412b-8144-a54ea0ed344f\userFiles-8d7775d9-534b-42f2-89d6-db4259f1b919\postgresql-42.7.3.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:155) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:70) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:67) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:67) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at scala.util.Try$.apply(Try.scala:217) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:1570) [?:?]
2025-10-30 23:11:04 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-a72035ab-90d8-412b-8144-a54ea0ed344f\pyspark-621803f8-a285-4eb7-ad27-d795dc36f970
2025-10-30 23:11:30 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-10-30 23:11:30 INFO  SparkContext:190 - Running Spark version 4.0.1
2025-10-30 23:11:30 INFO  SparkContext:190 - OS info Windows 11, 10.0, amd64
2025-10-30 23:11:30 INFO  SparkContext:190 - Java version 22.0.2
2025-10-30 23:11:30 INFO  ResourceUtils:184 - ==============================================================
2025-10-30 23:11:30 INFO  ResourceUtils:184 - No custom resources configured for spark.driver.
2025-10-30 23:11:30 INFO  ResourceUtils:184 - ==============================================================
2025-10-30 23:11:30 INFO  SparkContext:190 - Submitted application: LocalConnection
2025-10-30 23:11:30 INFO  ResourceProfile:190 - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-10-30 23:11:30 INFO  ResourceProfile:190 - Limiting resource is cpu
2025-10-30 23:11:30 INFO  ResourceProfileManager:190 - Added ResourceProfile id: 0
2025-10-30 23:11:30 INFO  SecurityManager:190 - Changing view acls to: user
2025-10-30 23:11:30 INFO  SecurityManager:190 - Changing modify acls to: user
2025-10-30 23:11:30 INFO  SecurityManager:190 - Changing view acls groups to: user
2025-10-30 23:11:30 INFO  SecurityManager:190 - Changing modify acls groups to: user
2025-10-30 23:11:30 INFO  SecurityManager:190 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: user groups with view permissions: EMPTY; users with modify permissions: user; groups with modify permissions: EMPTY; RPC SSL disabled
2025-10-30 23:11:31 INFO  Utils:190 - Successfully started service 'sparkDriver' on port 50398.
2025-10-30 23:11:31 INFO  SparkEnv:190 - Registering MapOutputTracker
2025-10-30 23:11:31 INFO  SparkEnv:190 - Registering BlockManagerMaster
2025-10-30 23:11:31 INFO  BlockManagerMasterEndpoint:190 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-10-30 23:11:31 INFO  BlockManagerMasterEndpoint:184 - BlockManagerMasterEndpoint up
2025-10-30 23:11:31 INFO  SparkEnv:190 - Registering BlockManagerMasterHeartbeat
2025-10-30 23:11:31 INFO  DiskBlockManager:190 - Created local directory at C:\Users\user\AppData\Local\Temp\blockmgr-1dc1c1dd-f79d-4917-8671-923bcde06c6b
2025-10-30 23:11:31 INFO  SparkEnv:190 - Registering OutputCommitCoordinator
2025-10-30 23:11:31 INFO  JettyUtils:190 - Start Jetty 0.0.0.0:4040 for SparkUI
2025-10-30 23:11:31 INFO  Server:384 - jetty-11.0.24; built: 2024-08-26T18:11:22.448Z; git: 5dfc59a691b748796f922208956bd1f2794bcd16; jvm 22.0.2+9-70
2025-10-30 23:11:31 INFO  Server:439 - Started Server@6e440710{STARTING}[11.0.24,sto=30000] @2442ms
2025-10-30 23:11:31 INFO  AbstractConnector:376 - Started ServerConnector@27ee1595{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-10-30 23:11:31 INFO  Utils:190 - Successfully started service 'SparkUI' on port 4040.
2025-10-30 23:11:31 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4d85cc96{/,null,AVAILABLE,@Spark}
2025-10-30 23:11:31 INFO  SparkContext:190 - Added JAR C:\Users\user\AppData\Roaming\JetBrains\DataGrip2025.2\jdbc-drivers\PostgreSQL\42.7.3\org\postgresql\postgresql\42.7.3\postgresql-42.7.3.jar at spark://127.0.0.1:50398/jars/postgresql-42.7.3.jar with timestamp 1761855090802
2025-10-30 23:11:31 INFO  SecurityManager:190 - Changing view acls to: user
2025-10-30 23:11:31 INFO  SecurityManager:190 - Changing modify acls to: user
2025-10-30 23:11:31 INFO  SecurityManager:190 - Changing view acls groups to: user
2025-10-30 23:11:31 INFO  SecurityManager:190 - Changing modify acls groups to: user
2025-10-30 23:11:31 INFO  SecurityManager:190 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: user groups with view permissions: EMPTY; users with modify permissions: user; groups with modify permissions: EMPTY; RPC SSL disabled
2025-10-30 23:11:31 INFO  Executor:190 - Starting executor ID driver on host localhost
2025-10-30 23:11:31 INFO  Executor:190 - OS info Windows 11, 10.0, amd64
2025-10-30 23:11:31 INFO  Executor:190 - Java version 22.0.2
2025-10-30 23:11:31 INFO  Executor:190 - Starting executor with user classpath (userClassPathFirst = false): ''
2025-10-30 23:11:31 INFO  Executor:190 - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@166a24b8 for default.
2025-10-30 23:11:31 INFO  Executor:190 - Fetching spark://127.0.0.1:50398/jars/postgresql-42.7.3.jar with timestamp 1761855090802
2025-10-30 23:11:31 INFO  TransportClientFactory:155 - Successfully created connection to /127.0.0.1:50398 after 21 ms (0 ms spent in bootstraps)
2025-10-30 23:11:31 INFO  Utils:190 - Fetching spark://127.0.0.1:50398/jars/postgresql-42.7.3.jar to C:\Users\user\AppData\Local\Temp\spark-8482f445-8bb2-41f2-9b89-db1155e74f89\userFiles-68e4a4d5-3788-4230-8e96-e3a98fe88666\fetchFileTemp5670981068981079001.tmp
2025-10-30 23:11:31 INFO  Executor:190 - Adding file:/C:/Users/user/AppData/Local/Temp/spark-8482f445-8bb2-41f2-9b89-db1155e74f89/userFiles-68e4a4d5-3788-4230-8e96-e3a98fe88666/postgresql-42.7.3.jar to class loader default
2025-10-30 23:11:31 INFO  Utils:190 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50403.
2025-10-30 23:11:31 INFO  NettyBlockTransferService:155 - Server created on 127.0.0.1:50403
2025-10-30 23:11:31 INFO  BlockManager:190 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-10-30 23:11:31 INFO  BlockManagerMaster:190 - Registering BlockManager BlockManagerId(driver, 127.0.0.1, 50403, None)
2025-10-30 23:11:31 INFO  BlockManagerMasterEndpoint:190 - Registering block manager 127.0.0.1:50403 with 434.4 MiB RAM, BlockManagerId(driver, 127.0.0.1, 50403, None)
2025-10-30 23:11:31 INFO  BlockManagerMaster:190 - Registered BlockManager BlockManagerId(driver, 127.0.0.1, 50403, None)
2025-10-30 23:11:31 INFO  BlockManager:190 - Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 50403, None)
2025-10-30 23:11:32 INFO  ContextHandler:1123 - Stopped o.s.j.s.ServletContextHandler@4d85cc96{/,null,STOPPED,@Spark}
2025-10-30 23:11:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@38be1d07{/jobs,null,AVAILABLE,@Spark}
2025-10-30 23:11:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@7a10b657{/jobs/json,null,AVAILABLE,@Spark}
2025-10-30 23:11:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@7b6f40c9{/jobs/job,null,AVAILABLE,@Spark}
2025-10-30 23:11:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@6ba570b2{/jobs/job/json,null,AVAILABLE,@Spark}
2025-10-30 23:11:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@50aac6a7{/stages,null,AVAILABLE,@Spark}
2025-10-30 23:11:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4213e9b4{/stages/json,null,AVAILABLE,@Spark}
2025-10-30 23:11:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@e6f563{/stages/stage,null,AVAILABLE,@Spark}
2025-10-30 23:11:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4640263b{/stages/stage/json,null,AVAILABLE,@Spark}
2025-10-30 23:11:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@b187db8{/stages/pool,null,AVAILABLE,@Spark}
2025-10-30 23:11:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4e7ae6db{/stages/pool/json,null,AVAILABLE,@Spark}
2025-10-30 23:11:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@2cda16bd{/stages/taskThreadDump,null,AVAILABLE,@Spark}
2025-10-30 23:11:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@5f68b473{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
2025-10-30 23:11:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@7dd3aa33{/storage,null,AVAILABLE,@Spark}
2025-10-30 23:11:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4f65d177{/storage/json,null,AVAILABLE,@Spark}
2025-10-30 23:11:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@2f1d0046{/storage/rdd,null,AVAILABLE,@Spark}
2025-10-30 23:11:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@3a36051e{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-10-30 23:11:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4feef769{/environment,null,AVAILABLE,@Spark}
2025-10-30 23:11:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@529f4db8{/environment/json,null,AVAILABLE,@Spark}
2025-10-30 23:11:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@54325fae{/executors,null,AVAILABLE,@Spark}
2025-10-30 23:11:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@790cfc48{/executors/json,null,AVAILABLE,@Spark}
2025-10-30 23:11:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@2e8c36ab{/executors/threadDump,null,AVAILABLE,@Spark}
2025-10-30 23:11:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@5585d596{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-10-30 23:11:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@5c69dda1{/executors/heapHistogram,null,AVAILABLE,@Spark}
2025-10-30 23:11:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4059e65c{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2025-10-30 23:11:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@3dffc5f9{/static,null,AVAILABLE,@Spark}
2025-10-30 23:11:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@32c55b50{/,null,AVAILABLE,@Spark}
2025-10-30 23:11:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@1def5a12{/api,null,AVAILABLE,@Spark}
2025-10-30 23:11:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@7f4d7e84{/metrics,null,AVAILABLE,@Spark}
2025-10-30 23:11:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@39559c1a{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-10-30 23:11:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@46463af3{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-10-30 23:11:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@12252f59{/metrics/json,null,AVAILABLE,@Spark}
2025-10-30 23:11:34 INFO  SharedState:190 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-10-30 23:11:34 INFO  SharedState:190 - Warehouse path is 'file:/C:/Users/user/DataGripProjects/innowise_trainee/TASKS/task_5/spark-warehouse'.
2025-10-30 23:11:34 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@1549bfeb{/SQL,null,AVAILABLE,@Spark}
2025-10-30 23:11:34 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@6db30844{/SQL/json,null,AVAILABLE,@Spark}
2025-10-30 23:11:34 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@1dca16f7{/SQL/execution,null,AVAILABLE,@Spark}
2025-10-30 23:11:34 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4b8f26a5{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-10-30 23:11:34 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4e70120f{/static/sql,null,AVAILABLE,@Spark}
2025-10-30 23:11:45 INFO  CodeGenerator:190 - Code generated in 151.3501 ms
2025-10-30 23:11:45 INFO  CodeGenerator:190 - Code generated in 151.3644 ms
2025-10-30 23:11:45 INFO  CodeGenerator:190 - Code generated in 151.3645 ms
2025-10-30 23:11:45 INFO  CodeGenerator:190 - Code generated in 151.3233 ms
2025-10-30 23:11:45 INFO  CodeGenerator:190 - Code generated in 151.3369 ms
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Registering RDD 11 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 2
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Got map stage job 0 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 0 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Parents of final stage: List()
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[11] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:11:46 INFO  MemoryStore:190 - MemoryStore started with capacity 434.4 MiB
2025-10-30 23:11:46 INFO  MemoryStore:190 - Block broadcast_0 stored as values in memory (estimated size 15.8 KiB, free 434.4 MiB)
2025-10-30 23:11:46 INFO  MemoryStore:190 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.4 MiB)
2025-10-30 23:11:46 INFO  SparkContext:190 - Created broadcast 0 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[11] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:11:46 INFO  TaskSchedulerImpl:190 - Adding task set 0.0 with 1 tasks resource profile 0
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Registering RDD 10 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 1
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Got map stage job 3 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 1 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Parents of final stage: List()
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 1 (MapPartitionsRDD[10] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:11:46 INFO  MemoryStore:190 - Block broadcast_1 stored as values in memory (estimated size 15.3 KiB, free 434.4 MiB)
2025-10-30 23:11:46 INFO  MemoryStore:190 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 434.4 MiB)
2025-10-30 23:11:46 INFO  SparkContext:190 - Created broadcast 1 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[10] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:11:46 INFO  TaskSchedulerImpl:190 - Adding task set 1.0 with 1 tasks resource profile 0
2025-10-30 23:11:46 INFO  TaskSetManager:190 - Starting task 0.0 in stage 0.0 (TID 0) (localhost,executor driver, partition 0, PROCESS_LOCAL, 9643 bytes)
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Registering RDD 12 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 0
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Got map stage job 1 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 2 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Parents of final stage: List()
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 2 (MapPartitionsRDD[12] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:11:46 INFO  TaskSetManager:190 - Starting task 0.0 in stage 1.0 (TID 1) (localhost,executor driver, partition 0, PROCESS_LOCAL, 9643 bytes)
2025-10-30 23:11:46 INFO  MemoryStore:190 - Block broadcast_2 stored as values in memory (estimated size 15.8 KiB, free 434.3 MiB)
2025-10-30 23:11:46 INFO  MemoryStore:190 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 434.3 MiB)
2025-10-30 23:11:46 INFO  SparkContext:190 - Created broadcast 2 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[12] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:11:46 INFO  TaskSchedulerImpl:190 - Adding task set 2.0 with 1 tasks resource profile 0
2025-10-30 23:11:46 INFO  Executor:190 - Running task 0.0 in stage 1.0 (TID 1)
2025-10-30 23:11:46 INFO  Executor:190 - Running task 0.0 in stage 0.0 (TID 0)
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Registering RDD 13 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 4
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Got map stage job 2 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 3 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Parents of final stage: List()
2025-10-30 23:11:46 INFO  TaskSetManager:190 - Starting task 0.0 in stage 2.0 (TID 2) (localhost,executor driver, partition 0, PROCESS_LOCAL, 9643 bytes)
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 3 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:11:46 INFO  Executor:190 - Running task 0.0 in stage 2.0 (TID 2)
2025-10-30 23:11:46 INFO  MemoryStore:190 - Block broadcast_3 stored as values in memory (estimated size 15.8 KiB, free 434.3 MiB)
2025-10-30 23:11:46 INFO  MemoryStore:190 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.3 MiB)
2025-10-30 23:11:46 INFO  SparkContext:190 - Created broadcast 3 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:11:46 INFO  TaskSchedulerImpl:190 - Adding task set 3.0 with 1 tasks resource profile 0
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Registering RDD 14 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 3
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Got map stage job 4 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 4 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:11:46 INFO  TaskSetManager:190 - Starting task 0.0 in stage 3.0 (TID 3) (localhost,executor driver, partition 0, PROCESS_LOCAL, 9643 bytes)
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Parents of final stage: List()
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 4 (MapPartitionsRDD[14] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:11:46 INFO  Executor:190 - Running task 0.0 in stage 3.0 (TID 3)
2025-10-30 23:11:46 INFO  MemoryStore:190 - Block broadcast_4 stored as values in memory (estimated size 15.8 KiB, free 434.3 MiB)
2025-10-30 23:11:46 INFO  MemoryStore:190 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.3 MiB)
2025-10-30 23:11:46 INFO  SparkContext:190 - Created broadcast 4 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:11:46 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[14] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:11:46 INFO  TaskSchedulerImpl:190 - Adding task set 4.0 with 1 tasks resource profile 0
2025-10-30 23:11:46 INFO  TaskSetManager:190 - Starting task 0.0 in stage 4.0 (TID 4) (localhost,executor driver, partition 0, PROCESS_LOCAL, 9643 bytes)
2025-10-30 23:11:46 INFO  Executor:190 - Running task 0.0 in stage 4.0 (TID 4)
2025-10-30 23:11:46 INFO  CodeGenerator:190 - Code generated in 26.9263 ms
2025-10-30 23:11:46 INFO  CodeGenerator:190 - Code generated in 27.61 ms
2025-10-30 23:11:46 INFO  CodeGenerator:190 - Code generated in 14.8981 ms
2025-10-30 23:11:46 INFO  CodeGenerator:190 - Code generated in 43.7228 ms
2025-10-30 23:11:46 INFO  CodeGenerator:190 - Code generated in 13.4583 ms
2025-10-30 23:11:46 INFO  CodeGenerator:190 - Code generated in 42.7497 ms
2025-10-30 23:11:46 INFO  CodeGenerator:190 - Code generated in 42.6431 ms
2025-10-30 23:11:46 INFO  SecurityManager:190 - Changing view acls to: user
2025-10-30 23:11:46 INFO  SecurityManager:190 - Changing modify acls to: user
2025-10-30 23:11:46 INFO  SecurityManager:190 - Changing view acls groups to: user
2025-10-30 23:11:46 INFO  SecurityManager:190 - Changing modify acls groups to: user
2025-10-30 23:11:46 INFO  SecurityManager:190 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: user groups with view permissions: EMPTY; users with modify permissions: user; groups with modify permissions: EMPTY; RPC SSL disabled
2025-10-30 23:11:46 INFO  JDBCRDD:184 - closed connection
2025-10-30 23:11:46 INFO  JDBCRDD:184 - closed connection
2025-10-30 23:11:47 INFO  JDBCRDD:184 - closed connection
2025-10-30 23:11:47 INFO  Executor:190 - Finished task 0.0 in stage 1.0 (TID 1). 2150 bytes result sent to driver
2025-10-30 23:11:47 INFO  Executor:190 - Finished task 0.0 in stage 3.0 (TID 3). 2150 bytes result sent to driver
2025-10-30 23:11:47 INFO  JDBCRDD:184 - closed connection
2025-10-30 23:11:47 INFO  TaskSetManager:190 - Finished task 0.0 in stage 1.0 (TID 1) in 976 ms on localhost (executor driver) (1/1)
2025-10-30 23:11:47 INFO  TaskSchedulerImpl:190 - Removed TaskSet 1.0 whose tasks have all completed, from pool
2025-10-30 23:11:47 INFO  TaskSetManager:190 - Finished task 0.0 in stage 3.0 (TID 3) in 979 ms on localhost (executor driver) (1/1)
2025-10-30 23:11:47 INFO  TaskSchedulerImpl:190 - Removed TaskSet 3.0 whose tasks have all completed, from pool
2025-10-30 23:11:47 INFO  JDBCRDD:184 - closed connection
2025-10-30 23:11:47 INFO  DAGScheduler:190 - ShuffleMapStage 1 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 1036 ms
2025-10-30 23:11:47 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:11:47 INFO  DAGScheduler:190 - running: HashSet(ShuffleMapStage 0, ShuffleMapStage 2, ShuffleMapStage 3, ShuffleMapStage 4)
2025-10-30 23:11:47 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:11:47 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:11:47 INFO  DAGScheduler:190 - ShuffleMapStage 3 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 1045 ms
2025-10-30 23:11:47 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:11:47 INFO  DAGScheduler:190 - running: HashSet(ShuffleMapStage 0, ShuffleMapStage 2, ShuffleMapStage 4)
2025-10-30 23:11:47 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:11:47 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:11:47 INFO  ShufflePartitionsUtil:190 - For shuffle(4, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:11:47 INFO  Executor:190 - Finished task 0.0 in stage 4.0 (TID 4). 2107 bytes result sent to driver
2025-10-30 23:11:47 INFO  Executor:190 - Finished task 0.0 in stage 2.0 (TID 2). 2107 bytes result sent to driver
2025-10-30 23:11:47 INFO  TaskSetManager:190 - Finished task 0.0 in stage 2.0 (TID 2) in 1416 ms on localhost (executor driver) (1/1)
2025-10-30 23:11:47 INFO  DAGScheduler:190 - ShuffleMapStage 2 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 1429 ms
2025-10-30 23:11:47 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:11:47 INFO  DAGScheduler:190 - running: HashSet(ShuffleMapStage 0, ShuffleMapStage 4)
2025-10-30 23:11:47 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:11:47 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:11:47 INFO  TaskSchedulerImpl:190 - Removed TaskSet 2.0 whose tasks have all completed, from pool
2025-10-30 23:11:47 INFO  TaskSetManager:190 - Finished task 0.0 in stage 4.0 (TID 4) in 1402 ms on localhost (executor driver) (1/1)
2025-10-30 23:11:47 INFO  TaskSchedulerImpl:190 - Removed TaskSet 4.0 whose tasks have all completed, from pool
2025-10-30 23:11:47 INFO  DAGScheduler:190 - ShuffleMapStage 4 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 1412 ms
2025-10-30 23:11:47 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:11:47 INFO  DAGScheduler:190 - running: HashSet(ShuffleMapStage 0)
2025-10-30 23:11:47 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:11:47 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:11:47 INFO  ShufflePartitionsUtil:190 - For shuffle(0, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:11:47 INFO  SparkContext:190 - Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:11:47 INFO  DAGScheduler:190 - Got job 5 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:11:47 INFO  DAGScheduler:190 - Final stage: ResultStage 6 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:11:47 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 5)
2025-10-30 23:11:47 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:11:47 INFO  DAGScheduler:190 - Submitting ResultStage 6 (MapPartitionsRDD[16] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:11:47 INFO  MemoryStore:190 - Block broadcast_5 stored as values in memory (estimated size 8.6 KiB, free 434.3 MiB)
2025-10-30 23:11:47 INFO  MemoryStore:190 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 434.3 MiB)
2025-10-30 23:11:47 INFO  SparkContext:190 - Created broadcast 5 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:11:47 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[16] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:11:47 INFO  TaskSchedulerImpl:190 - Adding task set 6.0 with 1 tasks resource profile 0
2025-10-30 23:11:47 INFO  SparkContext:190 - Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:11:47 INFO  ShufflePartitionsUtil:190 - For shuffle(3, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:11:47 INFO  DAGScheduler:190 - Got job 6 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:11:47 INFO  DAGScheduler:190 - Final stage: ResultStage 8 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:11:47 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 7)
2025-10-30 23:11:47 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:11:47 INFO  DAGScheduler:190 - Submitting ResultStage 8 (MapPartitionsRDD[18] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:11:47 INFO  MemoryStore:190 - Block broadcast_6 stored as values in memory (estimated size 8.6 KiB, free 434.3 MiB)
2025-10-30 23:11:47 INFO  TaskSetManager:190 - Starting task 0.0 in stage 6.0 (TID 5) (localhost,executor driver, partition 0, ANY, 9827 bytes)
2025-10-30 23:11:47 INFO  MemoryStore:190 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 434.3 MiB)
2025-10-30 23:11:47 INFO  Executor:190 - Running task 0.0 in stage 6.0 (TID 5)
2025-10-30 23:11:47 INFO  SparkContext:190 - Created broadcast 6 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:11:47 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[18] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:11:47 INFO  TaskSchedulerImpl:190 - Adding task set 8.0 with 1 tasks resource profile 0
2025-10-30 23:11:47 INFO  TaskSetManager:190 - Starting task 0.0 in stage 8.0 (TID 6) (localhost,executor driver, partition 0, ANY, 9827 bytes)
2025-10-30 23:11:47 INFO  Executor:190 - Running task 0.0 in stage 8.0 (TID 6)
2025-10-30 23:11:47 INFO  SparkContext:190 - Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:11:47 INFO  DAGScheduler:190 - Got job 7 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:11:47 INFO  DAGScheduler:190 - Final stage: ResultStage 10 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:11:47 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 9)
2025-10-30 23:11:47 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:11:47 INFO  Executor:190 - Finished task 0.0 in stage 0.0 (TID 0). 2107 bytes result sent to driver
2025-10-30 23:11:47 INFO  DAGScheduler:190 - Submitting ResultStage 10 (MapPartitionsRDD[20] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:11:47 INFO  TaskSetManager:190 - Finished task 0.0 in stage 0.0 (TID 0) in 1718 ms on localhost (executor driver) (1/1)
2025-10-30 23:11:47 INFO  TaskSchedulerImpl:190 - Removed TaskSet 0.0 whose tasks have all completed, from pool
2025-10-30 23:11:47 INFO  MemoryStore:190 - Block broadcast_7 stored as values in memory (estimated size 8.6 KiB, free 434.2 MiB)
2025-10-30 23:11:47 INFO  MemoryStore:190 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 434.2 MiB)
2025-10-30 23:11:47 INFO  SparkContext:190 - Created broadcast 7 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:11:47 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[20] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:11:47 INFO  TaskSchedulerImpl:190 - Adding task set 10.0 with 1 tasks resource profile 0
2025-10-30 23:11:47 INFO  TaskSetManager:190 - Starting task 0.0 in stage 10.0 (TID 7) (localhost,executor driver, partition 0, ANY, 9827 bytes)
2025-10-30 23:11:47 INFO  DAGScheduler:190 - ShuffleMapStage 0 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 1911 ms
2025-10-30 23:11:47 INFO  Executor:190 - Running task 0.0 in stage 10.0 (TID 7)
2025-10-30 23:11:47 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:11:47 INFO  DAGScheduler:190 - running: HashSet(ResultStage 6, ResultStage 8, ResultStage 10)
2025-10-30 23:11:47 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:11:47 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:11:48 INFO  ShufflePartitionsUtil:190 - For shuffle(2, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:11:48 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (7.3 KiB) non-empty blocks including 1 (7.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:11:48 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (153.6 KiB) non-empty blocks including 1 (153.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:11:48 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (43.1 KiB) non-empty blocks including 1 (43.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:11:48 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 111 ms
2025-10-30 23:11:48 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 76 ms
2025-10-30 23:11:48 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 111 ms
2025-10-30 23:11:48 INFO  SparkContext:190 - Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:11:48 INFO  DAGScheduler:190 - Got job 8 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:11:48 INFO  DAGScheduler:190 - Final stage: ResultStage 12 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:11:48 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 11)
2025-10-30 23:11:48 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:11:48 INFO  DAGScheduler:190 - Submitting ResultStage 12 (MapPartitionsRDD[22] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:11:48 INFO  MemoryStore:190 - Block broadcast_8 stored as values in memory (estimated size 8.6 KiB, free 434.3 MiB)
2025-10-30 23:11:48 INFO  MemoryStore:190 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 434.3 MiB)
2025-10-30 23:11:48 INFO  SparkContext:190 - Created broadcast 8 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:11:48 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[22] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:11:48 INFO  TaskSchedulerImpl:190 - Adding task set 12.0 with 1 tasks resource profile 0
2025-10-30 23:11:48 INFO  TaskSetManager:190 - Starting task 0.0 in stage 12.0 (TID 8) (localhost,executor driver, partition 0, ANY, 9827 bytes)
2025-10-30 23:11:48 INFO  Executor:190 - Running task 0.0 in stage 12.0 (TID 8)
2025-10-30 23:11:48 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (169.6 KiB) non-empty blocks including 1 (169.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:11:48 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 3 ms
2025-10-30 23:11:48 INFO  Executor:190 - Finished task 0.0 in stage 6.0 (TID 5). 10215 bytes result sent to driver
2025-10-30 23:11:48 INFO  TaskSetManager:190 - Finished task 0.0 in stage 6.0 (TID 5) in 326 ms on localhost (executor driver) (1/1)
2025-10-30 23:11:48 INFO  TaskSchedulerImpl:190 - Removed TaskSet 6.0 whose tasks have all completed, from pool
2025-10-30 23:11:48 INFO  DAGScheduler:190 - ResultStage 6 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 375 ms
2025-10-30 23:11:48 INFO  Executor:190 - Finished task 0.0 in stage 10.0 (TID 7). 33012 bytes result sent to driver
2025-10-30 23:11:48 INFO  DAGScheduler:190 - Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2025-10-30 23:11:48 INFO  TaskSetManager:190 - Finished task 0.0 in stage 10.0 (TID 7) in 199 ms on localhost (executor driver) (1/1)
2025-10-30 23:11:48 INFO  TaskSchedulerImpl:190 - Removed TaskSet 10.0 whose tasks have all completed, from pool
2025-10-30 23:11:48 INFO  TaskSchedulerImpl:190 - Canceling stage 6
2025-10-30 23:11:48 INFO  TaskSchedulerImpl:190 - Killing all running tasks in stage 6: Stage finished
2025-10-30 23:11:48 INFO  DAGScheduler:190 - ResultStage 10 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 222 ms
2025-10-30 23:11:48 INFO  DAGScheduler:190 - Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
2025-10-30 23:11:48 INFO  TaskSchedulerImpl:190 - Canceling stage 10
2025-10-30 23:11:48 INFO  TaskSchedulerImpl:190 - Killing all running tasks in stage 10: Stage finished
2025-10-30 23:11:48 INFO  DAGScheduler:190 - Job 7 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 234.8234 ms
2025-10-30 23:11:48 INFO  DAGScheduler:190 - Job 5 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 428.9468 ms
2025-10-30 23:11:48 INFO  Executor:190 - Finished task 0.0 in stage 12.0 (TID 8). 146442 bytes result sent to driver
2025-10-30 23:11:48 INFO  Executor:190 - Finished task 0.0 in stage 8.0 (TID 6). 128271 bytes result sent to driver
2025-10-30 23:11:48 INFO  TaskSetManager:190 - Finished task 0.0 in stage 12.0 (TID 8) in 96 ms on localhost (executor driver) (1/1)
2025-10-30 23:11:48 INFO  TaskSchedulerImpl:190 - Removed TaskSet 12.0 whose tasks have all completed, from pool
2025-10-30 23:11:48 INFO  TaskSetManager:190 - Finished task 0.0 in stage 8.0 (TID 6) in 357 ms on localhost (executor driver) (1/1)
2025-10-30 23:11:48 INFO  TaskSchedulerImpl:190 - Removed TaskSet 8.0 whose tasks have all completed, from pool
2025-10-30 23:11:48 INFO  DAGScheduler:190 - ResultStage 12 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 113 ms
2025-10-30 23:11:48 INFO  DAGScheduler:190 - Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
2025-10-30 23:11:48 INFO  TaskSchedulerImpl:190 - Canceling stage 12
2025-10-30 23:11:48 INFO  TaskSchedulerImpl:190 - Killing all running tasks in stage 12: Stage finished
2025-10-30 23:11:48 INFO  DAGScheduler:190 - ResultStage 8 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 388 ms
2025-10-30 23:11:48 INFO  DAGScheduler:190 - Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
2025-10-30 23:11:48 INFO  TaskSchedulerImpl:190 - Canceling stage 8
2025-10-30 23:11:48 INFO  TaskSchedulerImpl:190 - Killing all running tasks in stage 8: Stage finished
2025-10-30 23:11:48 INFO  DAGScheduler:190 - Job 8 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 121.6012 ms
2025-10-30 23:11:48 INFO  DAGScheduler:190 - Job 6 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 401.7505 ms
2025-10-30 23:11:48 INFO  CodeGenerator:190 - Code generated in 19.5519 ms
2025-10-30 23:11:48 INFO  CodeGenerator:190 - Code generated in 21.5608 ms
2025-10-30 23:11:48 INFO  MemoryStore:190 - Block broadcast_9 stored as values in memory (estimated size 1024.1 KiB, free 433.3 MiB)
2025-10-30 23:11:48 INFO  MemoryStore:190 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 11.1 KiB, free 433.3 MiB)
2025-10-30 23:11:48 INFO  SparkContext:190 - Created broadcast 9 from $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:11:48 INFO  MemoryStore:190 - Block broadcast_10 stored as values in memory (estimated size 1031.8 KiB, free 432.3 MiB)
2025-10-30 23:11:48 INFO  MemoryStore:190 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 50.6 KiB, free 432.3 MiB)
2025-10-30 23:11:48 INFO  SparkContext:190 - Created broadcast 10 from $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:11:48 INFO  MemoryStore:190 - Block broadcast_11 stored as values in memory (estimated size 1059.8 KiB, free 431.2 MiB)
2025-10-30 23:11:48 INFO  MemoryStore:190 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 206.1 KiB, free 431.0 MiB)
2025-10-30 23:11:48 INFO  SparkContext:190 - Created broadcast 11 from $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:11:48 INFO  MemoryStore:190 - Block broadcast_12 stored as values in memory (estimated size 1149.4 KiB, free 429.9 MiB)
2025-10-30 23:11:48 INFO  MemoryStore:190 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 186.3 KiB, free 429.7 MiB)
2025-10-30 23:11:48 INFO  SparkContext:190 - Created broadcast 12 from $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:11:48 INFO  ShufflePartitionsUtil:190 - For shuffle(1, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:11:48 INFO  CodeGenerator:190 - Code generated in 118.7258 ms
2025-10-30 23:11:48 INFO  DAGScheduler:190 - Registering RDD 25 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 5
2025-10-30 23:11:48 INFO  DAGScheduler:190 - Got map stage job 9 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:11:48 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 14 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:11:48 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 13)
2025-10-30 23:11:48 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:11:48 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 14 (MapPartitionsRDD[25] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:11:48 INFO  MemoryStore:190 - Block broadcast_13 stored as values in memory (estimated size 80.0 KiB, free 429.6 MiB)
2025-10-30 23:11:48 INFO  MemoryStore:190 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 31.3 KiB, free 429.6 MiB)
2025-10-30 23:11:48 INFO  SparkContext:190 - Created broadcast 13 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:11:48 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[25] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:11:48 INFO  TaskSchedulerImpl:190 - Adding task set 14.0 with 1 tasks resource profile 0
2025-10-30 23:11:48 INFO  TaskSetManager:190 - Starting task 0.0 in stage 14.0 (TID 9) (localhost,executor driver, partition 0, ANY, 9816 bytes)
2025-10-30 23:11:48 INFO  Executor:190 - Running task 0.0 in stage 14.0 (TID 9)
2025-10-30 23:11:48 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (1122.0 B) non-empty blocks including 1 (1122.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:11:48 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 1 ms
2025-10-30 23:11:48 INFO  CodeGenerator:190 - Code generated in 68.954 ms
2025-10-30 23:11:48 INFO  CodeGenerator:190 - Code generated in 15.6753 ms
2025-10-30 23:11:48 INFO  CodeGenerator:190 - Code generated in 7.1286 ms
2025-10-30 23:11:48 INFO  CodeGenerator:190 - Code generated in 7.5356 ms
2025-10-30 23:11:48 INFO  CodeGenerator:190 - Code generated in 6.7672 ms
2025-10-30 23:11:49 INFO  Executor:190 - Finished task 0.0 in stage 14.0 (TID 9). 10875 bytes result sent to driver
2025-10-30 23:11:49 INFO  TaskSetManager:190 - Finished task 0.0 in stage 14.0 (TID 9) in 306 ms on localhost (executor driver) (1/1)
2025-10-30 23:11:49 INFO  TaskSchedulerImpl:190 - Removed TaskSet 14.0 whose tasks have all completed, from pool
2025-10-30 23:11:49 INFO  DAGScheduler:190 - ShuffleMapStage 14 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 324 ms
2025-10-30 23:11:49 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:11:49 INFO  DAGScheduler:190 - running: HashSet()
2025-10-30 23:11:49 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:11:49 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:11:49 INFO  ShufflePartitionsUtil:190 - For shuffle(5, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:11:49 INFO  CodeGenerator:190 - Code generated in 40.8962 ms
2025-10-30 23:11:49 INFO  HashAggregateExec:190 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-10-30 23:11:49 INFO  CodeGenerator:190 - Code generated in 30.22 ms
2025-10-30 23:11:49 INFO  SparkContext:190 - Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:11:49 INFO  DAGScheduler:190 - Got job 10 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:11:49 INFO  DAGScheduler:190 - Final stage: ResultStage 17 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:11:49 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 16)
2025-10-30 23:11:49 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:11:49 INFO  DAGScheduler:190 - Submitting ResultStage 17 (MapPartitionsRDD[29] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:11:49 INFO  MemoryStore:190 - Block broadcast_14 stored as values in memory (estimated size 80.0 KiB, free 429.6 MiB)
2025-10-30 23:11:49 INFO  MemoryStore:190 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 31.0 KiB, free 429.6 MiB)
2025-10-30 23:11:49 INFO  SparkContext:190 - Created broadcast 14 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:11:49 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[29] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:11:49 INFO  TaskSchedulerImpl:190 - Adding task set 17.0 with 1 tasks resource profile 0
2025-10-30 23:11:49 INFO  TaskSetManager:190 - Starting task 0.0 in stage 17.0 (TID 10) (localhost,executor driver, partition 0, ANY, 9808 bytes)
2025-10-30 23:11:49 INFO  Executor:190 - Running task 0.0 in stage 17.0 (TID 10)
2025-10-30 23:11:49 INFO  CodeGenerator:190 - Code generated in 8.3894 ms
2025-10-30 23:11:49 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (1296.0 B) non-empty blocks including 1 (1296.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:11:49 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 1 ms
2025-10-30 23:11:49 INFO  CodeGenerator:190 - Code generated in 25.6277 ms
2025-10-30 23:11:49 INFO  Executor:190 - Finished task 0.0 in stage 17.0 (TID 10). 11916 bytes result sent to driver
2025-10-30 23:11:49 INFO  TaskSetManager:190 - Finished task 0.0 in stage 17.0 (TID 10) in 113 ms on localhost (executor driver) (1/1)
2025-10-30 23:11:49 INFO  TaskSchedulerImpl:190 - Removed TaskSet 17.0 whose tasks have all completed, from pool
2025-10-30 23:11:49 INFO  DAGScheduler:190 - ResultStage 17 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 130 ms
2025-10-30 23:11:49 INFO  DAGScheduler:190 - Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
2025-10-30 23:11:49 INFO  TaskSchedulerImpl:190 - Canceling stage 17
2025-10-30 23:11:49 INFO  TaskSchedulerImpl:190 - Killing all running tasks in stage 17: Stage finished
2025-10-30 23:11:49 INFO  DAGScheduler:190 - Job 10 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 143.4625 ms
2025-10-30 23:11:49 INFO  CodeGenerator:190 - Code generated in 10.1001 ms
2025-10-30 23:11:49 INFO  CodeGenerator:190 - Code generated in 12.1296 ms
2025-10-30 23:11:59 INFO  DAGScheduler:190 - Registering RDD 35 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 7
2025-10-30 23:11:59 INFO  DAGScheduler:190 - Got map stage job 12 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:11:59 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 18 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:11:59 INFO  DAGScheduler:190 - Parents of final stage: List()
2025-10-30 23:11:59 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:11:59 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 18 (MapPartitionsRDD[35] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:11:59 INFO  MemoryStore:190 - Block broadcast_15 stored as values in memory (estimated size 15.8 KiB, free 429.5 MiB)
2025-10-30 23:11:59 INFO  MemoryStore:190 - Block broadcast_15_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 429.5 MiB)
2025-10-30 23:11:59 INFO  SparkContext:190 - Created broadcast 15 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:11:59 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[35] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:11:59 INFO  TaskSchedulerImpl:190 - Adding task set 18.0 with 1 tasks resource profile 0
2025-10-30 23:11:59 INFO  DAGScheduler:190 - Registering RDD 34 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 6
2025-10-30 23:11:59 INFO  DAGScheduler:190 - Got map stage job 11 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:11:59 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 19 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:11:59 INFO  DAGScheduler:190 - Parents of final stage: List()
2025-10-30 23:11:59 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:11:59 INFO  TaskSetManager:190 - Starting task 0.0 in stage 18.0 (TID 11) (localhost,executor driver, partition 0, PROCESS_LOCAL, 9643 bytes)
2025-10-30 23:11:59 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 19 (MapPartitionsRDD[34] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:11:59 INFO  Executor:190 - Running task 0.0 in stage 18.0 (TID 11)
2025-10-30 23:11:59 INFO  MemoryStore:190 - Block broadcast_16 stored as values in memory (estimated size 15.3 KiB, free 429.5 MiB)
2025-10-30 23:11:59 INFO  MemoryStore:190 - Block broadcast_16_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 429.5 MiB)
2025-10-30 23:11:59 INFO  SparkContext:190 - Created broadcast 16 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:11:59 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[34] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:11:59 INFO  TaskSchedulerImpl:190 - Adding task set 19.0 with 1 tasks resource profile 0
2025-10-30 23:11:59 INFO  TaskSetManager:190 - Starting task 0.0 in stage 19.0 (TID 12) (localhost,executor driver, partition 0, PROCESS_LOCAL, 9643 bytes)
2025-10-30 23:11:59 INFO  Executor:190 - Running task 0.0 in stage 19.0 (TID 12)
2025-10-30 23:11:59 INFO  JDBCRDD:184 - closed connection
2025-10-30 23:11:59 INFO  JDBCRDD:184 - closed connection
2025-10-30 23:11:59 INFO  Executor:190 - Finished task 0.0 in stage 18.0 (TID 11). 2064 bytes result sent to driver
2025-10-30 23:11:59 INFO  TaskSetManager:190 - Finished task 0.0 in stage 18.0 (TID 11) in 302 ms on localhost (executor driver) (1/1)
2025-10-30 23:11:59 INFO  TaskSchedulerImpl:190 - Removed TaskSet 18.0 whose tasks have all completed, from pool
2025-10-30 23:11:59 INFO  Executor:190 - Finished task 0.0 in stage 19.0 (TID 12). 2107 bytes result sent to driver
2025-10-30 23:11:59 INFO  DAGScheduler:190 - ShuffleMapStage 18 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 306 ms
2025-10-30 23:11:59 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:11:59 INFO  DAGScheduler:190 - running: HashSet(ShuffleMapStage 19)
2025-10-30 23:11:59 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:11:59 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:11:59 INFO  TaskSetManager:190 - Finished task 0.0 in stage 19.0 (TID 12) in 296 ms on localhost (executor driver) (1/1)
2025-10-30 23:11:59 INFO  TaskSchedulerImpl:190 - Removed TaskSet 19.0 whose tasks have all completed, from pool
2025-10-30 23:11:59 INFO  DAGScheduler:190 - ShuffleMapStage 19 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 303 ms
2025-10-30 23:11:59 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:11:59 INFO  DAGScheduler:190 - running: HashSet()
2025-10-30 23:11:59 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:11:59 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:11:59 INFO  ShufflePartitionsUtil:190 - For shuffle(7, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:11:59 INFO  SparkContext:190 - Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:11:59 INFO  DAGScheduler:190 - Got job 13 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:11:59 INFO  DAGScheduler:190 - Final stage: ResultStage 21 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:11:59 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 20)
2025-10-30 23:11:59 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:11:59 INFO  DAGScheduler:190 - Submitting ResultStage 21 (MapPartitionsRDD[37] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:11:59 INFO  MemoryStore:190 - Block broadcast_17 stored as values in memory (estimated size 8.6 KiB, free 429.7 MiB)
2025-10-30 23:11:59 INFO  MemoryStore:190 - Block broadcast_17_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 429.7 MiB)
2025-10-30 23:11:59 INFO  SparkContext:190 - Created broadcast 17 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:11:59 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[37] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:11:59 INFO  TaskSchedulerImpl:190 - Adding task set 21.0 with 1 tasks resource profile 0
2025-10-30 23:11:59 INFO  TaskSetManager:190 - Starting task 0.0 in stage 21.0 (TID 13) (localhost,executor driver, partition 0, ANY, 9827 bytes)
2025-10-30 23:11:59 INFO  Executor:190 - Running task 0.0 in stage 21.0 (TID 13)
2025-10-30 23:11:59 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (43.1 KiB) non-empty blocks including 1 (43.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:11:59 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 1 ms
2025-10-30 23:11:59 INFO  Executor:190 - Finished task 0.0 in stage 21.0 (TID 13). 32926 bytes result sent to driver
2025-10-30 23:11:59 INFO  TaskSetManager:190 - Finished task 0.0 in stage 21.0 (TID 13) in 10 ms on localhost (executor driver) (1/1)
2025-10-30 23:11:59 INFO  TaskSchedulerImpl:190 - Removed TaskSet 21.0 whose tasks have all completed, from pool
2025-10-30 23:11:59 INFO  DAGScheduler:190 - ResultStage 21 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 16 ms
2025-10-30 23:11:59 INFO  DAGScheduler:190 - Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
2025-10-30 23:11:59 INFO  TaskSchedulerImpl:190 - Canceling stage 21
2025-10-30 23:11:59 INFO  TaskSchedulerImpl:190 - Killing all running tasks in stage 21: Stage finished
2025-10-30 23:11:59 INFO  DAGScheduler:190 - Job 13 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 18.6179 ms
2025-10-30 23:11:59 INFO  MemoryStore:190 - Block broadcast_18 stored as values in memory (estimated size 1031.8 KiB, free 428.7 MiB)
2025-10-30 23:11:59 INFO  MemoryStore:190 - Block broadcast_18_piece0 stored as bytes in memory (estimated size 50.6 KiB, free 428.7 MiB)
2025-10-30 23:11:59 INFO  SparkContext:190 - Created broadcast 18 from $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:11:59 INFO  ShufflePartitionsUtil:190 - For shuffle(6, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:11:59 INFO  CodeGenerator:190 - Code generated in 5.6618 ms
2025-10-30 23:11:59 INFO  CodeGenerator:190 - Code generated in 7.174 ms
2025-10-30 23:11:59 INFO  SparkContext:190 - Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:11:59 INFO  DAGScheduler:190 - Got job 14 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:11:59 INFO  DAGScheduler:190 - Final stage: ResultStage 23 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:11:59 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 22)
2025-10-30 23:11:59 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:11:59 INFO  DAGScheduler:190 - Submitting ResultStage 23 (MapPartitionsRDD[41] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:11:59 INFO  MemoryStore:190 - Block broadcast_19 stored as values in memory (estimated size 16.9 KiB, free 428.6 MiB)
2025-10-30 23:11:59 INFO  MemoryStore:190 - Block broadcast_19_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 428.6 MiB)
2025-10-30 23:11:59 INFO  SparkContext:190 - Created broadcast 19 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:11:59 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[41] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:11:59 INFO  TaskSchedulerImpl:190 - Adding task set 23.0 with 1 tasks resource profile 0
2025-10-30 23:11:59 INFO  TaskSetManager:190 - Starting task 0.0 in stage 23.0 (TID 14) (localhost,executor driver, partition 0, ANY, 9827 bytes)
2025-10-30 23:11:59 INFO  Executor:190 - Running task 0.0 in stage 23.0 (TID 14)
2025-10-30 23:11:59 INFO  CodeGenerator:190 - Code generated in 4.4965 ms
2025-10-30 23:11:59 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (41.3 KiB) non-empty blocks including 1 (41.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:11:59 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 0 ms
2025-10-30 23:11:59 INFO  CodeGenerator:190 - Code generated in 7.7488 ms
2025-10-30 23:11:59 INFO  Executor:190 - Finished task 0.0 in stage 23.0 (TID 14). 4961 bytes result sent to driver
2025-10-30 23:11:59 INFO  TaskSetManager:190 - Finished task 0.0 in stage 23.0 (TID 14) in 30 ms on localhost (executor driver) (1/1)
2025-10-30 23:11:59 INFO  TaskSchedulerImpl:190 - Removed TaskSet 23.0 whose tasks have all completed, from pool
2025-10-30 23:11:59 INFO  DAGScheduler:190 - ResultStage 23 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 35 ms
2025-10-30 23:11:59 INFO  DAGScheduler:190 - Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
2025-10-30 23:11:59 INFO  TaskSchedulerImpl:190 - Canceling stage 23
2025-10-30 23:11:59 INFO  TaskSchedulerImpl:190 - Killing all running tasks in stage 23: Stage finished
2025-10-30 23:11:59 INFO  DAGScheduler:190 - Job 14 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 38.3238 ms
2025-10-30 23:11:59 INFO  CodeGenerator:190 - Code generated in 4.9887 ms
2025-10-30 23:11:59 INFO  CodeGenerator:190 - Code generated in 4.4534 ms
2025-10-30 23:12:15 INFO  SparkContext:184 - Invoking stop() from shutdown hook
2025-10-30 23:12:15 INFO  SparkContext:190 - SparkContext is stopping with exitCode 0 from run at Executors.java:572.
2025-10-30 23:12:15 INFO  Server:479 - Stopped Server@6e440710{STOPPING}[11.0.24,sto=30000]
2025-10-30 23:12:15 INFO  Server:135 - Shutdown Server@6e440710{STOPPING}[11.0.24,sto=30000]
2025-10-30 23:12:15 INFO  AbstractConnector:431 - Stopped Spark@27ee1595{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-10-30 23:12:15 INFO  SparkUI:190 - Stopped Spark web UI at http://127.0.0.1:4040
2025-10-30 23:12:15 INFO  MapOutputTrackerMasterEndpoint:184 - MapOutputTrackerMasterEndpoint stopped!
2025-10-30 23:12:15 INFO  MemoryStore:184 - MemoryStore cleared
2025-10-30 23:12:15 INFO  BlockManager:184 - BlockManager stopped
2025-10-30 23:12:15 INFO  BlockManagerMaster:184 - BlockManagerMaster stopped
2025-10-30 23:12:15 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:184 - OutputCommitCoordinator stopped!
2025-10-30 23:12:15 WARN  SparkEnv:258 - Exception while deleting Spark temp dir: C:\Users\user\AppData\Local\Temp\spark-8482f445-8bb2-41f2-9b89-db1155e74f89\userFiles-68e4a4d5-3788-4230-8e96-e3a98fe88666
java.io.IOException: Failed to delete: C:\Users\user\AppData\Local\Temp\spark-8482f445-8bb2-41f2-9b89-db1155e74f89\userFiles-68e4a4d5-3788-4230-8e96-e3a98fe88666\postgresql-42.7.3.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:155) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:131) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2395) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2297) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at scala.util.Try$.apply(Try.scala:217) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:1570) [?:?]
2025-10-30 23:12:15 INFO  SparkContext:184 - Successfully stopped SparkContext
2025-10-30 23:12:15 INFO  ShutdownHookManager:184 - Shutdown hook called
2025-10-30 23:12:15 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-8482f445-8bb2-41f2-9b89-db1155e74f89
2025-10-30 23:12:15 ERROR ShutdownHookManager:278 - Exception while deleting Spark temp dir: C:\Users\user\AppData\Local\Temp\spark-8482f445-8bb2-41f2-9b89-db1155e74f89
java.io.IOException: Failed to delete: C:\Users\user\AppData\Local\Temp\spark-8482f445-8bb2-41f2-9b89-db1155e74f89\userFiles-68e4a4d5-3788-4230-8e96-e3a98fe88666\postgresql-42.7.3.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:155) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:70) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:67) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:67) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at scala.util.Try$.apply(Try.scala:217) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:1570) [?:?]
2025-10-30 23:12:15 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\artifacts-4c87a1bb-7b4b-4288-bfc1-829ce238f3ed
2025-10-30 23:12:15 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-8482f445-8bb2-41f2-9b89-db1155e74f89\pyspark-43adeb8d-17b9-48b9-8371-fde861a3b46a
2025-10-30 23:12:15 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-8482f445-8bb2-41f2-9b89-db1155e74f89\userFiles-68e4a4d5-3788-4230-8e96-e3a98fe88666
2025-10-30 23:12:15 ERROR ShutdownHookManager:278 - Exception while deleting Spark temp dir: C:\Users\user\AppData\Local\Temp\spark-8482f445-8bb2-41f2-9b89-db1155e74f89\userFiles-68e4a4d5-3788-4230-8e96-e3a98fe88666
java.io.IOException: Failed to delete: C:\Users\user\AppData\Local\Temp\spark-8482f445-8bb2-41f2-9b89-db1155e74f89\userFiles-68e4a4d5-3788-4230-8e96-e3a98fe88666\postgresql-42.7.3.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:155) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:70) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:67) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:67) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at scala.util.Try$.apply(Try.scala:217) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:1570) [?:?]
2025-10-30 23:12:15 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-2ba6a071-70f8-4c9c-abd3-9b65c619b8b8
2025-10-30 23:12:28 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-10-30 23:12:28 INFO  SparkContext:190 - Running Spark version 4.0.1
2025-10-30 23:12:28 INFO  SparkContext:190 - OS info Windows 11, 10.0, amd64
2025-10-30 23:12:28 INFO  SparkContext:190 - Java version 22.0.2
2025-10-30 23:12:28 INFO  ResourceUtils:184 - ==============================================================
2025-10-30 23:12:28 INFO  ResourceUtils:184 - No custom resources configured for spark.driver.
2025-10-30 23:12:28 INFO  ResourceUtils:184 - ==============================================================
2025-10-30 23:12:28 INFO  SparkContext:190 - Submitted application: LocalConnection
2025-10-30 23:12:28 INFO  ResourceProfile:190 - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-10-30 23:12:28 INFO  ResourceProfile:190 - Limiting resource is cpu
2025-10-30 23:12:28 INFO  ResourceProfileManager:190 - Added ResourceProfile id: 0
2025-10-30 23:12:28 INFO  SecurityManager:190 - Changing view acls to: user
2025-10-30 23:12:28 INFO  SecurityManager:190 - Changing modify acls to: user
2025-10-30 23:12:28 INFO  SecurityManager:190 - Changing view acls groups to: user
2025-10-30 23:12:28 INFO  SecurityManager:190 - Changing modify acls groups to: user
2025-10-30 23:12:28 INFO  SecurityManager:190 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: user groups with view permissions: EMPTY; users with modify permissions: user; groups with modify permissions: EMPTY; RPC SSL disabled
2025-10-30 23:12:28 INFO  Utils:190 - Successfully started service 'sparkDriver' on port 64674.
2025-10-30 23:12:28 INFO  SparkEnv:190 - Registering MapOutputTracker
2025-10-30 23:12:28 INFO  SparkEnv:190 - Registering BlockManagerMaster
2025-10-30 23:12:28 INFO  BlockManagerMasterEndpoint:190 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-10-30 23:12:28 INFO  BlockManagerMasterEndpoint:184 - BlockManagerMasterEndpoint up
2025-10-30 23:12:28 INFO  SparkEnv:190 - Registering BlockManagerMasterHeartbeat
2025-10-30 23:12:28 INFO  DiskBlockManager:190 - Created local directory at C:\Users\user\AppData\Local\Temp\blockmgr-87c61a3d-2328-4cc3-a675-7dd4fd9a80dc
2025-10-30 23:12:28 INFO  SparkEnv:190 - Registering OutputCommitCoordinator
2025-10-30 23:12:29 INFO  JettyUtils:190 - Start Jetty 0.0.0.0:4040 for SparkUI
2025-10-30 23:12:29 INFO  Server:384 - jetty-11.0.24; built: 2024-08-26T18:11:22.448Z; git: 5dfc59a691b748796f922208956bd1f2794bcd16; jvm 22.0.2+9-70
2025-10-30 23:12:29 INFO  Server:439 - Started Server@104c717b{STARTING}[11.0.24,sto=30000] @2534ms
2025-10-30 23:12:29 INFO  AbstractConnector:376 - Started ServerConnector@72112998{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-10-30 23:12:29 INFO  Utils:190 - Successfully started service 'SparkUI' on port 4040.
2025-10-30 23:12:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@6b9baa9a{/,null,AVAILABLE,@Spark}
2025-10-30 23:12:29 INFO  SparkContext:190 - Added JAR C:\Users\user\AppData\Roaming\JetBrains\DataGrip2025.2\jdbc-drivers\PostgreSQL\42.7.3\org\postgresql\postgresql\42.7.3\postgresql-42.7.3.jar at spark://127.0.0.1:64674/jars/postgresql-42.7.3.jar with timestamp 1761855148437
2025-10-30 23:12:29 INFO  SecurityManager:190 - Changing view acls to: user
2025-10-30 23:12:29 INFO  SecurityManager:190 - Changing modify acls to: user
2025-10-30 23:12:29 INFO  SecurityManager:190 - Changing view acls groups to: user
2025-10-30 23:12:29 INFO  SecurityManager:190 - Changing modify acls groups to: user
2025-10-30 23:12:29 INFO  SecurityManager:190 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: user groups with view permissions: EMPTY; users with modify permissions: user; groups with modify permissions: EMPTY; RPC SSL disabled
2025-10-30 23:12:29 INFO  Executor:190 - Starting executor ID driver on host localhost
2025-10-30 23:12:29 INFO  Executor:190 - OS info Windows 11, 10.0, amd64
2025-10-30 23:12:29 INFO  Executor:190 - Java version 22.0.2
2025-10-30 23:12:29 INFO  Executor:190 - Starting executor with user classpath (userClassPathFirst = false): ''
2025-10-30 23:12:29 INFO  Executor:190 - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@1cf8353 for default.
2025-10-30 23:12:29 INFO  Executor:190 - Fetching spark://127.0.0.1:64674/jars/postgresql-42.7.3.jar with timestamp 1761855148437
2025-10-30 23:12:29 INFO  TransportClientFactory:155 - Successfully created connection to /127.0.0.1:64674 after 20 ms (0 ms spent in bootstraps)
2025-10-30 23:12:29 INFO  Utils:190 - Fetching spark://127.0.0.1:64674/jars/postgresql-42.7.3.jar to C:\Users\user\AppData\Local\Temp\spark-881da810-fb35-46b7-90f2-cf58246424c2\userFiles-dbda9ef2-238a-4c8b-8308-5b178bbc389e\fetchFileTemp9232598319100821265.tmp
2025-10-30 23:12:29 INFO  Executor:190 - Adding file:/C:/Users/user/AppData/Local/Temp/spark-881da810-fb35-46b7-90f2-cf58246424c2/userFiles-dbda9ef2-238a-4c8b-8308-5b178bbc389e/postgresql-42.7.3.jar to class loader default
2025-10-30 23:12:29 INFO  Utils:190 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64679.
2025-10-30 23:12:29 INFO  NettyBlockTransferService:155 - Server created on 127.0.0.1:64679
2025-10-30 23:12:29 INFO  BlockManager:190 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-10-30 23:12:29 INFO  BlockManagerMaster:190 - Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64679, None)
2025-10-30 23:12:29 INFO  BlockManagerMasterEndpoint:190 - Registering block manager 127.0.0.1:64679 with 434.4 MiB RAM, BlockManagerId(driver, 127.0.0.1, 64679, None)
2025-10-30 23:12:29 INFO  BlockManagerMaster:190 - Registered BlockManager BlockManagerId(driver, 127.0.0.1, 64679, None)
2025-10-30 23:12:29 INFO  BlockManager:190 - Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 64679, None)
2025-10-30 23:12:29 INFO  ContextHandler:1123 - Stopped o.s.j.s.ServletContextHandler@6b9baa9a{/,null,STOPPED,@Spark}
2025-10-30 23:12:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4c75e679{/jobs,null,AVAILABLE,@Spark}
2025-10-30 23:12:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@566598e8{/jobs/json,null,AVAILABLE,@Spark}
2025-10-30 23:12:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@49f42031{/jobs/job,null,AVAILABLE,@Spark}
2025-10-30 23:12:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@697945a1{/jobs/job/json,null,AVAILABLE,@Spark}
2025-10-30 23:12:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@217c19aa{/stages,null,AVAILABLE,@Spark}
2025-10-30 23:12:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@185fd86c{/stages/json,null,AVAILABLE,@Spark}
2025-10-30 23:12:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@1a65145c{/stages/stage,null,AVAILABLE,@Spark}
2025-10-30 23:12:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@1fd4ebf{/stages/stage/json,null,AVAILABLE,@Spark}
2025-10-30 23:12:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@47d7c74e{/stages/pool,null,AVAILABLE,@Spark}
2025-10-30 23:12:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@705b7fef{/stages/pool/json,null,AVAILABLE,@Spark}
2025-10-30 23:12:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@6bdd33ec{/stages/taskThreadDump,null,AVAILABLE,@Spark}
2025-10-30 23:12:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@19276de1{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
2025-10-30 23:12:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@42adef20{/storage,null,AVAILABLE,@Spark}
2025-10-30 23:12:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@14d98ed3{/storage/json,null,AVAILABLE,@Spark}
2025-10-30 23:12:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@16560f96{/storage/rdd,null,AVAILABLE,@Spark}
2025-10-30 23:12:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@65951109{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-10-30 23:12:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@1ed6901{/environment,null,AVAILABLE,@Spark}
2025-10-30 23:12:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@648c1e88{/environment/json,null,AVAILABLE,@Spark}
2025-10-30 23:12:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@264ca065{/executors,null,AVAILABLE,@Spark}
2025-10-30 23:12:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@69587b7a{/executors/json,null,AVAILABLE,@Spark}
2025-10-30 23:12:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@7d6c1c20{/executors/threadDump,null,AVAILABLE,@Spark}
2025-10-30 23:12:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@182e0984{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-10-30 23:12:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@3d864bea{/executors/heapHistogram,null,AVAILABLE,@Spark}
2025-10-30 23:12:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@5eb831ab{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2025-10-30 23:12:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4798ff2e{/static,null,AVAILABLE,@Spark}
2025-10-30 23:12:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@2d03a0ea{/,null,AVAILABLE,@Spark}
2025-10-30 23:12:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@5e28a579{/api,null,AVAILABLE,@Spark}
2025-10-30 23:12:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@35477e5d{/metrics,null,AVAILABLE,@Spark}
2025-10-30 23:12:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@623122d3{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-10-30 23:12:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@52a36fd1{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-10-30 23:12:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4175fce3{/metrics/json,null,AVAILABLE,@Spark}
2025-10-30 23:12:32 INFO  SharedState:190 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-10-30 23:12:32 INFO  SharedState:190 - Warehouse path is 'file:/C:/Users/user/DataGripProjects/innowise_trainee/TASKS/task_5/spark-warehouse'.
2025-10-30 23:12:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@b134abe{/SQL,null,AVAILABLE,@Spark}
2025-10-30 23:12:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@7b66283{/SQL/json,null,AVAILABLE,@Spark}
2025-10-30 23:12:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@5d4fec1{/SQL/execution,null,AVAILABLE,@Spark}
2025-10-30 23:12:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@2858fdd6{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-10-30 23:12:32 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@690d468b{/static/sql,null,AVAILABLE,@Spark}
2025-10-30 23:12:39 INFO  CodeGenerator:190 - Code generated in 146.8067 ms
2025-10-30 23:12:39 INFO  CodeGenerator:190 - Code generated in 146.8072 ms
2025-10-30 23:12:39 INFO  CodeGenerator:190 - Code generated in 146.8067 ms
2025-10-30 23:12:39 INFO  DAGScheduler:190 - Registering RDD 8 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 2
2025-10-30 23:12:39 INFO  DAGScheduler:190 - Got map stage job 2 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:12:39 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 0 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:12:39 INFO  DAGScheduler:190 - Parents of final stage: List()
2025-10-30 23:12:39 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:12:39 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[8] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:12:39 INFO  MemoryStore:190 - MemoryStore started with capacity 434.4 MiB
2025-10-30 23:12:39 INFO  MemoryStore:190 - Block broadcast_0 stored as values in memory (estimated size 15.9 KiB, free 434.4 MiB)
2025-10-30 23:12:39 INFO  MemoryStore:190 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 434.4 MiB)
2025-10-30 23:12:39 INFO  SparkContext:190 - Created broadcast 0 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:12:39 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[8] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:12:39 INFO  TaskSchedulerImpl:190 - Adding task set 0.0 with 1 tasks resource profile 0
2025-10-30 23:12:39 INFO  DAGScheduler:190 - Registering RDD 6 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 0
2025-10-30 23:12:39 INFO  DAGScheduler:190 - Got map stage job 1 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:12:39 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 1 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:12:39 INFO  DAGScheduler:190 - Parents of final stage: List()
2025-10-30 23:12:39 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:12:39 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 1 (MapPartitionsRDD[6] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:12:39 INFO  MemoryStore:190 - Block broadcast_1 stored as values in memory (estimated size 15.7 KiB, free 434.4 MiB)
2025-10-30 23:12:39 INFO  MemoryStore:190 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.4 MiB)
2025-10-30 23:12:39 INFO  SparkContext:190 - Created broadcast 1 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:12:39 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[6] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:12:39 INFO  TaskSchedulerImpl:190 - Adding task set 1.0 with 1 tasks resource profile 0
2025-10-30 23:12:39 INFO  TaskSetManager:190 - Starting task 0.0 in stage 0.0 (TID 0) (localhost,executor driver, partition 0, PROCESS_LOCAL, 9643 bytes)
2025-10-30 23:12:39 INFO  DAGScheduler:190 - Registering RDD 7 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 1
2025-10-30 23:12:39 INFO  DAGScheduler:190 - Got map stage job 0 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:12:39 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 2 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:12:39 INFO  DAGScheduler:190 - Parents of final stage: List()
2025-10-30 23:12:39 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:12:39 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 2 (MapPartitionsRDD[7] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:12:39 INFO  MemoryStore:190 - Block broadcast_2 stored as values in memory (estimated size 15.8 KiB, free 434.3 MiB)
2025-10-30 23:12:39 INFO  MemoryStore:190 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.3 MiB)
2025-10-30 23:12:39 INFO  TaskSetManager:190 - Starting task 0.0 in stage 1.0 (TID 1) (localhost,executor driver, partition 0, PROCESS_LOCAL, 9643 bytes)
2025-10-30 23:12:39 INFO  SparkContext:190 - Created broadcast 2 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:12:39 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[7] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:12:39 INFO  TaskSchedulerImpl:190 - Adding task set 2.0 with 1 tasks resource profile 0
2025-10-30 23:12:39 INFO  TaskSetManager:190 - Starting task 0.0 in stage 2.0 (TID 2) (localhost,executor driver, partition 0, PROCESS_LOCAL, 9643 bytes)
2025-10-30 23:12:39 INFO  Executor:190 - Running task 0.0 in stage 0.0 (TID 0)
2025-10-30 23:12:39 INFO  Executor:190 - Running task 0.0 in stage 2.0 (TID 2)
2025-10-30 23:12:39 INFO  Executor:190 - Running task 0.0 in stage 1.0 (TID 1)
2025-10-30 23:12:40 INFO  CodeGenerator:190 - Code generated in 26.6524 ms
2025-10-30 23:12:40 INFO  CodeGenerator:190 - Code generated in 31.6432 ms
2025-10-30 23:12:40 INFO  CodeGenerator:190 - Code generated in 31.6608 ms
2025-10-30 23:12:40 INFO  CodeGenerator:190 - Code generated in 19.486 ms
2025-10-30 23:12:40 INFO  SecurityManager:190 - Changing view acls to: user
2025-10-30 23:12:40 INFO  SecurityManager:190 - Changing modify acls to: user
2025-10-30 23:12:40 INFO  SecurityManager:190 - Changing view acls groups to: user
2025-10-30 23:12:40 INFO  SecurityManager:190 - Changing modify acls groups to: user
2025-10-30 23:12:40 INFO  SecurityManager:190 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: user groups with view permissions: EMPTY; users with modify permissions: user; groups with modify permissions: EMPTY; RPC SSL disabled
2025-10-30 23:12:40 INFO  JDBCRDD:184 - closed connection
2025-10-30 23:12:40 INFO  JDBCRDD:184 - closed connection
2025-10-30 23:12:40 INFO  JDBCRDD:184 - closed connection
2025-10-30 23:12:40 INFO  Executor:190 - Finished task 0.0 in stage 0.0 (TID 0). 2150 bytes result sent to driver
2025-10-30 23:12:40 INFO  Executor:190 - Finished task 0.0 in stage 1.0 (TID 1). 2150 bytes result sent to driver
2025-10-30 23:12:40 INFO  Executor:190 - Finished task 0.0 in stage 2.0 (TID 2). 2150 bytes result sent to driver
2025-10-30 23:12:40 INFO  TaskSetManager:190 - Finished task 0.0 in stage 1.0 (TID 1) in 561 ms on localhost (executor driver) (1/1)
2025-10-30 23:12:40 INFO  TaskSchedulerImpl:190 - Removed TaskSet 1.0 whose tasks have all completed, from pool
2025-10-30 23:12:40 INFO  TaskSetManager:190 - Finished task 0.0 in stage 2.0 (TID 2) in 564 ms on localhost (executor driver) (1/1)
2025-10-30 23:12:40 INFO  TaskSchedulerImpl:190 - Removed TaskSet 2.0 whose tasks have all completed, from pool
2025-10-30 23:12:40 INFO  TaskSetManager:190 - Finished task 0.0 in stage 0.0 (TID 0) in 597 ms on localhost (executor driver) (1/1)
2025-10-30 23:12:40 INFO  TaskSchedulerImpl:190 - Removed TaskSet 0.0 whose tasks have all completed, from pool
2025-10-30 23:12:40 INFO  DAGScheduler:190 - ShuffleMapStage 1 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 604 ms
2025-10-30 23:12:40 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:12:40 INFO  DAGScheduler:190 - running: HashSet(ShuffleMapStage 0, ShuffleMapStage 2)
2025-10-30 23:12:40 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:12:40 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:12:40 INFO  DAGScheduler:190 - ShuffleMapStage 2 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 588 ms
2025-10-30 23:12:40 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:12:40 INFO  DAGScheduler:190 - running: HashSet(ShuffleMapStage 0)
2025-10-30 23:12:40 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:12:40 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:12:40 INFO  DAGScheduler:190 - ShuffleMapStage 0 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 754 ms
2025-10-30 23:12:40 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:12:40 INFO  DAGScheduler:190 - running: HashSet()
2025-10-30 23:12:40 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:12:40 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:12:40 INFO  ShufflePartitionsUtil:190 - For shuffle(0, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:12:40 INFO  ShufflePartitionsUtil:190 - For shuffle(2, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:12:40 INFO  SparkContext:190 - Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:12:40 INFO  DAGScheduler:190 - Got job 3 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:12:40 INFO  DAGScheduler:190 - Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:12:40 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 3)
2025-10-30 23:12:40 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:12:40 INFO  DAGScheduler:190 - Submitting ResultStage 4 (MapPartitionsRDD[10] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:12:40 INFO  SparkContext:190 - Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:12:40 INFO  MemoryStore:190 - Block broadcast_3 stored as values in memory (estimated size 8.6 KiB, free 434.3 MiB)
2025-10-30 23:12:40 INFO  MemoryStore:190 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 434.3 MiB)
2025-10-30 23:12:40 INFO  SparkContext:190 - Created broadcast 3 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:12:40 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[10] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:12:40 INFO  TaskSchedulerImpl:190 - Adding task set 4.0 with 1 tasks resource profile 0
2025-10-30 23:12:40 INFO  DAGScheduler:190 - Got job 4 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:12:40 INFO  DAGScheduler:190 - Final stage: ResultStage 6 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:12:40 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 5)
2025-10-30 23:12:40 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:12:40 INFO  TaskSetManager:190 - Starting task 0.0 in stage 4.0 (TID 3) (localhost,executor driver, partition 0, ANY, 9827 bytes)
2025-10-30 23:12:40 INFO  DAGScheduler:190 - Submitting ResultStage 6 (MapPartitionsRDD[12] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:12:40 INFO  Executor:190 - Running task 0.0 in stage 4.0 (TID 3)
2025-10-30 23:12:40 INFO  MemoryStore:190 - Block broadcast_4 stored as values in memory (estimated size 8.6 KiB, free 434.3 MiB)
2025-10-30 23:12:40 INFO  MemoryStore:190 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 434.3 MiB)
2025-10-30 23:12:40 INFO  SparkContext:190 - Created broadcast 4 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:12:40 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[12] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:12:40 INFO  TaskSchedulerImpl:190 - Adding task set 6.0 with 1 tasks resource profile 0
2025-10-30 23:12:40 INFO  TaskSetManager:190 - Starting task 0.0 in stage 6.0 (TID 4) (localhost,executor driver, partition 0, ANY, 9827 bytes)
2025-10-30 23:12:40 INFO  Executor:190 - Running task 0.0 in stage 6.0 (TID 4)
2025-10-30 23:12:40 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (24.8 KiB) non-empty blocks including 1 (24.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:12:40 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (17.0 KiB) non-empty blocks including 1 (17.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:12:40 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 16 ms
2025-10-30 23:12:40 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 16 ms
2025-10-30 23:12:40 INFO  Executor:190 - Finished task 0.0 in stage 4.0 (TID 3). 9608 bytes result sent to driver
2025-10-30 23:12:40 INFO  Executor:190 - Finished task 0.0 in stage 6.0 (TID 4). 15524 bytes result sent to driver
2025-10-30 23:12:40 INFO  TaskSetManager:190 - Finished task 0.0 in stage 6.0 (TID 4) in 93 ms on localhost (executor driver) (1/1)
2025-10-30 23:12:40 INFO  TaskSchedulerImpl:190 - Removed TaskSet 6.0 whose tasks have all completed, from pool
2025-10-30 23:12:40 INFO  TaskSetManager:190 - Finished task 0.0 in stage 4.0 (TID 3) in 110 ms on localhost (executor driver) (1/1)
2025-10-30 23:12:40 INFO  TaskSchedulerImpl:190 - Removed TaskSet 4.0 whose tasks have all completed, from pool
2025-10-30 23:12:40 INFO  DAGScheduler:190 - ResultStage 6 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 108 ms
2025-10-30 23:12:40 INFO  DAGScheduler:190 - Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2025-10-30 23:12:40 INFO  TaskSchedulerImpl:190 - Canceling stage 6
2025-10-30 23:12:40 INFO  TaskSchedulerImpl:190 - Killing all running tasks in stage 6: Stage finished
2025-10-30 23:12:40 INFO  DAGScheduler:190 - ResultStage 4 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 128 ms
2025-10-30 23:12:40 INFO  DAGScheduler:190 - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-10-30 23:12:40 INFO  TaskSchedulerImpl:190 - Canceling stage 4
2025-10-30 23:12:40 INFO  TaskSchedulerImpl:190 - Killing all running tasks in stage 4: Stage finished
2025-10-30 23:12:40 INFO  DAGScheduler:190 - Job 3 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 141.5358 ms
2025-10-30 23:12:40 INFO  DAGScheduler:190 - Job 4 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 132.7691 ms
2025-10-30 23:12:40 INFO  CodeGenerator:190 - Code generated in 14.4444 ms
2025-10-30 23:12:40 INFO  MemoryStore:190 - Block broadcast_6 stored as values in memory (estimated size 1028.7 KiB, free 432.4 MiB)
2025-10-30 23:12:40 INFO  MemoryStore:190 - Block broadcast_5 stored as values in memory (estimated size 1028.7 KiB, free 432.4 MiB)
2025-10-30 23:12:40 INFO  MemoryStore:190 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 13.7 KiB, free 432.4 MiB)
2025-10-30 23:12:40 INFO  MemoryStore:190 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 432.3 MiB)
2025-10-30 23:12:40 INFO  SparkContext:190 - Created broadcast 6 from $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:12:40 INFO  SparkContext:190 - Created broadcast 5 from $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:12:40 INFO  ShufflePartitionsUtil:190 - For shuffle(1, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:12:41 INFO  CodeGenerator:190 - Code generated in 79.1604 ms
2025-10-30 23:12:41 INFO  DAGScheduler:190 - Registering RDD 15 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 3
2025-10-30 23:12:41 INFO  DAGScheduler:190 - Got map stage job 5 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:12:41 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 8 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:12:41 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 7)
2025-10-30 23:12:41 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:12:41 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 8 (MapPartitionsRDD[15] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:12:41 INFO  MemoryStore:190 - Block broadcast_7 stored as values in memory (estimated size 65.0 KiB, free 432.3 MiB)
2025-10-30 23:12:41 INFO  MemoryStore:190 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 26.8 KiB, free 432.3 MiB)
2025-10-30 23:12:41 INFO  SparkContext:190 - Created broadcast 7 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:12:41 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[15] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:12:41 INFO  TaskSchedulerImpl:190 - Adding task set 8.0 with 1 tasks resource profile 0
2025-10-30 23:12:41 INFO  TaskSetManager:190 - Starting task 0.0 in stage 8.0 (TID 5) (localhost,executor driver, partition 0, ANY, 9816 bytes)
2025-10-30 23:12:41 INFO  Executor:190 - Running task 0.0 in stage 8.0 (TID 5)
2025-10-30 23:12:41 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (17.8 KiB) non-empty blocks including 1 (17.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:12:41 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 2 ms
2025-10-30 23:12:41 INFO  CodeGenerator:190 - Code generated in 62.2446 ms
2025-10-30 23:12:41 INFO  CodeGenerator:190 - Code generated in 14.1134 ms
2025-10-30 23:12:41 INFO  CodeGenerator:190 - Code generated in 10.094 ms
2025-10-30 23:12:41 INFO  CodeGenerator:190 - Code generated in 10.2778 ms
2025-10-30 23:12:41 INFO  CodeGenerator:190 - Code generated in 9.9244 ms
2025-10-30 23:12:41 INFO  Executor:190 - Finished task 0.0 in stage 8.0 (TID 5). 7856 bytes result sent to driver
2025-10-30 23:12:41 INFO  TaskSetManager:190 - Finished task 0.0 in stage 8.0 (TID 5) in 498 ms on localhost (executor driver) (1/1)
2025-10-30 23:12:41 INFO  TaskSchedulerImpl:190 - Removed TaskSet 8.0 whose tasks have all completed, from pool
2025-10-30 23:12:41 INFO  DAGScheduler:190 - ShuffleMapStage 8 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 515 ms
2025-10-30 23:12:41 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:12:41 INFO  DAGScheduler:190 - running: HashSet()
2025-10-30 23:12:41 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:12:41 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:12:41 INFO  ShufflePartitionsUtil:190 - For shuffle(3, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:12:41 INFO  CodeGenerator:190 - Code generated in 28.4802 ms
2025-10-30 23:12:41 INFO  HashAggregateExec:190 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-10-30 23:12:41 INFO  CodeGenerator:190 - Code generated in 26.6082 ms
2025-10-30 23:12:41 INFO  SparkContext:190 - Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:12:41 INFO  DAGScheduler:190 - Got job 6 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:12:41 INFO  DAGScheduler:190 - Final stage: ResultStage 11 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:12:41 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 10)
2025-10-30 23:12:41 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:12:41 INFO  DAGScheduler:190 - Submitting ResultStage 11 (MapPartitionsRDD[19] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:12:41 INFO  MemoryStore:190 - Block broadcast_8 stored as values in memory (estimated size 69.0 KiB, free 432.2 MiB)
2025-10-30 23:12:41 INFO  MemoryStore:190 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 432.2 MiB)
2025-10-30 23:12:41 INFO  SparkContext:190 - Created broadcast 8 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:12:41 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[19] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:12:41 INFO  TaskSchedulerImpl:190 - Adding task set 11.0 with 1 tasks resource profile 0
2025-10-30 23:12:41 INFO  TaskSetManager:190 - Starting task 0.0 in stage 11.0 (TID 6) (localhost,executor driver, partition 0, ANY, 9808 bytes)
2025-10-30 23:12:41 INFO  Executor:190 - Running task 0.0 in stage 11.0 (TID 6)
2025-10-30 23:12:41 INFO  CodeGenerator:190 - Code generated in 9.9874 ms
2025-10-30 23:12:41 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (23.4 KiB) non-empty blocks including 1 (23.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:12:41 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 1 ms
2025-10-30 23:12:41 INFO  CodeGenerator:190 - Code generated in 25.6905 ms
2025-10-30 23:12:41 INFO  Executor:190 - Finished task 0.0 in stage 11.0 (TID 6). 10165 bytes result sent to driver
2025-10-30 23:12:41 INFO  TaskSetManager:190 - Finished task 0.0 in stage 11.0 (TID 6) in 99 ms on localhost (executor driver) (1/1)
2025-10-30 23:12:41 INFO  TaskSchedulerImpl:190 - Removed TaskSet 11.0 whose tasks have all completed, from pool
2025-10-30 23:12:41 INFO  DAGScheduler:190 - ResultStage 11 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 112 ms
2025-10-30 23:12:41 INFO  DAGScheduler:190 - Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
2025-10-30 23:12:41 INFO  TaskSchedulerImpl:190 - Canceling stage 11
2025-10-30 23:12:41 INFO  TaskSchedulerImpl:190 - Killing all running tasks in stage 11: Stage finished
2025-10-30 23:12:41 INFO  DAGScheduler:190 - Job 6 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 128.869 ms
2025-10-30 23:12:41 INFO  CodeGenerator:190 - Code generated in 8.754 ms
2025-10-30 23:12:42 INFO  CodeGenerator:190 - Code generated in 9.9363 ms
2025-10-30 23:12:52 INFO  SparkContext:184 - Invoking stop() from shutdown hook
2025-10-30 23:12:52 INFO  SparkContext:190 - SparkContext is stopping with exitCode 0 from run at Executors.java:572.
2025-10-30 23:12:52 INFO  Server:479 - Stopped Server@104c717b{STOPPING}[11.0.24,sto=30000]
2025-10-30 23:12:52 INFO  Server:135 - Shutdown Server@104c717b{STOPPING}[11.0.24,sto=30000]
2025-10-30 23:12:52 INFO  AbstractConnector:431 - Stopped Spark@72112998{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-10-30 23:12:52 INFO  SparkUI:190 - Stopped Spark web UI at http://127.0.0.1:4040
2025-10-30 23:12:52 INFO  MapOutputTrackerMasterEndpoint:184 - MapOutputTrackerMasterEndpoint stopped!
2025-10-30 23:12:52 INFO  MemoryStore:184 - MemoryStore cleared
2025-10-30 23:12:52 INFO  BlockManager:184 - BlockManager stopped
2025-10-30 23:12:52 INFO  BlockManagerMaster:184 - BlockManagerMaster stopped
2025-10-30 23:12:52 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:184 - OutputCommitCoordinator stopped!
2025-10-30 23:12:52 WARN  SparkEnv:258 - Exception while deleting Spark temp dir: C:\Users\user\AppData\Local\Temp\spark-881da810-fb35-46b7-90f2-cf58246424c2\userFiles-dbda9ef2-238a-4c8b-8308-5b178bbc389e
java.io.IOException: Failed to delete: C:\Users\user\AppData\Local\Temp\spark-881da810-fb35-46b7-90f2-cf58246424c2\userFiles-dbda9ef2-238a-4c8b-8308-5b178bbc389e\postgresql-42.7.3.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:155) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:131) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2395) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2297) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at scala.util.Try$.apply(Try.scala:217) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:1570) [?:?]
2025-10-30 23:12:52 INFO  SparkContext:184 - Successfully stopped SparkContext
2025-10-30 23:12:52 INFO  ShutdownHookManager:184 - Shutdown hook called
2025-10-30 23:12:52 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-881da810-fb35-46b7-90f2-cf58246424c2\pyspark-aaeb1260-66cb-424c-8f83-aff6dde30956
2025-10-30 23:12:52 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-881da810-fb35-46b7-90f2-cf58246424c2\userFiles-dbda9ef2-238a-4c8b-8308-5b178bbc389e
2025-10-30 23:12:52 ERROR ShutdownHookManager:278 - Exception while deleting Spark temp dir: C:\Users\user\AppData\Local\Temp\spark-881da810-fb35-46b7-90f2-cf58246424c2\userFiles-dbda9ef2-238a-4c8b-8308-5b178bbc389e
java.io.IOException: Failed to delete: C:\Users\user\AppData\Local\Temp\spark-881da810-fb35-46b7-90f2-cf58246424c2\userFiles-dbda9ef2-238a-4c8b-8308-5b178bbc389e\postgresql-42.7.3.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:155) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:70) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:67) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:67) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at scala.util.Try$.apply(Try.scala:217) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:1570) [?:?]
2025-10-30 23:12:52 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\artifacts-2583d8cb-1f96-45b5-8c69-58186eb3dc38
2025-10-30 23:12:52 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-9777e200-fff0-45c2-8616-abf37faa69fd
2025-10-30 23:12:52 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-881da810-fb35-46b7-90f2-cf58246424c2
2025-10-30 23:12:52 ERROR ShutdownHookManager:278 - Exception while deleting Spark temp dir: C:\Users\user\AppData\Local\Temp\spark-881da810-fb35-46b7-90f2-cf58246424c2
java.io.IOException: Failed to delete: C:\Users\user\AppData\Local\Temp\spark-881da810-fb35-46b7-90f2-cf58246424c2\userFiles-dbda9ef2-238a-4c8b-8308-5b178bbc389e\postgresql-42.7.3.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:155) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:70) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:67) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:67) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at scala.util.Try$.apply(Try.scala:217) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:1570) [?:?]
2025-10-30 23:15:14 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-10-30 23:15:15 INFO  SparkContext:190 - Running Spark version 4.0.1
2025-10-30 23:15:15 INFO  SparkContext:190 - OS info Windows 11, 10.0, amd64
2025-10-30 23:15:15 INFO  SparkContext:190 - Java version 22.0.2
2025-10-30 23:15:15 INFO  ResourceUtils:184 - ==============================================================
2025-10-30 23:15:15 INFO  ResourceUtils:184 - No custom resources configured for spark.driver.
2025-10-30 23:15:15 INFO  ResourceUtils:184 - ==============================================================
2025-10-30 23:15:15 INFO  SparkContext:190 - Submitted application: LocalConnection
2025-10-30 23:15:15 INFO  ResourceProfile:190 - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-10-30 23:15:15 INFO  ResourceProfile:190 - Limiting resource is cpu
2025-10-30 23:15:15 INFO  ResourceProfileManager:190 - Added ResourceProfile id: 0
2025-10-30 23:15:15 INFO  SecurityManager:190 - Changing view acls to: user
2025-10-30 23:15:15 INFO  SecurityManager:190 - Changing modify acls to: user
2025-10-30 23:15:15 INFO  SecurityManager:190 - Changing view acls groups to: user
2025-10-30 23:15:15 INFO  SecurityManager:190 - Changing modify acls groups to: user
2025-10-30 23:15:15 INFO  SecurityManager:190 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: user groups with view permissions: EMPTY; users with modify permissions: user; groups with modify permissions: EMPTY; RPC SSL disabled
2025-10-30 23:15:15 INFO  Utils:190 - Successfully started service 'sparkDriver' on port 51405.
2025-10-30 23:15:15 INFO  SparkEnv:190 - Registering MapOutputTracker
2025-10-30 23:15:15 INFO  SparkEnv:190 - Registering BlockManagerMaster
2025-10-30 23:15:15 INFO  BlockManagerMasterEndpoint:190 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-10-30 23:15:15 INFO  BlockManagerMasterEndpoint:184 - BlockManagerMasterEndpoint up
2025-10-30 23:15:15 INFO  SparkEnv:190 - Registering BlockManagerMasterHeartbeat
2025-10-30 23:15:15 INFO  DiskBlockManager:190 - Created local directory at C:\Users\user\AppData\Local\Temp\blockmgr-5e97e2fb-8cd5-4272-ab6a-166160f6aff8
2025-10-30 23:15:15 INFO  SparkEnv:190 - Registering OutputCommitCoordinator
2025-10-30 23:15:15 INFO  JettyUtils:190 - Start Jetty 0.0.0.0:4040 for SparkUI
2025-10-30 23:15:15 INFO  Server:384 - jetty-11.0.24; built: 2024-08-26T18:11:22.448Z; git: 5dfc59a691b748796f922208956bd1f2794bcd16; jvm 22.0.2+9-70
2025-10-30 23:15:15 INFO  Server:439 - Started Server@104c717b{STARTING}[11.0.24,sto=30000] @2497ms
2025-10-30 23:15:15 INFO  AbstractConnector:376 - Started ServerConnector@72112998{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-10-30 23:15:15 INFO  Utils:190 - Successfully started service 'SparkUI' on port 4040.
2025-10-30 23:15:15 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@6b9baa9a{/,null,AVAILABLE,@Spark}
2025-10-30 23:15:15 INFO  SparkContext:190 - Added JAR C:\Users\user\AppData\Roaming\JetBrains\DataGrip2025.2\jdbc-drivers\PostgreSQL\42.7.3\org\postgresql\postgresql\42.7.3\postgresql-42.7.3.jar at spark://127.0.0.1:51405/jars/postgresql-42.7.3.jar with timestamp 1761855315124
2025-10-30 23:15:15 INFO  SecurityManager:190 - Changing view acls to: user
2025-10-30 23:15:15 INFO  SecurityManager:190 - Changing modify acls to: user
2025-10-30 23:15:15 INFO  SecurityManager:190 - Changing view acls groups to: user
2025-10-30 23:15:15 INFO  SecurityManager:190 - Changing modify acls groups to: user
2025-10-30 23:15:15 INFO  SecurityManager:190 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: user groups with view permissions: EMPTY; users with modify permissions: user; groups with modify permissions: EMPTY; RPC SSL disabled
2025-10-30 23:15:16 INFO  Executor:190 - Starting executor ID driver on host localhost
2025-10-30 23:15:16 INFO  Executor:190 - OS info Windows 11, 10.0, amd64
2025-10-30 23:15:16 INFO  Executor:190 - Java version 22.0.2
2025-10-30 23:15:16 INFO  Executor:190 - Starting executor with user classpath (userClassPathFirst = false): ''
2025-10-30 23:15:16 INFO  Executor:190 - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@1cf8353 for default.
2025-10-30 23:15:16 INFO  Executor:190 - Fetching spark://127.0.0.1:51405/jars/postgresql-42.7.3.jar with timestamp 1761855315124
2025-10-30 23:15:16 INFO  TransportClientFactory:155 - Successfully created connection to /127.0.0.1:51405 after 21 ms (0 ms spent in bootstraps)
2025-10-30 23:15:16 INFO  Utils:190 - Fetching spark://127.0.0.1:51405/jars/postgresql-42.7.3.jar to C:\Users\user\AppData\Local\Temp\spark-7a7959c2-2e40-4770-976e-873a253cfdb7\userFiles-9d827284-c0ed-4fa5-86d3-8e578849095a\fetchFileTemp2937548405126765721.tmp
2025-10-30 23:15:16 INFO  Executor:190 - Adding file:/C:/Users/user/AppData/Local/Temp/spark-7a7959c2-2e40-4770-976e-873a253cfdb7/userFiles-9d827284-c0ed-4fa5-86d3-8e578849095a/postgresql-42.7.3.jar to class loader default
2025-10-30 23:15:16 INFO  Utils:190 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51410.
2025-10-30 23:15:16 INFO  NettyBlockTransferService:155 - Server created on 127.0.0.1:51410
2025-10-30 23:15:16 INFO  BlockManager:190 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-10-30 23:15:16 INFO  BlockManagerMaster:190 - Registering BlockManager BlockManagerId(driver, 127.0.0.1, 51410, None)
2025-10-30 23:15:16 INFO  BlockManagerMasterEndpoint:190 - Registering block manager 127.0.0.1:51410 with 434.4 MiB RAM, BlockManagerId(driver, 127.0.0.1, 51410, None)
2025-10-30 23:15:16 INFO  BlockManagerMaster:190 - Registered BlockManager BlockManagerId(driver, 127.0.0.1, 51410, None)
2025-10-30 23:15:16 INFO  BlockManager:190 - Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 51410, None)
2025-10-30 23:15:16 INFO  ContextHandler:1123 - Stopped o.s.j.s.ServletContextHandler@6b9baa9a{/,null,STOPPED,@Spark}
2025-10-30 23:15:16 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4c75e679{/jobs,null,AVAILABLE,@Spark}
2025-10-30 23:15:16 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@566598e8{/jobs/json,null,AVAILABLE,@Spark}
2025-10-30 23:15:16 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@49f42031{/jobs/job,null,AVAILABLE,@Spark}
2025-10-30 23:15:16 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@697945a1{/jobs/job/json,null,AVAILABLE,@Spark}
2025-10-30 23:15:16 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@217c19aa{/stages,null,AVAILABLE,@Spark}
2025-10-30 23:15:16 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@185fd86c{/stages/json,null,AVAILABLE,@Spark}
2025-10-30 23:15:16 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@1a65145c{/stages/stage,null,AVAILABLE,@Spark}
2025-10-30 23:15:16 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@1fd4ebf{/stages/stage/json,null,AVAILABLE,@Spark}
2025-10-30 23:15:16 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@47d7c74e{/stages/pool,null,AVAILABLE,@Spark}
2025-10-30 23:15:16 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@705b7fef{/stages/pool/json,null,AVAILABLE,@Spark}
2025-10-30 23:15:16 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@6bdd33ec{/stages/taskThreadDump,null,AVAILABLE,@Spark}
2025-10-30 23:15:16 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@19276de1{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
2025-10-30 23:15:16 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@42adef20{/storage,null,AVAILABLE,@Spark}
2025-10-30 23:15:16 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@14d98ed3{/storage/json,null,AVAILABLE,@Spark}
2025-10-30 23:15:16 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@16560f96{/storage/rdd,null,AVAILABLE,@Spark}
2025-10-30 23:15:16 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@65951109{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-10-30 23:15:16 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@1ed6901{/environment,null,AVAILABLE,@Spark}
2025-10-30 23:15:16 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@648c1e88{/environment/json,null,AVAILABLE,@Spark}
2025-10-30 23:15:16 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@264ca065{/executors,null,AVAILABLE,@Spark}
2025-10-30 23:15:16 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@69587b7a{/executors/json,null,AVAILABLE,@Spark}
2025-10-30 23:15:16 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@7d6c1c20{/executors/threadDump,null,AVAILABLE,@Spark}
2025-10-30 23:15:16 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@182e0984{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-10-30 23:15:16 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@3d864bea{/executors/heapHistogram,null,AVAILABLE,@Spark}
2025-10-30 23:15:16 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@5eb831ab{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2025-10-30 23:15:16 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4798ff2e{/static,null,AVAILABLE,@Spark}
2025-10-30 23:15:16 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@2d03a0ea{/,null,AVAILABLE,@Spark}
2025-10-30 23:15:16 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@5e28a579{/api,null,AVAILABLE,@Spark}
2025-10-30 23:15:16 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@35477e5d{/metrics,null,AVAILABLE,@Spark}
2025-10-30 23:15:16 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@623122d3{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-10-30 23:15:16 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@52a36fd1{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-10-30 23:15:16 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4175fce3{/metrics/json,null,AVAILABLE,@Spark}
2025-10-30 23:15:18 INFO  SharedState:190 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-10-30 23:15:18 INFO  SharedState:190 - Warehouse path is 'file:/C:/Users/user/DataGripProjects/innowise_trainee/TASKS/task_5/spark-warehouse'.
2025-10-30 23:15:18 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@2894796b{/SQL,null,AVAILABLE,@Spark}
2025-10-30 23:15:18 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@3a965ee0{/SQL/json,null,AVAILABLE,@Spark}
2025-10-30 23:15:18 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@2258ab5f{/SQL/execution,null,AVAILABLE,@Spark}
2025-10-30 23:15:18 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@2e744ff0{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-10-30 23:15:18 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@1527360c{/static/sql,null,AVAILABLE,@Spark}
2025-10-30 23:18:18 INFO  SparkContext:184 - Invoking stop() from shutdown hook
2025-10-30 23:18:18 INFO  SparkContext:190 - SparkContext is stopping with exitCode 0 from run at Executors.java:572.
2025-10-30 23:18:18 INFO  Server:479 - Stopped Server@104c717b{STOPPING}[11.0.24,sto=30000]
2025-10-30 23:18:18 INFO  Server:135 - Shutdown Server@104c717b{STOPPING}[11.0.24,sto=30000]
2025-10-30 23:18:18 INFO  AbstractConnector:431 - Stopped Spark@72112998{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-10-30 23:18:18 INFO  SparkUI:190 - Stopped Spark web UI at http://127.0.0.1:4040
2025-10-30 23:18:18 INFO  MapOutputTrackerMasterEndpoint:184 - MapOutputTrackerMasterEndpoint stopped!
2025-10-30 23:18:18 INFO  MemoryStore:190 - MemoryStore started with capacity 434.4 MiB
2025-10-30 23:18:18 INFO  MemoryStore:184 - MemoryStore cleared
2025-10-30 23:18:18 INFO  BlockManager:184 - BlockManager stopped
2025-10-30 23:18:18 INFO  BlockManagerMaster:184 - BlockManagerMaster stopped
2025-10-30 23:18:18 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:184 - OutputCommitCoordinator stopped!
2025-10-30 23:18:18 INFO  SparkContext:184 - Successfully stopped SparkContext
2025-10-30 23:18:18 INFO  ShutdownHookManager:184 - Shutdown hook called
2025-10-30 23:18:18 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-b524fc86-ad60-4e5b-985b-9f5f5877b764
2025-10-30 23:18:18 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-7a7959c2-2e40-4770-976e-873a253cfdb7
2025-10-30 23:18:18 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-7a7959c2-2e40-4770-976e-873a253cfdb7\pyspark-13a2d87c-a7e6-4891-843e-fa2b496973bf
2025-10-30 23:18:18 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\artifacts-64bbbee3-773a-4bb1-b007-1b434a4b88df
2025-10-30 23:19:24 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-10-30 23:19:25 INFO  SparkContext:190 - Running Spark version 4.0.1
2025-10-30 23:19:25 INFO  SparkContext:190 - OS info Windows 11, 10.0, amd64
2025-10-30 23:19:25 INFO  SparkContext:190 - Java version 22.0.2
2025-10-30 23:19:25 INFO  ResourceUtils:184 - ==============================================================
2025-10-30 23:19:25 INFO  ResourceUtils:184 - No custom resources configured for spark.driver.
2025-10-30 23:19:25 INFO  ResourceUtils:184 - ==============================================================
2025-10-30 23:19:25 INFO  SparkContext:190 - Submitted application: LocalConnection
2025-10-30 23:19:25 INFO  ResourceProfile:190 - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-10-30 23:19:25 INFO  ResourceProfile:190 - Limiting resource is cpu
2025-10-30 23:19:25 INFO  ResourceProfileManager:190 - Added ResourceProfile id: 0
2025-10-30 23:19:25 INFO  SecurityManager:190 - Changing view acls to: user
2025-10-30 23:19:25 INFO  SecurityManager:190 - Changing modify acls to: user
2025-10-30 23:19:25 INFO  SecurityManager:190 - Changing view acls groups to: user
2025-10-30 23:19:25 INFO  SecurityManager:190 - Changing modify acls groups to: user
2025-10-30 23:19:25 INFO  SecurityManager:190 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: user groups with view permissions: EMPTY; users with modify permissions: user; groups with modify permissions: EMPTY; RPC SSL disabled
2025-10-30 23:19:25 INFO  Utils:190 - Successfully started service 'sparkDriver' on port 50205.
2025-10-30 23:19:25 INFO  SparkEnv:190 - Registering MapOutputTracker
2025-10-30 23:19:25 INFO  SparkEnv:190 - Registering BlockManagerMaster
2025-10-30 23:19:25 INFO  BlockManagerMasterEndpoint:190 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-10-30 23:19:25 INFO  BlockManagerMasterEndpoint:184 - BlockManagerMasterEndpoint up
2025-10-30 23:19:25 INFO  SparkEnv:190 - Registering BlockManagerMasterHeartbeat
2025-10-30 23:19:25 INFO  DiskBlockManager:190 - Created local directory at C:\Users\user\AppData\Local\Temp\blockmgr-af8a59f5-f7de-4e8b-a5ba-dbb233aea441
2025-10-30 23:19:25 INFO  SparkEnv:190 - Registering OutputCommitCoordinator
2025-10-30 23:19:26 INFO  JettyUtils:190 - Start Jetty 0.0.0.0:4040 for SparkUI
2025-10-30 23:19:26 INFO  Server:384 - jetty-11.0.24; built: 2024-08-26T18:11:22.448Z; git: 5dfc59a691b748796f922208956bd1f2794bcd16; jvm 22.0.2+9-70
2025-10-30 23:19:26 INFO  Server:439 - Started Server@104c717b{STARTING}[11.0.24,sto=30000] @3208ms
2025-10-30 23:19:26 INFO  AbstractConnector:376 - Started ServerConnector@27ee1595{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-10-30 23:19:26 INFO  Utils:190 - Successfully started service 'SparkUI' on port 4040.
2025-10-30 23:19:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@6b9baa9a{/,null,AVAILABLE,@Spark}
2025-10-30 23:19:26 INFO  SparkContext:190 - Added JAR C:\Users\user\AppData\Roaming\JetBrains\DataGrip2025.2\jdbc-drivers\PostgreSQL\42.7.3\org\postgresql\postgresql\42.7.3\postgresql-42.7.3.jar at spark://127.0.0.1:50205/jars/postgresql-42.7.3.jar with timestamp 1761855565136
2025-10-30 23:19:26 INFO  SecurityManager:190 - Changing view acls to: user
2025-10-30 23:19:26 INFO  SecurityManager:190 - Changing modify acls to: user
2025-10-30 23:19:26 INFO  SecurityManager:190 - Changing view acls groups to: user
2025-10-30 23:19:26 INFO  SecurityManager:190 - Changing modify acls groups to: user
2025-10-30 23:19:26 INFO  SecurityManager:190 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: user groups with view permissions: EMPTY; users with modify permissions: user; groups with modify permissions: EMPTY; RPC SSL disabled
2025-10-30 23:19:26 INFO  Executor:190 - Starting executor ID driver on host localhost
2025-10-30 23:19:26 INFO  Executor:190 - OS info Windows 11, 10.0, amd64
2025-10-30 23:19:26 INFO  Executor:190 - Java version 22.0.2
2025-10-30 23:19:26 INFO  Executor:190 - Starting executor with user classpath (userClassPathFirst = false): ''
2025-10-30 23:19:26 INFO  Executor:190 - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@1cf8353 for default.
2025-10-30 23:19:26 INFO  Executor:190 - Fetching spark://127.0.0.1:50205/jars/postgresql-42.7.3.jar with timestamp 1761855565136
2025-10-30 23:19:26 INFO  TransportClientFactory:155 - Successfully created connection to /127.0.0.1:50205 after 31 ms (0 ms spent in bootstraps)
2025-10-30 23:19:26 INFO  Utils:190 - Fetching spark://127.0.0.1:50205/jars/postgresql-42.7.3.jar to C:\Users\user\AppData\Local\Temp\spark-6913bf8b-717a-4f93-90da-1d29315aeb01\userFiles-9c14de0f-a253-423e-8736-f6cb31f39f52\fetchFileTemp5506481446887423711.tmp
2025-10-30 23:19:26 INFO  Executor:190 - Adding file:/C:/Users/user/AppData/Local/Temp/spark-6913bf8b-717a-4f93-90da-1d29315aeb01/userFiles-9c14de0f-a253-423e-8736-f6cb31f39f52/postgresql-42.7.3.jar to class loader default
2025-10-30 23:19:26 INFO  Utils:190 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50210.
2025-10-30 23:19:26 INFO  NettyBlockTransferService:155 - Server created on 127.0.0.1:50210
2025-10-30 23:19:26 INFO  BlockManager:190 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-10-30 23:19:26 INFO  BlockManagerMaster:190 - Registering BlockManager BlockManagerId(driver, 127.0.0.1, 50210, None)
2025-10-30 23:19:26 INFO  BlockManagerMasterEndpoint:190 - Registering block manager 127.0.0.1:50210 with 434.4 MiB RAM, BlockManagerId(driver, 127.0.0.1, 50210, None)
2025-10-30 23:19:26 INFO  BlockManagerMaster:190 - Registered BlockManager BlockManagerId(driver, 127.0.0.1, 50210, None)
2025-10-30 23:19:26 INFO  BlockManager:190 - Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 50210, None)
2025-10-30 23:19:26 INFO  ContextHandler:1123 - Stopped o.s.j.s.ServletContextHandler@6b9baa9a{/,null,STOPPED,@Spark}
2025-10-30 23:19:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4c75e679{/jobs,null,AVAILABLE,@Spark}
2025-10-30 23:19:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@566598e8{/jobs/json,null,AVAILABLE,@Spark}
2025-10-30 23:19:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@49f42031{/jobs/job,null,AVAILABLE,@Spark}
2025-10-30 23:19:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@697945a1{/jobs/job/json,null,AVAILABLE,@Spark}
2025-10-30 23:19:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@217c19aa{/stages,null,AVAILABLE,@Spark}
2025-10-30 23:19:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@185fd86c{/stages/json,null,AVAILABLE,@Spark}
2025-10-30 23:19:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@1a65145c{/stages/stage,null,AVAILABLE,@Spark}
2025-10-30 23:19:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@1fd4ebf{/stages/stage/json,null,AVAILABLE,@Spark}
2025-10-30 23:19:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@47d7c74e{/stages/pool,null,AVAILABLE,@Spark}
2025-10-30 23:19:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@705b7fef{/stages/pool/json,null,AVAILABLE,@Spark}
2025-10-30 23:19:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@6bdd33ec{/stages/taskThreadDump,null,AVAILABLE,@Spark}
2025-10-30 23:19:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@19276de1{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
2025-10-30 23:19:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@42adef20{/storage,null,AVAILABLE,@Spark}
2025-10-30 23:19:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@14d98ed3{/storage/json,null,AVAILABLE,@Spark}
2025-10-30 23:19:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@16560f96{/storage/rdd,null,AVAILABLE,@Spark}
2025-10-30 23:19:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@65951109{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-10-30 23:19:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@1ed6901{/environment,null,AVAILABLE,@Spark}
2025-10-30 23:19:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@648c1e88{/environment/json,null,AVAILABLE,@Spark}
2025-10-30 23:19:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@264ca065{/executors,null,AVAILABLE,@Spark}
2025-10-30 23:19:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@69587b7a{/executors/json,null,AVAILABLE,@Spark}
2025-10-30 23:19:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@7d6c1c20{/executors/threadDump,null,AVAILABLE,@Spark}
2025-10-30 23:19:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@182e0984{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-10-30 23:19:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@3d864bea{/executors/heapHistogram,null,AVAILABLE,@Spark}
2025-10-30 23:19:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@5eb831ab{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2025-10-30 23:19:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4798ff2e{/static,null,AVAILABLE,@Spark}
2025-10-30 23:19:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@2d03a0ea{/,null,AVAILABLE,@Spark}
2025-10-30 23:19:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@5e28a579{/api,null,AVAILABLE,@Spark}
2025-10-30 23:19:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@35477e5d{/metrics,null,AVAILABLE,@Spark}
2025-10-30 23:19:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@623122d3{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-10-30 23:19:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@52a36fd1{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-10-30 23:19:26 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4175fce3{/metrics/json,null,AVAILABLE,@Spark}
2025-10-30 23:19:29 INFO  SharedState:190 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-10-30 23:19:29 INFO  SharedState:190 - Warehouse path is 'file:/C:/Users/user/DataGripProjects/innowise_trainee/TASKS/task_5/spark-warehouse'.
2025-10-30 23:19:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@b134abe{/SQL,null,AVAILABLE,@Spark}
2025-10-30 23:19:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@7b66283{/SQL/json,null,AVAILABLE,@Spark}
2025-10-30 23:19:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@5d4fec1{/SQL/execution,null,AVAILABLE,@Spark}
2025-10-30 23:19:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@2858fdd6{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-10-30 23:19:29 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@690d468b{/static/sql,null,AVAILABLE,@Spark}
2025-10-30 23:19:47 INFO  CodeGenerator:190 - Code generated in 144.4697 ms
2025-10-30 23:19:47 INFO  CodeGenerator:190 - Code generated in 144.5051 ms
2025-10-30 23:19:47 INFO  CodeGenerator:190 - Code generated in 144.4739 ms
2025-10-30 23:19:47 INFO  CodeGenerator:190 - Code generated in 144.4775 ms
2025-10-30 23:19:48 INFO  DAGScheduler:190 - Registering RDD 8 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 3
2025-10-30 23:19:48 INFO  DAGScheduler:190 - Got map stage job 3 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:19:48 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 0 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:19:48 INFO  DAGScheduler:190 - Parents of final stage: List()
2025-10-30 23:19:48 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:19:48 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[8] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:19:48 INFO  MemoryStore:190 - MemoryStore started with capacity 434.4 MiB
2025-10-30 23:19:48 INFO  MemoryStore:190 - Block broadcast_0 stored as values in memory (estimated size 15.7 KiB, free 434.4 MiB)
2025-10-30 23:19:48 INFO  MemoryStore:190 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.4 MiB)
2025-10-30 23:19:48 INFO  SparkContext:190 - Created broadcast 0 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:19:48 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[8] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:19:48 INFO  TaskSchedulerImpl:190 - Adding task set 0.0 with 1 tasks resource profile 0
2025-10-30 23:19:48 INFO  DAGScheduler:190 - Registering RDD 10 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 0
2025-10-30 23:19:48 INFO  DAGScheduler:190 - Got map stage job 0 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:19:48 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 1 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:19:48 INFO  DAGScheduler:190 - Parents of final stage: List()
2025-10-30 23:19:48 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:19:48 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 1 (MapPartitionsRDD[10] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:19:48 INFO  MemoryStore:190 - Block broadcast_1 stored as values in memory (estimated size 15.8 KiB, free 434.4 MiB)
2025-10-30 23:19:48 INFO  MemoryStore:190 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.4 MiB)
2025-10-30 23:19:48 INFO  SparkContext:190 - Created broadcast 1 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:19:48 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[10] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:19:48 INFO  TaskSchedulerImpl:190 - Adding task set 1.0 with 1 tasks resource profile 0
2025-10-30 23:19:48 INFO  TaskSetManager:190 - Starting task 0.0 in stage 0.0 (TID 0) (localhost,executor driver, partition 0, PROCESS_LOCAL, 9643 bytes)
2025-10-30 23:19:48 INFO  DAGScheduler:190 - Registering RDD 9 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 1
2025-10-30 23:19:48 INFO  DAGScheduler:190 - Got map stage job 2 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:19:48 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 2 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:19:48 INFO  DAGScheduler:190 - Parents of final stage: List()
2025-10-30 23:19:48 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:19:48 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 2 (MapPartitionsRDD[9] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:19:48 INFO  MemoryStore:190 - Block broadcast_2 stored as values in memory (estimated size 15.8 KiB, free 434.3 MiB)
2025-10-30 23:19:48 INFO  TaskSetManager:190 - Starting task 0.0 in stage 1.0 (TID 1) (localhost,executor driver, partition 0, PROCESS_LOCAL, 9643 bytes)
2025-10-30 23:19:48 INFO  MemoryStore:190 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.3 MiB)
2025-10-30 23:19:48 INFO  SparkContext:190 - Created broadcast 2 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:19:48 INFO  Executor:190 - Running task 0.0 in stage 1.0 (TID 1)
2025-10-30 23:19:48 INFO  Executor:190 - Running task 0.0 in stage 0.0 (TID 0)
2025-10-30 23:19:48 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[9] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:19:48 INFO  TaskSchedulerImpl:190 - Adding task set 2.0 with 1 tasks resource profile 0
2025-10-30 23:19:48 INFO  DAGScheduler:190 - Registering RDD 11 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 2
2025-10-30 23:19:48 INFO  DAGScheduler:190 - Got map stage job 1 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:19:48 INFO  TaskSetManager:190 - Starting task 0.0 in stage 2.0 (TID 2) (localhost,executor driver, partition 0, PROCESS_LOCAL, 9643 bytes)
2025-10-30 23:19:48 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 3 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:19:48 INFO  DAGScheduler:190 - Parents of final stage: List()
2025-10-30 23:19:48 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:19:48 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 3 (MapPartitionsRDD[11] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:19:48 INFO  Executor:190 - Running task 0.0 in stage 2.0 (TID 2)
2025-10-30 23:19:48 INFO  MemoryStore:190 - Block broadcast_3 stored as values in memory (estimated size 15.7 KiB, free 434.3 MiB)
2025-10-30 23:19:48 INFO  MemoryStore:190 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 434.3 MiB)
2025-10-30 23:19:48 INFO  SparkContext:190 - Created broadcast 3 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:19:48 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[11] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:19:48 INFO  TaskSchedulerImpl:190 - Adding task set 3.0 with 1 tasks resource profile 0
2025-10-30 23:19:48 INFO  TaskSetManager:190 - Starting task 0.0 in stage 3.0 (TID 3) (localhost,executor driver, partition 0, PROCESS_LOCAL, 9643 bytes)
2025-10-30 23:19:48 INFO  Executor:190 - Running task 0.0 in stage 3.0 (TID 3)
2025-10-30 23:19:48 INFO  CodeGenerator:190 - Code generated in 13.3271 ms
2025-10-30 23:19:48 INFO  CodeGenerator:190 - Code generated in 13.3333 ms
2025-10-30 23:19:48 INFO  CodeGenerator:190 - Code generated in 14.3902 ms
2025-10-30 23:19:48 INFO  CodeGenerator:190 - Code generated in 14.5881 ms
2025-10-30 23:19:48 INFO  CodeGenerator:190 - Code generated in 33.4125 ms
2025-10-30 23:19:48 INFO  CodeGenerator:190 - Code generated in 33.1271 ms
2025-10-30 23:19:48 INFO  SecurityManager:190 - Changing view acls to: user
2025-10-30 23:19:48 INFO  SecurityManager:190 - Changing modify acls to: user
2025-10-30 23:19:48 INFO  SecurityManager:190 - Changing view acls groups to: user
2025-10-30 23:19:48 INFO  SecurityManager:190 - Changing modify acls groups to: user
2025-10-30 23:19:48 INFO  SecurityManager:190 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: user groups with view permissions: EMPTY; users with modify permissions: user; groups with modify permissions: EMPTY; RPC SSL disabled
2025-10-30 23:19:48 INFO  JDBCRDD:184 - closed connection
2025-10-30 23:19:48 INFO  JDBCRDD:184 - closed connection
2025-10-30 23:19:48 INFO  JDBCRDD:184 - closed connection
2025-10-30 23:19:48 INFO  JDBCRDD:184 - closed connection
2025-10-30 23:19:48 INFO  Executor:190 - Finished task 0.0 in stage 3.0 (TID 3). 2150 bytes result sent to driver
2025-10-30 23:19:48 INFO  Executor:190 - Finished task 0.0 in stage 0.0 (TID 0). 2150 bytes result sent to driver
2025-10-30 23:19:48 INFO  TaskSetManager:190 - Finished task 0.0 in stage 0.0 (TID 0) in 716 ms on localhost (executor driver) (1/1)
2025-10-30 23:19:48 INFO  TaskSchedulerImpl:190 - Removed TaskSet 0.0 whose tasks have all completed, from pool
2025-10-30 23:19:48 INFO  TaskSetManager:190 - Finished task 0.0 in stage 3.0 (TID 3) in 687 ms on localhost (executor driver) (1/1)
2025-10-30 23:19:48 INFO  TaskSchedulerImpl:190 - Removed TaskSet 3.0 whose tasks have all completed, from pool
2025-10-30 23:19:48 INFO  DAGScheduler:190 - ShuffleMapStage 0 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 890 ms
2025-10-30 23:19:48 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:19:48 INFO  DAGScheduler:190 - running: HashSet(ShuffleMapStage 1, ShuffleMapStage 2, ShuffleMapStage 3)
2025-10-30 23:19:48 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:19:48 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:19:48 INFO  Executor:190 - Finished task 0.0 in stage 1.0 (TID 1). 2107 bytes result sent to driver
2025-10-30 23:19:48 INFO  TaskSetManager:190 - Finished task 0.0 in stage 1.0 (TID 1) in 728 ms on localhost (executor driver) (1/1)
2025-10-30 23:19:48 INFO  TaskSchedulerImpl:190 - Removed TaskSet 1.0 whose tasks have all completed, from pool
2025-10-30 23:19:48 INFO  DAGScheduler:190 - ShuffleMapStage 3 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 729 ms
2025-10-30 23:19:48 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:19:48 INFO  DAGScheduler:190 - running: HashSet(ShuffleMapStage 1, ShuffleMapStage 2)
2025-10-30 23:19:48 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:19:48 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:19:48 INFO  DAGScheduler:190 - ShuffleMapStage 1 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 762 ms
2025-10-30 23:19:48 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:19:48 INFO  DAGScheduler:190 - running: HashSet(ShuffleMapStage 2)
2025-10-30 23:19:48 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:19:48 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:19:48 INFO  Executor:190 - Finished task 0.0 in stage 2.0 (TID 2). 2107 bytes result sent to driver
2025-10-30 23:19:48 INFO  TaskSetManager:190 - Finished task 0.0 in stage 2.0 (TID 2) in 780 ms on localhost (executor driver) (1/1)
2025-10-30 23:19:48 INFO  DAGScheduler:190 - ShuffleMapStage 2 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 789 ms
2025-10-30 23:19:48 INFO  TaskSchedulerImpl:190 - Removed TaskSet 2.0 whose tasks have all completed, from pool
2025-10-30 23:19:48 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:19:48 INFO  DAGScheduler:190 - running: HashSet()
2025-10-30 23:19:48 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:19:48 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:19:49 INFO  ShufflePartitionsUtil:190 - For shuffle(3, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:19:49 INFO  ShufflePartitionsUtil:190 - For shuffle(0, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:19:49 INFO  ShufflePartitionsUtil:190 - For shuffle(1, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:19:49 INFO  SparkContext:190 - Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:19:49 INFO  DAGScheduler:190 - Got job 4 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:19:49 INFO  DAGScheduler:190 - Final stage: ResultStage 5 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:19:49 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 4)
2025-10-30 23:19:49 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:19:49 INFO  DAGScheduler:190 - Submitting ResultStage 5 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:19:49 INFO  MemoryStore:190 - Block broadcast_4 stored as values in memory (estimated size 8.6 KiB, free 434.4 MiB)
2025-10-30 23:19:49 INFO  SparkContext:190 - Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:19:49 INFO  MemoryStore:190 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 434.4 MiB)
2025-10-30 23:19:49 INFO  SparkContext:190 - Created broadcast 4 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:19:49 INFO  SparkContext:190 - Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:19:49 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:19:49 INFO  TaskSchedulerImpl:190 - Adding task set 5.0 with 1 tasks resource profile 0
2025-10-30 23:19:49 INFO  DAGScheduler:190 - Got job 5 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:19:49 INFO  DAGScheduler:190 - Final stage: ResultStage 7 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:19:49 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 6)
2025-10-30 23:19:49 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:19:49 INFO  DAGScheduler:190 - Submitting ResultStage 7 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:19:49 INFO  TaskSetManager:190 - Starting task 0.0 in stage 5.0 (TID 4) (localhost,executor driver, partition 0, ANY, 9827 bytes)
2025-10-30 23:19:49 INFO  Executor:190 - Running task 0.0 in stage 5.0 (TID 4)
2025-10-30 23:19:49 INFO  MemoryStore:190 - Block broadcast_5 stored as values in memory (estimated size 8.6 KiB, free 434.4 MiB)
2025-10-30 23:19:49 INFO  MemoryStore:190 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 434.4 MiB)
2025-10-30 23:19:49 INFO  SparkContext:190 - Created broadcast 5 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:19:49 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[17] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:19:49 INFO  TaskSchedulerImpl:190 - Adding task set 7.0 with 1 tasks resource profile 0
2025-10-30 23:19:49 INFO  DAGScheduler:190 - Got job 6 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:19:49 INFO  DAGScheduler:190 - Final stage: ResultStage 9 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:19:49 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 8)
2025-10-30 23:19:49 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:19:49 INFO  TaskSetManager:190 - Starting task 0.0 in stage 7.0 (TID 5) (localhost,executor driver, partition 0, ANY, 9827 bytes)
2025-10-30 23:19:49 INFO  DAGScheduler:190 - Submitting ResultStage 9 (MapPartitionsRDD[16] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:19:49 INFO  Executor:190 - Running task 0.0 in stage 7.0 (TID 5)
2025-10-30 23:19:49 INFO  MemoryStore:190 - Block broadcast_6 stored as values in memory (estimated size 8.6 KiB, free 434.4 MiB)
2025-10-30 23:19:49 INFO  MemoryStore:190 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 434.4 MiB)
2025-10-30 23:19:49 INFO  SparkContext:190 - Created broadcast 6 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:19:49 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[16] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:19:49 INFO  TaskSchedulerImpl:190 - Adding task set 9.0 with 1 tasks resource profile 0
2025-10-30 23:19:49 INFO  TaskSetManager:190 - Starting task 0.0 in stage 9.0 (TID 6) (localhost,executor driver, partition 0, ANY, 9827 bytes)
2025-10-30 23:19:49 INFO  Executor:190 - Running task 0.0 in stage 9.0 (TID 6)
2025-10-30 23:19:49 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (43.1 KiB) non-empty blocks including 1 (43.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:19:49 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (169.6 KiB) non-empty blocks including 1 (169.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:19:49 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (45.8 KiB) non-empty blocks including 1 (45.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:19:49 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 34 ms
2025-10-30 23:19:49 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 34 ms
2025-10-30 23:19:49 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 34 ms
2025-10-30 23:19:49 INFO  Executor:190 - Finished task 0.0 in stage 7.0 (TID 5). 33055 bytes result sent to driver
2025-10-30 23:19:49 INFO  Executor:190 - Finished task 0.0 in stage 5.0 (TID 4). 42727 bytes result sent to driver
2025-10-30 23:19:49 INFO  TaskSetManager:190 - Finished task 0.0 in stage 7.0 (TID 5) in 135 ms on localhost (executor driver) (1/1)
2025-10-30 23:19:49 INFO  TaskSchedulerImpl:190 - Removed TaskSet 7.0 whose tasks have all completed, from pool
2025-10-30 23:19:49 INFO  TaskSetManager:190 - Finished task 0.0 in stage 5.0 (TID 4) in 150 ms on localhost (executor driver) (1/1)
2025-10-30 23:19:49 INFO  TaskSchedulerImpl:190 - Removed TaskSet 5.0 whose tasks have all completed, from pool
2025-10-30 23:19:49 INFO  DAGScheduler:190 - ResultStage 7 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 147 ms
2025-10-30 23:19:49 INFO  DAGScheduler:190 - Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2025-10-30 23:19:49 INFO  TaskSchedulerImpl:190 - Canceling stage 7
2025-10-30 23:19:49 INFO  TaskSchedulerImpl:190 - Killing all running tasks in stage 7: Stage finished
2025-10-30 23:19:49 INFO  DAGScheduler:190 - ResultStage 5 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 177 ms
2025-10-30 23:19:49 INFO  DAGScheduler:190 - Job 5 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 163.7656 ms
2025-10-30 23:19:49 INFO  DAGScheduler:190 - Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2025-10-30 23:19:49 INFO  TaskSchedulerImpl:190 - Canceling stage 5
2025-10-30 23:19:49 INFO  TaskSchedulerImpl:190 - Killing all running tasks in stage 5: Stage finished
2025-10-30 23:19:49 INFO  DAGScheduler:190 - Job 4 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 189.7203 ms
2025-10-30 23:19:49 INFO  Executor:190 - Finished task 0.0 in stage 9.0 (TID 6). 146356 bytes result sent to driver
2025-10-30 23:19:49 INFO  TaskSetManager:190 - Finished task 0.0 in stage 9.0 (TID 6) in 122 ms on localhost (executor driver) (1/1)
2025-10-30 23:19:49 INFO  TaskSchedulerImpl:190 - Removed TaskSet 9.0 whose tasks have all completed, from pool
2025-10-30 23:19:49 INFO  DAGScheduler:190 - ResultStage 9 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 133 ms
2025-10-30 23:19:49 INFO  DAGScheduler:190 - Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
2025-10-30 23:19:49 INFO  TaskSchedulerImpl:190 - Canceling stage 9
2025-10-30 23:19:49 INFO  TaskSchedulerImpl:190 - Killing all running tasks in stage 9: Stage finished
2025-10-30 23:19:49 INFO  DAGScheduler:190 - Job 6 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 166.7756 ms
2025-10-30 23:19:49 INFO  CodeGenerator:190 - Code generated in 9.029 ms
2025-10-30 23:19:49 INFO  CodeGenerator:190 - Code generated in 9.0307 ms
2025-10-30 23:19:49 INFO  MemoryStore:190 - Block broadcast_7 stored as values in memory (estimated size 1031.8 KiB, free 432.4 MiB)
2025-10-30 23:19:49 INFO  MemoryStore:190 - Block broadcast_8 stored as values in memory (estimated size 1025.6 KiB, free 432.4 MiB)
2025-10-30 23:19:49 INFO  MemoryStore:190 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 50.6 KiB, free 432.3 MiB)
2025-10-30 23:19:49 INFO  MemoryStore:190 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 51.5 KiB, free 432.3 MiB)
2025-10-30 23:19:49 INFO  SparkContext:190 - Created broadcast 8 from $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:19:49 INFO  SparkContext:190 - Created broadcast 7 from $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:19:49 INFO  MemoryStore:190 - Block broadcast_9 stored as values in memory (estimated size 1059.8 KiB, free 431.2 MiB)
2025-10-30 23:19:49 INFO  MemoryStore:190 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 206.1 KiB, free 431.0 MiB)
2025-10-30 23:19:49 INFO  SparkContext:190 - Created broadcast 9 from $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:19:49 INFO  ShufflePartitionsUtil:190 - For shuffle(2, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:19:49 INFO  CodeGenerator:190 - Code generated in 72.3193 ms
2025-10-30 23:19:49 INFO  DAGScheduler:190 - Registering RDD 20 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 4
2025-10-30 23:19:49 INFO  DAGScheduler:190 - Got map stage job 7 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:19:49 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 11 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:19:49 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 10)
2025-10-30 23:19:49 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:19:49 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 11 (MapPartitionsRDD[20] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:19:49 INFO  MemoryStore:190 - Block broadcast_10 stored as values in memory (estimated size 70.7 KiB, free 430.9 MiB)
2025-10-30 23:19:49 INFO  MemoryStore:190 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 28.5 KiB, free 430.9 MiB)
2025-10-30 23:19:49 INFO  SparkContext:190 - Created broadcast 10 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:19:49 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[20] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:19:49 INFO  TaskSchedulerImpl:190 - Adding task set 11.0 with 1 tasks resource profile 0
2025-10-30 23:19:49 INFO  TaskSetManager:190 - Starting task 0.0 in stage 11.0 (TID 7) (localhost,executor driver, partition 0, ANY, 9816 bytes)
2025-10-30 23:19:49 INFO  Executor:190 - Running task 0.0 in stage 11.0 (TID 7)
2025-10-30 23:19:49 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (13.8 KiB) non-empty blocks including 1 (13.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:19:49 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 1 ms
2025-10-30 23:19:49 INFO  CodeGenerator:190 - Code generated in 56.5124 ms
2025-10-30 23:19:49 INFO  CodeGenerator:190 - Code generated in 17.3117 ms
2025-10-30 23:19:49 INFO  CodeGenerator:190 - Code generated in 8.6516 ms
2025-10-30 23:19:49 INFO  CodeGenerator:190 - Code generated in 6.9682 ms
2025-10-30 23:19:49 INFO  CodeGenerator:190 - Code generated in 10.0142 ms
2025-10-30 23:19:50 INFO  Executor:190 - Finished task 0.0 in stage 11.0 (TID 7). 9387 bytes result sent to driver
2025-10-30 23:19:50 INFO  TaskSetManager:190 - Finished task 0.0 in stage 11.0 (TID 7) in 481 ms on localhost (executor driver) (1/1)
2025-10-30 23:19:50 INFO  TaskSchedulerImpl:190 - Removed TaskSet 11.0 whose tasks have all completed, from pool
2025-10-30 23:19:50 INFO  DAGScheduler:190 - ShuffleMapStage 11 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 497 ms
2025-10-30 23:19:50 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:19:50 INFO  DAGScheduler:190 - running: HashSet()
2025-10-30 23:19:50 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:19:50 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:19:50 INFO  ShufflePartitionsUtil:190 - For shuffle(4, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:19:50 INFO  CodeGenerator:190 - Code generated in 24.2151 ms
2025-10-30 23:19:50 INFO  HashAggregateExec:190 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-10-30 23:19:50 INFO  CodeGenerator:190 - Code generated in 19.1 ms
2025-10-30 23:19:50 INFO  SparkContext:190 - Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:19:50 INFO  DAGScheduler:190 - Got job 8 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:19:50 INFO  DAGScheduler:190 - Final stage: ResultStage 14 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:19:50 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 13)
2025-10-30 23:19:50 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:19:50 INFO  DAGScheduler:190 - Submitting ResultStage 14 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:19:50 INFO  MemoryStore:190 - Block broadcast_11 stored as values in memory (estimated size 69.7 KiB, free 430.9 MiB)
2025-10-30 23:19:50 INFO  MemoryStore:190 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 430.9 MiB)
2025-10-30 23:19:50 INFO  SparkContext:190 - Created broadcast 11 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:19:50 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[24] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:19:50 INFO  TaskSchedulerImpl:190 - Adding task set 14.0 with 1 tasks resource profile 0
2025-10-30 23:19:50 INFO  TaskSetManager:190 - Starting task 0.0 in stage 14.0 (TID 8) (localhost,executor driver, partition 0, ANY, 9808 bytes)
2025-10-30 23:19:50 INFO  Executor:190 - Running task 0.0 in stage 14.0 (TID 8)
2025-10-30 23:19:50 INFO  CodeGenerator:190 - Code generated in 8.3844 ms
2025-10-30 23:19:50 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (12.7 KiB) non-empty blocks including 1 (12.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:19:50 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 1 ms
2025-10-30 23:19:50 INFO  CodeGenerator:190 - Code generated in 23.4553 ms
2025-10-30 23:19:50 INFO  Executor:190 - Finished task 0.0 in stage 14.0 (TID 8). 10957 bytes result sent to driver
2025-10-30 23:19:50 INFO  TaskSetManager:190 - Finished task 0.0 in stage 14.0 (TID 8) in 98 ms on localhost (executor driver) (1/1)
2025-10-30 23:19:50 INFO  TaskSchedulerImpl:190 - Removed TaskSet 14.0 whose tasks have all completed, from pool
2025-10-30 23:19:50 INFO  DAGScheduler:190 - ResultStage 14 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 117 ms
2025-10-30 23:19:50 INFO  DAGScheduler:190 - Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
2025-10-30 23:19:50 INFO  TaskSchedulerImpl:190 - Canceling stage 14
2025-10-30 23:19:50 INFO  TaskSchedulerImpl:190 - Killing all running tasks in stage 14: Stage finished
2025-10-30 23:19:50 INFO  DAGScheduler:190 - Job 8 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 131.6409 ms
2025-10-30 23:19:50 INFO  CodeGenerator:190 - Code generated in 11.1317 ms
2025-10-30 23:19:50 INFO  CodeGenerator:190 - Code generated in 9.622 ms
2025-10-30 23:19:54 INFO  CodeGenerator:190 - Code generated in 4.8335 ms
2025-10-30 23:19:54 INFO  CodeGenerator:190 - Code generated in 5.0776 ms
2025-10-30 23:19:54 INFO  DAGScheduler:190 - Registering RDD 29 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 5
2025-10-30 23:19:54 INFO  DAGScheduler:190 - Got map stage job 9 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:19:54 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 15 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:19:54 INFO  DAGScheduler:190 - Parents of final stage: List()
2025-10-30 23:19:54 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:19:54 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 15 (MapPartitionsRDD[29] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:19:54 INFO  MemoryStore:190 - Block broadcast_12 stored as values in memory (estimated size 15.9 KiB, free 430.8 MiB)
2025-10-30 23:19:54 INFO  MemoryStore:190 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 430.8 MiB)
2025-10-30 23:19:54 INFO  SparkContext:190 - Created broadcast 12 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:19:54 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[29] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:19:54 INFO  TaskSchedulerImpl:190 - Adding task set 15.0 with 1 tasks resource profile 0
2025-10-30 23:19:54 INFO  DAGScheduler:190 - Registering RDD 30 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 6
2025-10-30 23:19:54 INFO  DAGScheduler:190 - Got map stage job 10 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:19:54 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 16 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:19:54 INFO  DAGScheduler:190 - Parents of final stage: List()
2025-10-30 23:19:54 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:19:54 INFO  TaskSetManager:190 - Starting task 0.0 in stage 15.0 (TID 9) (localhost,executor driver, partition 0, PROCESS_LOCAL, 9643 bytes)
2025-10-30 23:19:54 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 16 (MapPartitionsRDD[30] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:19:54 INFO  Executor:190 - Running task 0.0 in stage 15.0 (TID 9)
2025-10-30 23:19:54 INFO  MemoryStore:190 - Block broadcast_13 stored as values in memory (estimated size 15.8 KiB, free 430.8 MiB)
2025-10-30 23:19:54 INFO  MemoryStore:190 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 430.8 MiB)
2025-10-30 23:19:54 INFO  SparkContext:190 - Created broadcast 13 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:19:54 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[30] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:19:54 INFO  TaskSchedulerImpl:190 - Adding task set 16.0 with 1 tasks resource profile 0
2025-10-30 23:19:54 INFO  TaskSetManager:190 - Starting task 0.0 in stage 16.0 (TID 10) (localhost,executor driver, partition 0, PROCESS_LOCAL, 9643 bytes)
2025-10-30 23:19:54 INFO  Executor:190 - Running task 0.0 in stage 16.0 (TID 10)
2025-10-30 23:19:54 INFO  CodeGenerator:190 - Code generated in 6.5578 ms
2025-10-30 23:19:54 INFO  CodeGenerator:190 - Code generated in 5.3048 ms
2025-10-30 23:19:54 INFO  JDBCRDD:184 - closed connection
2025-10-30 23:19:54 INFO  JDBCRDD:184 - closed connection
2025-10-30 23:19:54 INFO  Executor:190 - Finished task 0.0 in stage 15.0 (TID 9). 2064 bytes result sent to driver
2025-10-30 23:19:54 INFO  TaskSetManager:190 - Finished task 0.0 in stage 15.0 (TID 9) in 73 ms on localhost (executor driver) (1/1)
2025-10-30 23:19:54 INFO  TaskSchedulerImpl:190 - Removed TaskSet 15.0 whose tasks have all completed, from pool
2025-10-30 23:19:54 INFO  DAGScheduler:190 - ShuffleMapStage 15 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 78 ms
2025-10-30 23:19:54 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:19:54 INFO  Executor:190 - Finished task 0.0 in stage 16.0 (TID 10). 2021 bytes result sent to driver
2025-10-30 23:19:54 INFO  DAGScheduler:190 - running: HashSet(ShuffleMapStage 16)
2025-10-30 23:19:54 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:19:54 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:19:54 INFO  TaskSetManager:190 - Finished task 0.0 in stage 16.0 (TID 10) in 70 ms on localhost (executor driver) (1/1)
2025-10-30 23:19:54 INFO  TaskSchedulerImpl:190 - Removed TaskSet 16.0 whose tasks have all completed, from pool
2025-10-30 23:19:54 INFO  DAGScheduler:190 - ShuffleMapStage 16 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 75 ms
2025-10-30 23:19:54 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:19:54 INFO  DAGScheduler:190 - running: HashSet()
2025-10-30 23:19:54 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:19:54 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:19:54 INFO  ShufflePartitionsUtil:190 - For shuffle(6, 5, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:19:55 INFO  CodeGenerator:190 - Code generated in 58.4378 ms
2025-10-30 23:19:55 INFO  CodeGenerator:190 - Code generated in 12.0778 ms
2025-10-30 23:19:55 INFO  CodeGenerator:190 - Code generated in 10.1862 ms
2025-10-30 23:19:55 INFO  DAGScheduler:190 - Registering RDD 37 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 7
2025-10-30 23:19:55 INFO  DAGScheduler:190 - Got map stage job 11 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:19:55 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 19 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:19:55 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 17, ShuffleMapStage 18)
2025-10-30 23:19:55 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:19:55 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 19 (MapPartitionsRDD[37] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:19:55 INFO  MemoryStore:190 - Block broadcast_14 stored as values in memory (estimated size 56.3 KiB, free 430.8 MiB)
2025-10-30 23:19:55 INFO  MemoryStore:190 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 23.8 KiB, free 430.7 MiB)
2025-10-30 23:19:55 INFO  SparkContext:190 - Created broadcast 14 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:19:55 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[37] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:19:55 INFO  TaskSchedulerImpl:190 - Adding task set 19.0 with 1 tasks resource profile 0
2025-10-30 23:19:55 INFO  TaskSetManager:190 - Starting task 0.0 in stage 19.0 (TID 11) (localhost,executor driver, partition 0, ANY, 10295 bytes)
2025-10-30 23:19:55 INFO  Executor:190 - Running task 0.0 in stage 19.0 (TID 11)
2025-10-30 23:19:55 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (7.3 KiB) non-empty blocks including 1 (7.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:19:55 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 0 ms
2025-10-30 23:19:55 INFO  CodeGenerator:190 - Code generated in 6.7267 ms
2025-10-30 23:19:55 INFO  CodeGenerator:190 - Code generated in 6.2698 ms
2025-10-30 23:19:55 INFO  CodeGenerator:190 - Code generated in 3.8801 ms
2025-10-30 23:19:55 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (1122.0 B) non-empty blocks including 1 (1122.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:19:55 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 1 ms
2025-10-30 23:19:55 INFO  CodeGenerator:190 - Code generated in 7.5992 ms
2025-10-30 23:19:55 INFO  CodeGenerator:190 - Code generated in 3.8408 ms
2025-10-30 23:19:55 INFO  CodeGenerator:190 - Code generated in 3.79 ms
2025-10-30 23:19:55 INFO  CodeGenerator:190 - Code generated in 29.1524 ms
2025-10-30 23:19:55 INFO  Executor:190 - Finished task 0.0 in stage 19.0 (TID 11). 6473 bytes result sent to driver
2025-10-30 23:19:55 INFO  TaskSetManager:190 - Finished task 0.0 in stage 19.0 (TID 11) in 179 ms on localhost (executor driver) (1/1)
2025-10-30 23:19:55 INFO  TaskSchedulerImpl:190 - Removed TaskSet 19.0 whose tasks have all completed, from pool
2025-10-30 23:19:55 INFO  DAGScheduler:190 - ShuffleMapStage 19 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 187 ms
2025-10-30 23:19:55 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:19:55 INFO  DAGScheduler:190 - running: HashSet()
2025-10-30 23:19:55 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:19:55 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:19:55 INFO  ShufflePartitionsUtil:190 - For shuffle(7, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:19:55 INFO  HashAggregateExec:190 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-10-30 23:19:55 INFO  SparkContext:190 - Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:19:55 INFO  DAGScheduler:190 - Got job 12 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:19:55 INFO  DAGScheduler:190 - Final stage: ResultStage 23 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:19:55 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 22)
2025-10-30 23:19:55 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:19:55 INFO  DAGScheduler:190 - Submitting ResultStage 23 (MapPartitionsRDD[41] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:19:55 INFO  MemoryStore:190 - Block broadcast_15 stored as values in memory (estimated size 51.1 KiB, free 431.0 MiB)
2025-10-30 23:19:55 INFO  MemoryStore:190 - Block broadcast_15_piece0 stored as bytes in memory (estimated size 21.8 KiB, free 431.0 MiB)
2025-10-30 23:19:55 INFO  SparkContext:190 - Created broadcast 15 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:19:55 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[41] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:19:55 INFO  TaskSchedulerImpl:190 - Adding task set 23.0 with 1 tasks resource profile 0
2025-10-30 23:19:55 INFO  TaskSetManager:190 - Starting task 0.0 in stage 23.0 (TID 12) (localhost,executor driver, partition 0, ANY, 9808 bytes)
2025-10-30 23:19:55 INFO  Executor:190 - Running task 0.0 in stage 23.0 (TID 12)
2025-10-30 23:19:55 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (1168.0 B) non-empty blocks including 1 (1168.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:19:55 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 2 ms
2025-10-30 23:19:55 INFO  Executor:190 - Finished task 0.0 in stage 23.0 (TID 12). 8353 bytes result sent to driver
2025-10-30 23:19:55 INFO  TaskSetManager:190 - Finished task 0.0 in stage 23.0 (TID 12) in 64 ms on localhost (executor driver) (1/1)
2025-10-30 23:19:55 INFO  TaskSchedulerImpl:190 - Removed TaskSet 23.0 whose tasks have all completed, from pool
2025-10-30 23:19:55 INFO  DAGScheduler:190 - ResultStage 23 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 83 ms
2025-10-30 23:19:55 INFO  DAGScheduler:190 - Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
2025-10-30 23:19:55 INFO  TaskSchedulerImpl:190 - Canceling stage 23
2025-10-30 23:19:55 INFO  TaskSchedulerImpl:190 - Killing all running tasks in stage 23: Stage finished
2025-10-30 23:19:55 INFO  DAGScheduler:190 - Job 12 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 88.0292 ms
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Registering RDD 51 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 10
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Got map stage job 13 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 24 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Parents of final stage: List()
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 24 (MapPartitionsRDD[51] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:20:11 INFO  MemoryStore:190 - Block broadcast_16 stored as values in memory (estimated size 15.8 KiB, free 431.0 MiB)
2025-10-30 23:20:11 INFO  CodeGenerator:190 - Code generated in 8.4791 ms
2025-10-30 23:20:11 INFO  MemoryStore:190 - Block broadcast_16_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 431.0 MiB)
2025-10-30 23:20:11 INFO  SparkContext:190 - Created broadcast 16 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[51] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:20:11 INFO  TaskSchedulerImpl:190 - Adding task set 24.0 with 1 tasks resource profile 0
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Registering RDD 52 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 9
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Got map stage job 15 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 25 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Parents of final stage: List()
2025-10-30 23:20:11 INFO  TaskSetManager:190 - Starting task 0.0 in stage 24.0 (TID 13) (localhost,executor driver, partition 0, PROCESS_LOCAL, 9643 bytes)
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 25 (MapPartitionsRDD[52] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:20:11 INFO  Executor:190 - Running task 0.0 in stage 24.0 (TID 13)
2025-10-30 23:20:11 INFO  MemoryStore:190 - Block broadcast_17 stored as values in memory (estimated size 15.8 KiB, free 430.9 MiB)
2025-10-30 23:20:11 INFO  MemoryStore:190 - Block broadcast_17_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 430.9 MiB)
2025-10-30 23:20:11 INFO  CodeGenerator:190 - Code generated in 5.7935 ms
2025-10-30 23:20:11 INFO  SparkContext:190 - Created broadcast 17 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[52] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:20:11 INFO  TaskSchedulerImpl:190 - Adding task set 25.0 with 1 tasks resource profile 0
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Registering RDD 50 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 8
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Got map stage job 14 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 26 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:20:11 INFO  TaskSetManager:190 - Starting task 0.0 in stage 25.0 (TID 14) (localhost,executor driver, partition 0, PROCESS_LOCAL, 9643 bytes)
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Parents of final stage: List()
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 26 (MapPartitionsRDD[50] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:20:11 INFO  Executor:190 - Running task 0.0 in stage 25.0 (TID 14)
2025-10-30 23:20:11 INFO  MemoryStore:190 - Block broadcast_18 stored as values in memory (estimated size 15.8 KiB, free 430.9 MiB)
2025-10-30 23:20:11 INFO  MemoryStore:190 - Block broadcast_18_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 430.9 MiB)
2025-10-30 23:20:11 INFO  SparkContext:190 - Created broadcast 18 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[50] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:20:11 INFO  TaskSchedulerImpl:190 - Adding task set 26.0 with 1 tasks resource profile 0
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Registering RDD 54 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 11
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Got map stage job 16 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 27 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Parents of final stage: List()
2025-10-30 23:20:11 INFO  TaskSetManager:190 - Starting task 0.0 in stage 26.0 (TID 15) (localhost,executor driver, partition 0, PROCESS_LOCAL, 9643 bytes)
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 27 (MapPartitionsRDD[54] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:20:11 INFO  Executor:190 - Running task 0.0 in stage 26.0 (TID 15)
2025-10-30 23:20:11 INFO  MemoryStore:190 - Block broadcast_19 stored as values in memory (estimated size 15.3 KiB, free 430.9 MiB)
2025-10-30 23:20:11 INFO  MemoryStore:190 - Block broadcast_19_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 430.9 MiB)
2025-10-30 23:20:11 INFO  SparkContext:190 - Created broadcast 19 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[54] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:20:11 INFO  TaskSchedulerImpl:190 - Adding task set 27.0 with 1 tasks resource profile 0
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Registering RDD 56 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 12
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Got map stage job 17 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:20:11 INFO  TaskSetManager:190 - Starting task 0.0 in stage 27.0 (TID 16) (localhost,executor driver, partition 0, PROCESS_LOCAL, 9643 bytes)
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 28 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Parents of final stage: List()
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:20:11 INFO  Executor:190 - Running task 0.0 in stage 27.0 (TID 16)
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 28 (MapPartitionsRDD[56] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:20:11 INFO  MemoryStore:190 - Block broadcast_20 stored as values in memory (estimated size 15.8 KiB, free 430.9 MiB)
2025-10-30 23:20:11 INFO  MemoryStore:190 - Block broadcast_20_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 430.9 MiB)
2025-10-30 23:20:11 INFO  SparkContext:190 - Created broadcast 20 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[56] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:20:11 INFO  TaskSchedulerImpl:190 - Adding task set 28.0 with 1 tasks resource profile 0
2025-10-30 23:20:11 INFO  TaskSetManager:190 - Starting task 0.0 in stage 28.0 (TID 17) (localhost,executor driver, partition 0, PROCESS_LOCAL, 9643 bytes)
2025-10-30 23:20:11 INFO  Executor:190 - Running task 0.0 in stage 28.0 (TID 17)
2025-10-30 23:20:11 INFO  JDBCRDD:184 - closed connection
2025-10-30 23:20:11 INFO  CodeGenerator:190 - Code generated in 8.4515 ms
2025-10-30 23:20:11 INFO  JDBCRDD:184 - closed connection
2025-10-30 23:20:11 INFO  JDBCRDD:184 - closed connection
2025-10-30 23:20:11 INFO  Executor:190 - Finished task 0.0 in stage 26.0 (TID 15). 2064 bytes result sent to driver
2025-10-30 23:20:11 INFO  TaskSetManager:190 - Finished task 0.0 in stage 26.0 (TID 15) in 161 ms on localhost (executor driver) (1/1)
2025-10-30 23:20:11 INFO  TaskSchedulerImpl:190 - Removed TaskSet 26.0 whose tasks have all completed, from pool
2025-10-30 23:20:11 INFO  DAGScheduler:190 - ShuffleMapStage 26 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 171 ms
2025-10-30 23:20:11 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:20:11 INFO  DAGScheduler:190 - running: HashSet(ShuffleMapStage 24, ShuffleMapStage 25, ShuffleMapStage 27, ShuffleMapStage 28)
2025-10-30 23:20:11 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:20:11 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:20:11 INFO  Executor:190 - Finished task 0.0 in stage 27.0 (TID 16). 2021 bytes result sent to driver
2025-10-30 23:20:11 INFO  TaskSetManager:190 - Finished task 0.0 in stage 27.0 (TID 16) in 164 ms on localhost (executor driver) (1/1)
2025-10-30 23:20:11 INFO  TaskSchedulerImpl:190 - Removed TaskSet 27.0 whose tasks have all completed, from pool
2025-10-30 23:20:11 INFO  DAGScheduler:190 - ShuffleMapStage 27 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 172 ms
2025-10-30 23:20:11 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:20:11 INFO  DAGScheduler:190 - running: HashSet(ShuffleMapStage 24, ShuffleMapStage 25, ShuffleMapStage 28)
2025-10-30 23:20:11 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:20:11 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:20:11 INFO  ShufflePartitionsUtil:190 - For shuffle(8, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:20:11 INFO  CodeGenerator:190 - Code generated in 6.838 ms
2025-10-30 23:20:11 INFO  JDBCRDD:184 - closed connection
2025-10-30 23:20:11 INFO  SparkContext:190 - Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Got job 18 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Final stage: ResultStage 30 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 29)
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Submitting ResultStage 30 (MapPartitionsRDD[58] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:20:11 INFO  MemoryStore:190 - Block broadcast_21 stored as values in memory (estimated size 8.6 KiB, free 430.9 MiB)
2025-10-30 23:20:11 INFO  MemoryStore:190 - Block broadcast_21_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 430.9 MiB)
2025-10-30 23:20:11 INFO  SparkContext:190 - Created broadcast 21 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[58] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:20:11 INFO  TaskSchedulerImpl:190 - Adding task set 30.0 with 1 tasks resource profile 0
2025-10-30 23:20:11 INFO  TaskSetManager:190 - Starting task 0.0 in stage 30.0 (TID 18) (localhost,executor driver, partition 0, ANY, 9827 bytes)
2025-10-30 23:20:11 INFO  Executor:190 - Running task 0.0 in stage 30.0 (TID 18)
2025-10-30 23:20:11 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (7.3 KiB) non-empty blocks including 1 (7.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:20:11 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 1 ms
2025-10-30 23:20:11 INFO  Executor:190 - Finished task 0.0 in stage 30.0 (TID 18). 10086 bytes result sent to driver
2025-10-30 23:20:11 INFO  TaskSetManager:190 - Finished task 0.0 in stage 30.0 (TID 18) in 13 ms on localhost (executor driver) (1/1)
2025-10-30 23:20:11 INFO  TaskSchedulerImpl:190 - Removed TaskSet 30.0 whose tasks have all completed, from pool
2025-10-30 23:20:11 INFO  DAGScheduler:190 - ResultStage 30 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 22 ms
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
2025-10-30 23:20:11 INFO  TaskSchedulerImpl:190 - Canceling stage 30
2025-10-30 23:20:11 INFO  TaskSchedulerImpl:190 - Killing all running tasks in stage 30: Stage finished
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Job 18 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 27.9801 ms
2025-10-30 23:20:11 INFO  MemoryStore:190 - Block broadcast_22 stored as values in memory (estimated size 1024.1 KiB, free 429.9 MiB)
2025-10-30 23:20:11 INFO  MemoryStore:190 - Block broadcast_22_piece0 stored as bytes in memory (estimated size 11.1 KiB, free 429.8 MiB)
2025-10-30 23:20:11 INFO  SparkContext:190 - Created broadcast 22 from $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:20:11 INFO  ShufflePartitionsUtil:190 - For shuffle(11, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:20:11 INFO  CodeGenerator:190 - Code generated in 12.8992 ms
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Registering RDD 61 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 13
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Got map stage job 19 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 32 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 31)
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 32 (MapPartitionsRDD[61] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:20:11 INFO  JDBCRDD:184 - closed connection
2025-10-30 23:20:11 INFO  MemoryStore:190 - Block broadcast_23 stored as values in memory (estimated size 16.0 KiB, free 429.9 MiB)
2025-10-30 23:20:11 INFO  MemoryStore:190 - Block broadcast_23_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 429.9 MiB)
2025-10-30 23:20:11 INFO  SparkContext:190 - Created broadcast 23 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[61] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:20:11 INFO  TaskSchedulerImpl:190 - Adding task set 32.0 with 1 tasks resource profile 0
2025-10-30 23:20:11 INFO  TaskSetManager:190 - Starting task 0.0 in stage 32.0 (TID 19) (localhost,executor driver, partition 0, ANY, 9816 bytes)
2025-10-30 23:20:11 INFO  Executor:190 - Running task 0.0 in stage 32.0 (TID 19)
2025-10-30 23:20:11 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (1122.0 B) non-empty blocks including 1 (1122.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:20:11 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 1 ms
2025-10-30 23:20:11 INFO  Executor:190 - Finished task 0.0 in stage 24.0 (TID 13). 2107 bytes result sent to driver
2025-10-30 23:20:11 INFO  TaskSetManager:190 - Finished task 0.0 in stage 24.0 (TID 13) in 419 ms on localhost (executor driver) (1/1)
2025-10-30 23:20:11 INFO  TaskSchedulerImpl:190 - Removed TaskSet 24.0 whose tasks have all completed, from pool
2025-10-30 23:20:11 INFO  DAGScheduler:190 - ShuffleMapStage 24 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 426 ms
2025-10-30 23:20:11 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:20:11 INFO  DAGScheduler:190 - running: HashSet(ShuffleMapStage 32, ShuffleMapStage 25, ShuffleMapStage 28)
2025-10-30 23:20:11 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:20:11 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:20:11 INFO  CodeGenerator:190 - Code generated in 9.2628 ms
2025-10-30 23:20:11 INFO  ShufflePartitionsUtil:190 - For shuffle(10, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:20:11 INFO  SparkContext:190 - Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Got job 20 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Final stage: ResultStage 34 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 33)
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Submitting ResultStage 34 (MapPartitionsRDD[63] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:20:11 INFO  MemoryStore:190 - Block broadcast_24 stored as values in memory (estimated size 8.6 KiB, free 429.9 MiB)
2025-10-30 23:20:11 INFO  MemoryStore:190 - Block broadcast_24_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 429.9 MiB)
2025-10-30 23:20:11 INFO  SparkContext:190 - Created broadcast 24 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[63] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:20:11 INFO  TaskSchedulerImpl:190 - Adding task set 34.0 with 1 tasks resource profile 0
2025-10-30 23:20:11 INFO  TaskSetManager:190 - Starting task 0.0 in stage 34.0 (TID 20) (localhost,executor driver, partition 0, ANY, 9827 bytes)
2025-10-30 23:20:11 INFO  Executor:190 - Running task 0.0 in stage 34.0 (TID 20)
2025-10-30 23:20:11 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (43.1 KiB) non-empty blocks including 1 (43.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:20:11 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 1 ms
2025-10-30 23:20:11 INFO  Executor:190 - Finished task 0.0 in stage 34.0 (TID 20). 32969 bytes result sent to driver
2025-10-30 23:20:11 INFO  TaskSetManager:190 - Finished task 0.0 in stage 34.0 (TID 20) in 12 ms on localhost (executor driver) (1/1)
2025-10-30 23:20:11 INFO  TaskSchedulerImpl:190 - Removed TaskSet 34.0 whose tasks have all completed, from pool
2025-10-30 23:20:11 INFO  DAGScheduler:190 - ResultStage 34 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 19 ms
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
2025-10-30 23:20:11 INFO  TaskSchedulerImpl:190 - Canceling stage 34
2025-10-30 23:20:11 INFO  TaskSchedulerImpl:190 - Killing all running tasks in stage 34: Stage finished
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Job 20 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 21.2247 ms
2025-10-30 23:20:11 INFO  MemoryStore:190 - Block broadcast_25 stored as values in memory (estimated size 1031.8 KiB, free 428.9 MiB)
2025-10-30 23:20:11 INFO  MemoryStore:190 - Block broadcast_25_piece0 stored as bytes in memory (estimated size 50.6 KiB, free 428.9 MiB)
2025-10-30 23:20:11 INFO  SparkContext:190 - Created broadcast 25 from $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:20:11 INFO  Executor:190 - Finished task 0.0 in stage 25.0 (TID 14). 2064 bytes result sent to driver
2025-10-30 23:20:11 INFO  TaskSetManager:190 - Finished task 0.0 in stage 25.0 (TID 14) in 527 ms on localhost (executor driver) (1/1)
2025-10-30 23:20:11 INFO  TaskSchedulerImpl:190 - Removed TaskSet 25.0 whose tasks have all completed, from pool
2025-10-30 23:20:11 INFO  DAGScheduler:190 - ShuffleMapStage 25 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 532 ms
2025-10-30 23:20:11 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:20:11 INFO  DAGScheduler:190 - running: HashSet(ShuffleMapStage 32, ShuffleMapStage 28)
2025-10-30 23:20:11 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:20:11 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:20:11 INFO  ShufflePartitionsUtil:190 - For shuffle(9, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:20:11 INFO  SparkContext:190 - Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Got job 21 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Final stage: ResultStage 36 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 35)
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Submitting ResultStage 36 (MapPartitionsRDD[65] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:20:11 INFO  MemoryStore:190 - Block broadcast_26 stored as values in memory (estimated size 8.6 KiB, free 428.9 MiB)
2025-10-30 23:20:11 INFO  MemoryStore:190 - Block broadcast_26_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 428.9 MiB)
2025-10-30 23:20:11 INFO  SparkContext:190 - Created broadcast 26 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[65] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:20:11 INFO  TaskSchedulerImpl:190 - Adding task set 36.0 with 1 tasks resource profile 0
2025-10-30 23:20:11 INFO  TaskSetManager:190 - Starting task 0.0 in stage 36.0 (TID 21) (localhost,executor driver, partition 0, ANY, 9827 bytes)
2025-10-30 23:20:11 INFO  Executor:190 - Running task 0.0 in stage 36.0 (TID 21)
2025-10-30 23:20:11 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (169.6 KiB) non-empty blocks including 1 (169.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:20:11 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 0 ms
2025-10-30 23:20:11 INFO  Executor:190 - Finished task 0.0 in stage 36.0 (TID 21). 146356 bytes result sent to driver
2025-10-30 23:20:11 INFO  TaskSetManager:190 - Finished task 0.0 in stage 36.0 (TID 21) in 15 ms on localhost (executor driver) (1/1)
2025-10-30 23:20:11 INFO  TaskSchedulerImpl:190 - Removed TaskSet 36.0 whose tasks have all completed, from pool
2025-10-30 23:20:11 INFO  DAGScheduler:190 - ResultStage 36 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 20 ms
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
2025-10-30 23:20:11 INFO  TaskSchedulerImpl:190 - Canceling stage 36
2025-10-30 23:20:11 INFO  TaskSchedulerImpl:190 - Killing all running tasks in stage 36: Stage finished
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Job 21 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 23.7564 ms
2025-10-30 23:20:11 INFO  MemoryStore:190 - Block broadcast_27 stored as values in memory (estimated size 1059.8 KiB, free 427.8 MiB)
2025-10-30 23:20:11 INFO  MemoryStore:190 - Block broadcast_27_piece0 stored as bytes in memory (estimated size 206.1 KiB, free 427.6 MiB)
2025-10-30 23:20:11 INFO  SparkContext:190 - Created broadcast 27 from $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:20:11 INFO  Executor:190 - Finished task 0.0 in stage 28.0 (TID 17). 2064 bytes result sent to driver
2025-10-30 23:20:11 INFO  TaskSetManager:190 - Finished task 0.0 in stage 28.0 (TID 17) in 572 ms on localhost (executor driver) (1/1)
2025-10-30 23:20:11 INFO  TaskSchedulerImpl:190 - Removed TaskSet 28.0 whose tasks have all completed, from pool
2025-10-30 23:20:11 INFO  DAGScheduler:190 - ShuffleMapStage 28 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 590 ms
2025-10-30 23:20:11 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:20:11 INFO  DAGScheduler:190 - running: HashSet(ShuffleMapStage 32)
2025-10-30 23:20:11 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:20:11 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:20:11 INFO  ShufflePartitionsUtil:190 - For shuffle(12, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:20:11 INFO  SparkContext:190 - Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Got job 22 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Final stage: ResultStage 38 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 37)
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Submitting ResultStage 38 (MapPartitionsRDD[67] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:20:11 INFO  MemoryStore:190 - Block broadcast_28 stored as values in memory (estimated size 8.6 KiB, free 427.6 MiB)
2025-10-30 23:20:11 INFO  MemoryStore:190 - Block broadcast_28_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 427.6 MiB)
2025-10-30 23:20:11 INFO  SparkContext:190 - Created broadcast 28 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[67] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:20:11 INFO  TaskSchedulerImpl:190 - Adding task set 38.0 with 1 tasks resource profile 0
2025-10-30 23:20:11 INFO  TaskSetManager:190 - Starting task 0.0 in stage 38.0 (TID 22) (localhost,executor driver, partition 0, ANY, 9827 bytes)
2025-10-30 23:20:11 INFO  Executor:190 - Running task 0.0 in stage 38.0 (TID 22)
2025-10-30 23:20:11 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (153.6 KiB) non-empty blocks including 1 (153.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:20:11 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 0 ms
2025-10-30 23:20:11 INFO  Executor:190 - Finished task 0.0 in stage 32.0 (TID 19). 4172 bytes result sent to driver
2025-10-30 23:20:11 INFO  TaskSetManager:190 - Finished task 0.0 in stage 32.0 (TID 19) in 258 ms on localhost (executor driver) (1/1)
2025-10-30 23:20:11 INFO  TaskSchedulerImpl:190 - Removed TaskSet 32.0 whose tasks have all completed, from pool
2025-10-30 23:20:11 INFO  DAGScheduler:190 - ShuffleMapStage 32 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 267 ms
2025-10-30 23:20:11 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:20:11 INFO  Executor:190 - Finished task 0.0 in stage 38.0 (TID 22). 128185 bytes result sent to driver
2025-10-30 23:20:11 INFO  DAGScheduler:190 - running: HashSet(ResultStage 38)
2025-10-30 23:20:11 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:20:11 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:20:11 INFO  TaskSetManager:190 - Finished task 0.0 in stage 38.0 (TID 22) in 15 ms on localhost (executor driver) (1/1)
2025-10-30 23:20:11 INFO  DAGScheduler:190 - ResultStage 38 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 21 ms
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
2025-10-30 23:20:11 INFO  TaskSchedulerImpl:190 - Removed TaskSet 38.0 whose tasks have all completed, from pool
2025-10-30 23:20:11 INFO  TaskSchedulerImpl:190 - Canceling stage 38
2025-10-30 23:20:11 INFO  TaskSchedulerImpl:190 - Killing all running tasks in stage 38: Stage finished
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Job 22 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 23.7814 ms
2025-10-30 23:20:11 INFO  MemoryStore:190 - Block broadcast_29 stored as values in memory (estimated size 1149.4 KiB, free 426.5 MiB)
2025-10-30 23:20:11 INFO  MemoryStore:190 - Block broadcast_29_piece0 stored as bytes in memory (estimated size 186.3 KiB, free 426.3 MiB)
2025-10-30 23:20:11 INFO  SparkContext:190 - Created broadcast 29 from $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:20:11 INFO  ShufflePartitionsUtil:190 - For shuffle(13, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:20:11 INFO  CodeGenerator:190 - Code generated in 23.9721 ms
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Registering RDD 70 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 14
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Got map stage job 23 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 41 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 40)
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 41 (MapPartitionsRDD[70] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:20:11 INFO  MemoryStore:190 - Block broadcast_30 stored as values in memory (estimated size 82.1 KiB, free 426.2 MiB)
2025-10-30 23:20:11 INFO  MemoryStore:190 - Block broadcast_30_piece0 stored as bytes in memory (estimated size 31.8 KiB, free 426.2 MiB)
2025-10-30 23:20:11 INFO  SparkContext:190 - Created broadcast 30 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:20:11 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[70] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:20:11 INFO  TaskSchedulerImpl:190 - Adding task set 41.0 with 1 tasks resource profile 0
2025-10-30 23:20:11 INFO  TaskSetManager:190 - Starting task 0.0 in stage 41.0 (TID 23) (localhost,executor driver, partition 0, ANY, 9816 bytes)
2025-10-30 23:20:11 INFO  Executor:190 - Running task 0.0 in stage 41.0 (TID 23)
2025-10-30 23:20:11 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (30.7 KiB) non-empty blocks including 1 (30.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:20:11 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 1 ms
2025-10-30 23:20:11 INFO  CodeGenerator:190 - Code generated in 33.8344 ms
2025-10-30 23:20:11 INFO  CodeGenerator:190 - Code generated in 4.3877 ms
2025-10-30 23:20:11 INFO  Executor:190 - Finished task 0.0 in stage 41.0 (TID 23). 11936 bytes result sent to driver
2025-10-30 23:20:11 INFO  TaskSetManager:190 - Finished task 0.0 in stage 41.0 (TID 23) in 177 ms on localhost (executor driver) (1/1)
2025-10-30 23:20:11 INFO  TaskSchedulerImpl:190 - Removed TaskSet 41.0 whose tasks have all completed, from pool
2025-10-30 23:20:11 INFO  DAGScheduler:190 - ShuffleMapStage 41 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 185 ms
2025-10-30 23:20:11 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:20:11 INFO  DAGScheduler:190 - running: HashSet()
2025-10-30 23:20:11 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:20:11 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:20:11 INFO  ShufflePartitionsUtil:190 - For shuffle(14, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:20:11 INFO  CodeGenerator:190 - Code generated in 6.6096 ms
2025-10-30 23:20:11 INFO  HashAggregateExec:190 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-10-30 23:20:12 INFO  CodeGenerator:190 - Code generated in 20.1761 ms
2025-10-30 23:20:12 INFO  SparkContext:190 - Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:20:12 INFO  DAGScheduler:190 - Got job 24 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:20:12 INFO  DAGScheduler:190 - Final stage: ResultStage 45 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:20:12 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 44)
2025-10-30 23:20:12 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:20:12 INFO  DAGScheduler:190 - Submitting ResultStage 45 (MapPartitionsRDD[74] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:20:12 INFO  MemoryStore:190 - Block broadcast_31 stored as values in memory (estimated size 83.1 KiB, free 429.6 MiB)
2025-10-30 23:20:12 INFO  MemoryStore:190 - Block broadcast_31_piece0 stored as bytes in memory (estimated size 31.8 KiB, free 429.6 MiB)
2025-10-30 23:20:12 INFO  SparkContext:190 - Created broadcast 31 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:20:12 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[74] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:20:12 INFO  TaskSchedulerImpl:190 - Adding task set 45.0 with 1 tasks resource profile 0
2025-10-30 23:20:12 INFO  TaskSetManager:190 - Starting task 0.0 in stage 45.0 (TID 24) (localhost,executor driver, partition 0, ANY, 9808 bytes)
2025-10-30 23:20:12 INFO  Executor:190 - Running task 0.0 in stage 45.0 (TID 24)
2025-10-30 23:20:12 INFO  CodeGenerator:190 - Code generated in 5.1971 ms
2025-10-30 23:20:12 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (1296.0 B) non-empty blocks including 1 (1296.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:20:12 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 0 ms
2025-10-30 23:20:12 INFO  CodeGenerator:190 - Code generated in 13.3414 ms
2025-10-30 23:20:12 INFO  Executor:190 - Finished task 0.0 in stage 45.0 (TID 24). 13020 bytes result sent to driver
2025-10-30 23:20:12 INFO  TaskSetManager:190 - Finished task 0.0 in stage 45.0 (TID 24) in 39 ms on localhost (executor driver) (1/1)
2025-10-30 23:20:12 INFO  TaskSchedulerImpl:190 - Removed TaskSet 45.0 whose tasks have all completed, from pool
2025-10-30 23:20:12 INFO  DAGScheduler:190 - ResultStage 45 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 47 ms
2025-10-30 23:20:12 INFO  DAGScheduler:190 - Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
2025-10-30 23:20:12 INFO  TaskSchedulerImpl:190 - Canceling stage 45
2025-10-30 23:20:12 INFO  TaskSchedulerImpl:190 - Killing all running tasks in stage 45: Stage finished
2025-10-30 23:20:12 INFO  DAGScheduler:190 - Job 24 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 49.5992 ms
2025-10-30 23:20:12 INFO  CodeGenerator:190 - Code generated in 4.3096 ms
2025-10-30 23:20:14 INFO  DAGScheduler:190 - Registering RDD 80 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 16
2025-10-30 23:20:14 INFO  DAGScheduler:190 - Got map stage job 26 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:20:14 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 46 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:20:14 INFO  DAGScheduler:190 - Parents of final stage: List()
2025-10-30 23:20:14 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:20:14 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 46 (MapPartitionsRDD[80] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:20:14 INFO  MemoryStore:190 - Block broadcast_32 stored as values in memory (estimated size 15.3 KiB, free 429.6 MiB)
2025-10-30 23:20:14 INFO  MemoryStore:190 - Block broadcast_32_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 429.5 MiB)
2025-10-30 23:20:14 INFO  SparkContext:190 - Created broadcast 32 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:20:14 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 46 (MapPartitionsRDD[80] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:20:14 INFO  TaskSchedulerImpl:190 - Adding task set 46.0 with 1 tasks resource profile 0
2025-10-30 23:20:14 INFO  DAGScheduler:190 - Registering RDD 79 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 15
2025-10-30 23:20:14 INFO  DAGScheduler:190 - Got map stage job 25 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:20:14 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 47 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:20:14 INFO  DAGScheduler:190 - Parents of final stage: List()
2025-10-30 23:20:14 INFO  TaskSetManager:190 - Starting task 0.0 in stage 46.0 (TID 25) (localhost,executor driver, partition 0, PROCESS_LOCAL, 9643 bytes)
2025-10-30 23:20:14 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:20:15 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 47 (MapPartitionsRDD[79] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:20:15 INFO  Executor:190 - Running task 0.0 in stage 46.0 (TID 25)
2025-10-30 23:20:15 INFO  MemoryStore:190 - Block broadcast_33 stored as values in memory (estimated size 15.8 KiB, free 429.5 MiB)
2025-10-30 23:20:15 INFO  MemoryStore:190 - Block broadcast_33_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 429.5 MiB)
2025-10-30 23:20:15 INFO  SparkContext:190 - Created broadcast 33 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:20:15 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 47 (MapPartitionsRDD[79] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:20:15 INFO  TaskSchedulerImpl:190 - Adding task set 47.0 with 1 tasks resource profile 0
2025-10-30 23:20:15 INFO  TaskSetManager:190 - Starting task 0.0 in stage 47.0 (TID 26) (localhost,executor driver, partition 0, PROCESS_LOCAL, 9643 bytes)
2025-10-30 23:20:15 INFO  Executor:190 - Running task 0.0 in stage 47.0 (TID 26)
2025-10-30 23:20:15 INFO  JDBCRDD:184 - closed connection
2025-10-30 23:20:15 INFO  JDBCRDD:184 - closed connection
2025-10-30 23:20:15 INFO  Executor:190 - Finished task 0.0 in stage 46.0 (TID 25). 2021 bytes result sent to driver
2025-10-30 23:20:15 INFO  TaskSetManager:190 - Finished task 0.0 in stage 46.0 (TID 25) in 253 ms on localhost (executor driver) (1/1)
2025-10-30 23:20:15 INFO  TaskSchedulerImpl:190 - Removed TaskSet 46.0 whose tasks have all completed, from pool
2025-10-30 23:20:15 INFO  Executor:190 - Finished task 0.0 in stage 47.0 (TID 26). 2021 bytes result sent to driver
2025-10-30 23:20:15 INFO  DAGScheduler:190 - ShuffleMapStage 46 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 257 ms
2025-10-30 23:20:15 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:20:15 INFO  DAGScheduler:190 - running: HashSet(ShuffleMapStage 47)
2025-10-30 23:20:15 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:20:15 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:20:15 INFO  TaskSetManager:190 - Finished task 0.0 in stage 47.0 (TID 26) in 248 ms on localhost (executor driver) (1/1)
2025-10-30 23:20:15 INFO  TaskSchedulerImpl:190 - Removed TaskSet 47.0 whose tasks have all completed, from pool
2025-10-30 23:20:15 INFO  DAGScheduler:190 - ShuffleMapStage 47 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 254 ms
2025-10-30 23:20:15 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:20:15 INFO  DAGScheduler:190 - running: HashSet()
2025-10-30 23:20:15 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:20:15 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:20:15 INFO  ShufflePartitionsUtil:190 - For shuffle(15, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:20:15 INFO  SparkContext:190 - Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:20:15 INFO  DAGScheduler:190 - Got job 27 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:20:15 INFO  DAGScheduler:190 - Final stage: ResultStage 49 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:20:15 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 48)
2025-10-30 23:20:15 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:20:15 INFO  DAGScheduler:190 - Submitting ResultStage 49 (MapPartitionsRDD[82] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:20:15 INFO  MemoryStore:190 - Block broadcast_34 stored as values in memory (estimated size 8.6 KiB, free 429.5 MiB)
2025-10-30 23:20:15 INFO  MemoryStore:190 - Block broadcast_34_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 429.5 MiB)
2025-10-30 23:20:15 INFO  SparkContext:190 - Created broadcast 34 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:20:15 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[82] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:20:15 INFO  TaskSchedulerImpl:190 - Adding task set 49.0 with 1 tasks resource profile 0
2025-10-30 23:20:15 INFO  TaskSetManager:190 - Starting task 0.0 in stage 49.0 (TID 27) (localhost,executor driver, partition 0, ANY, 9827 bytes)
2025-10-30 23:20:15 INFO  Executor:190 - Running task 0.0 in stage 49.0 (TID 27)
2025-10-30 23:20:15 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (43.1 KiB) non-empty blocks including 1 (43.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:20:15 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 0 ms
2025-10-30 23:20:15 INFO  Executor:190 - Finished task 0.0 in stage 49.0 (TID 27). 32926 bytes result sent to driver
2025-10-30 23:20:15 INFO  TaskSetManager:190 - Finished task 0.0 in stage 49.0 (TID 27) in 10 ms on localhost (executor driver) (1/1)
2025-10-30 23:20:15 INFO  TaskSchedulerImpl:190 - Removed TaskSet 49.0 whose tasks have all completed, from pool
2025-10-30 23:20:15 INFO  DAGScheduler:190 - ResultStage 49 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 13 ms
2025-10-30 23:20:15 INFO  DAGScheduler:190 - Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
2025-10-30 23:20:15 INFO  TaskSchedulerImpl:190 - Canceling stage 49
2025-10-30 23:20:15 INFO  TaskSchedulerImpl:190 - Killing all running tasks in stage 49: Stage finished
2025-10-30 23:20:15 INFO  DAGScheduler:190 - Job 27 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 15.0282 ms
2025-10-30 23:20:15 INFO  MemoryStore:190 - Block broadcast_35 stored as values in memory (estimated size 1031.8 KiB, free 428.5 MiB)
2025-10-30 23:20:15 INFO  MemoryStore:190 - Block broadcast_35_piece0 stored as bytes in memory (estimated size 50.6 KiB, free 428.5 MiB)
2025-10-30 23:20:15 INFO  SparkContext:190 - Created broadcast 35 from $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:20:15 INFO  ShufflePartitionsUtil:190 - For shuffle(16, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:20:15 INFO  CodeGenerator:190 - Code generated in 5.4632 ms
2025-10-30 23:20:15 INFO  CodeGenerator:190 - Code generated in 7.1947 ms
2025-10-30 23:20:15 INFO  SparkContext:190 - Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:20:15 INFO  DAGScheduler:190 - Got job 28 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:20:15 INFO  DAGScheduler:190 - Final stage: ResultStage 51 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:20:15 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 50)
2025-10-30 23:20:15 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:20:15 INFO  DAGScheduler:190 - Submitting ResultStage 51 (MapPartitionsRDD[86] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:20:15 INFO  MemoryStore:190 - Block broadcast_36 stored as values in memory (estimated size 16.9 KiB, free 428.4 MiB)
2025-10-30 23:20:15 INFO  MemoryStore:190 - Block broadcast_36_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 428.4 MiB)
2025-10-30 23:20:15 INFO  SparkContext:190 - Created broadcast 36 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:20:15 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[86] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:20:15 INFO  TaskSchedulerImpl:190 - Adding task set 51.0 with 1 tasks resource profile 0
2025-10-30 23:20:15 INFO  TaskSetManager:190 - Starting task 0.0 in stage 51.0 (TID 28) (localhost,executor driver, partition 0, ANY, 9827 bytes)
2025-10-30 23:20:15 INFO  Executor:190 - Running task 0.0 in stage 51.0 (TID 28)
2025-10-30 23:20:15 INFO  CodeGenerator:190 - Code generated in 4.8727 ms
2025-10-30 23:20:15 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (41.3 KiB) non-empty blocks including 1 (41.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:20:15 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 0 ms
2025-10-30 23:20:15 INFO  CodeGenerator:190 - Code generated in 5.3803 ms
2025-10-30 23:20:15 INFO  Executor:190 - Finished task 0.0 in stage 51.0 (TID 28). 4961 bytes result sent to driver
2025-10-30 23:20:15 INFO  TaskSetManager:190 - Finished task 0.0 in stage 51.0 (TID 28) in 27 ms on localhost (executor driver) (1/1)
2025-10-30 23:20:15 INFO  TaskSchedulerImpl:190 - Removed TaskSet 51.0 whose tasks have all completed, from pool
2025-10-30 23:20:15 INFO  DAGScheduler:190 - ResultStage 51 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 33 ms
2025-10-30 23:20:15 INFO  DAGScheduler:190 - Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
2025-10-30 23:20:15 INFO  TaskSchedulerImpl:190 - Canceling stage 51
2025-10-30 23:20:15 INFO  TaskSchedulerImpl:190 - Killing all running tasks in stage 51: Stage finished
2025-10-30 23:20:15 INFO  DAGScheduler:190 - Job 28 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 34.3453 ms
2025-10-30 23:20:15 INFO  CodeGenerator:190 - Code generated in 4.2122 ms
2025-10-30 23:20:15 INFO  CodeGenerator:190 - Code generated in 5.4149 ms
2025-10-30 23:20:20 INFO  SparkContext:184 - Invoking stop() from shutdown hook
2025-10-30 23:20:20 INFO  SparkContext:190 - SparkContext is stopping with exitCode 0 from run at Executors.java:572.
2025-10-30 23:20:20 INFO  Server:479 - Stopped Server@104c717b{STOPPING}[11.0.24,sto=30000]
2025-10-30 23:20:20 INFO  Server:135 - Shutdown Server@104c717b{STOPPING}[11.0.24,sto=30000]
2025-10-30 23:20:20 INFO  AbstractConnector:431 - Stopped Spark@27ee1595{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-10-30 23:20:20 INFO  SparkUI:190 - Stopped Spark web UI at http://127.0.0.1:4040
2025-10-30 23:20:20 INFO  MapOutputTrackerMasterEndpoint:184 - MapOutputTrackerMasterEndpoint stopped!
2025-10-30 23:20:20 INFO  MemoryStore:184 - MemoryStore cleared
2025-10-30 23:20:20 INFO  BlockManager:184 - BlockManager stopped
2025-10-30 23:20:20 INFO  BlockManagerMaster:184 - BlockManagerMaster stopped
2025-10-30 23:20:20 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:184 - OutputCommitCoordinator stopped!
2025-10-30 23:20:20 WARN  SparkEnv:258 - Exception while deleting Spark temp dir: C:\Users\user\AppData\Local\Temp\spark-6913bf8b-717a-4f93-90da-1d29315aeb01\userFiles-9c14de0f-a253-423e-8736-f6cb31f39f52
java.io.IOException: Failed to delete: C:\Users\user\AppData\Local\Temp\spark-6913bf8b-717a-4f93-90da-1d29315aeb01\userFiles-9c14de0f-a253-423e-8736-f6cb31f39f52\postgresql-42.7.3.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:155) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:131) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2395) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2297) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at scala.util.Try$.apply(Try.scala:217) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:1570) [?:?]
2025-10-30 23:20:20 INFO  SparkContext:184 - Successfully stopped SparkContext
2025-10-30 23:20:20 INFO  ShutdownHookManager:184 - Shutdown hook called
2025-10-30 23:20:20 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-6913bf8b-717a-4f93-90da-1d29315aeb01\userFiles-9c14de0f-a253-423e-8736-f6cb31f39f52
2025-10-30 23:20:20 ERROR ShutdownHookManager:278 - Exception while deleting Spark temp dir: C:\Users\user\AppData\Local\Temp\spark-6913bf8b-717a-4f93-90da-1d29315aeb01\userFiles-9c14de0f-a253-423e-8736-f6cb31f39f52
java.io.IOException: Failed to delete: C:\Users\user\AppData\Local\Temp\spark-6913bf8b-717a-4f93-90da-1d29315aeb01\userFiles-9c14de0f-a253-423e-8736-f6cb31f39f52\postgresql-42.7.3.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:155) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:70) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:67) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:67) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at scala.util.Try$.apply(Try.scala:217) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:1570) [?:?]
2025-10-30 23:20:20 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-94a2c6e4-227f-41bf-8eba-927c0fa9c40d
2025-10-30 23:20:20 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-6913bf8b-717a-4f93-90da-1d29315aeb01\pyspark-fb9d7a3a-be27-408e-bccf-4fef0ff6c698
2025-10-30 23:20:20 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-6913bf8b-717a-4f93-90da-1d29315aeb01
2025-10-30 23:20:20 ERROR ShutdownHookManager:278 - Exception while deleting Spark temp dir: C:\Users\user\AppData\Local\Temp\spark-6913bf8b-717a-4f93-90da-1d29315aeb01
java.io.IOException: Failed to delete: C:\Users\user\AppData\Local\Temp\spark-6913bf8b-717a-4f93-90da-1d29315aeb01\userFiles-9c14de0f-a253-423e-8736-f6cb31f39f52\postgresql-42.7.3.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:155) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:70) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:67) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:67) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at scala.util.Try$.apply(Try.scala:217) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:1570) [?:?]
2025-10-30 23:20:20 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\artifacts-df4d98be-e776-4b49-9ac6-50aeca567725
2025-10-30 23:22:07 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-10-30 23:22:07 INFO  SparkContext:190 - Running Spark version 4.0.1
2025-10-30 23:22:07 INFO  SparkContext:190 - OS info Windows 11, 10.0, amd64
2025-10-30 23:22:07 INFO  SparkContext:190 - Java version 22.0.2
2025-10-30 23:22:07 INFO  ResourceUtils:184 - ==============================================================
2025-10-30 23:22:07 INFO  ResourceUtils:184 - No custom resources configured for spark.driver.
2025-10-30 23:22:07 INFO  ResourceUtils:184 - ==============================================================
2025-10-30 23:22:07 INFO  SparkContext:190 - Submitted application: LocalConnection
2025-10-30 23:22:07 INFO  ResourceProfile:190 - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-10-30 23:22:07 INFO  ResourceProfile:190 - Limiting resource is cpu
2025-10-30 23:22:07 INFO  ResourceProfileManager:190 - Added ResourceProfile id: 0
2025-10-30 23:22:07 INFO  SecurityManager:190 - Changing view acls to: user
2025-10-30 23:22:07 INFO  SecurityManager:190 - Changing modify acls to: user
2025-10-30 23:22:07 INFO  SecurityManager:190 - Changing view acls groups to: user
2025-10-30 23:22:07 INFO  SecurityManager:190 - Changing modify acls groups to: user
2025-10-30 23:22:07 INFO  SecurityManager:190 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: user groups with view permissions: EMPTY; users with modify permissions: user; groups with modify permissions: EMPTY; RPC SSL disabled
2025-10-30 23:22:07 INFO  Utils:190 - Successfully started service 'sparkDriver' on port 64707.
2025-10-30 23:22:07 INFO  SparkEnv:190 - Registering MapOutputTracker
2025-10-30 23:22:07 INFO  SparkEnv:190 - Registering BlockManagerMaster
2025-10-30 23:22:07 INFO  BlockManagerMasterEndpoint:190 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-10-30 23:22:07 INFO  BlockManagerMasterEndpoint:184 - BlockManagerMasterEndpoint up
2025-10-30 23:22:07 INFO  SparkEnv:190 - Registering BlockManagerMasterHeartbeat
2025-10-30 23:22:07 INFO  DiskBlockManager:190 - Created local directory at C:\Users\user\AppData\Local\Temp\blockmgr-82033229-7c55-4a9f-ab17-4adf32eff20c
2025-10-30 23:22:07 INFO  SparkEnv:190 - Registering OutputCommitCoordinator
2025-10-30 23:22:07 INFO  JettyUtils:190 - Start Jetty 0.0.0.0:4040 for SparkUI
2025-10-30 23:22:07 INFO  Server:384 - jetty-11.0.24; built: 2024-08-26T18:11:22.448Z; git: 5dfc59a691b748796f922208956bd1f2794bcd16; jvm 22.0.2+9-70
2025-10-30 23:22:08 INFO  Server:439 - Started Server@104c717b{STARTING}[11.0.24,sto=30000] @2334ms
2025-10-30 23:22:08 INFO  AbstractConnector:376 - Started ServerConnector@72112998{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-10-30 23:22:08 INFO  Utils:190 - Successfully started service 'SparkUI' on port 4040.
2025-10-30 23:22:08 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@6b9baa9a{/,null,AVAILABLE,@Spark}
2025-10-30 23:22:08 INFO  SparkContext:190 - Added JAR C:\Users\user\AppData\Roaming\JetBrains\DataGrip2025.2\jdbc-drivers\PostgreSQL\42.7.3\org\postgresql\postgresql\42.7.3\postgresql-42.7.3.jar at spark://127.0.0.1:64707/jars/postgresql-42.7.3.jar with timestamp 1761855727341
2025-10-30 23:22:08 INFO  SecurityManager:190 - Changing view acls to: user
2025-10-30 23:22:08 INFO  SecurityManager:190 - Changing modify acls to: user
2025-10-30 23:22:08 INFO  SecurityManager:190 - Changing view acls groups to: user
2025-10-30 23:22:08 INFO  SecurityManager:190 - Changing modify acls groups to: user
2025-10-30 23:22:08 INFO  SecurityManager:190 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: user groups with view permissions: EMPTY; users with modify permissions: user; groups with modify permissions: EMPTY; RPC SSL disabled
2025-10-30 23:22:08 INFO  Executor:190 - Starting executor ID driver on host localhost
2025-10-30 23:22:08 INFO  Executor:190 - OS info Windows 11, 10.0, amd64
2025-10-30 23:22:08 INFO  Executor:190 - Java version 22.0.2
2025-10-30 23:22:08 INFO  Executor:190 - Starting executor with user classpath (userClassPathFirst = false): ''
2025-10-30 23:22:08 INFO  Executor:190 - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@1cf8353 for default.
2025-10-30 23:22:08 INFO  Executor:190 - Fetching spark://127.0.0.1:64707/jars/postgresql-42.7.3.jar with timestamp 1761855727341
2025-10-30 23:22:08 INFO  TransportClientFactory:155 - Successfully created connection to /127.0.0.1:64707 after 24 ms (0 ms spent in bootstraps)
2025-10-30 23:22:08 INFO  Utils:190 - Fetching spark://127.0.0.1:64707/jars/postgresql-42.7.3.jar to C:\Users\user\AppData\Local\Temp\spark-92e8ff0e-800e-4abe-9426-dc298da73ff3\userFiles-24065cfc-f47f-40ca-9654-744718290a45\fetchFileTemp12261642401046525014.tmp
2025-10-30 23:22:08 INFO  Executor:190 - Adding file:/C:/Users/user/AppData/Local/Temp/spark-92e8ff0e-800e-4abe-9426-dc298da73ff3/userFiles-24065cfc-f47f-40ca-9654-744718290a45/postgresql-42.7.3.jar to class loader default
2025-10-30 23:22:08 INFO  Utils:190 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64712.
2025-10-30 23:22:08 INFO  NettyBlockTransferService:155 - Server created on 127.0.0.1:64712
2025-10-30 23:22:08 INFO  BlockManager:190 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-10-30 23:22:08 INFO  BlockManagerMaster:190 - Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64712, None)
2025-10-30 23:22:08 INFO  BlockManagerMasterEndpoint:190 - Registering block manager 127.0.0.1:64712 with 434.4 MiB RAM, BlockManagerId(driver, 127.0.0.1, 64712, None)
2025-10-30 23:22:08 INFO  BlockManagerMaster:190 - Registered BlockManager BlockManagerId(driver, 127.0.0.1, 64712, None)
2025-10-30 23:22:08 INFO  BlockManager:190 - Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 64712, None)
2025-10-30 23:22:08 INFO  ContextHandler:1123 - Stopped o.s.j.s.ServletContextHandler@6b9baa9a{/,null,STOPPED,@Spark}
2025-10-30 23:22:08 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4c75e679{/jobs,null,AVAILABLE,@Spark}
2025-10-30 23:22:08 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@566598e8{/jobs/json,null,AVAILABLE,@Spark}
2025-10-30 23:22:08 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@49f42031{/jobs/job,null,AVAILABLE,@Spark}
2025-10-30 23:22:08 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@697945a1{/jobs/job/json,null,AVAILABLE,@Spark}
2025-10-30 23:22:08 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@217c19aa{/stages,null,AVAILABLE,@Spark}
2025-10-30 23:22:08 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@185fd86c{/stages/json,null,AVAILABLE,@Spark}
2025-10-30 23:22:08 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@1a65145c{/stages/stage,null,AVAILABLE,@Spark}
2025-10-30 23:22:08 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@1fd4ebf{/stages/stage/json,null,AVAILABLE,@Spark}
2025-10-30 23:22:08 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@47d7c74e{/stages/pool,null,AVAILABLE,@Spark}
2025-10-30 23:22:08 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@705b7fef{/stages/pool/json,null,AVAILABLE,@Spark}
2025-10-30 23:22:08 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@6bdd33ec{/stages/taskThreadDump,null,AVAILABLE,@Spark}
2025-10-30 23:22:08 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@19276de1{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
2025-10-30 23:22:08 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@42adef20{/storage,null,AVAILABLE,@Spark}
2025-10-30 23:22:08 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@14d98ed3{/storage/json,null,AVAILABLE,@Spark}
2025-10-30 23:22:08 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@16560f96{/storage/rdd,null,AVAILABLE,@Spark}
2025-10-30 23:22:08 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@65951109{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-10-30 23:22:08 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@1ed6901{/environment,null,AVAILABLE,@Spark}
2025-10-30 23:22:08 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@648c1e88{/environment/json,null,AVAILABLE,@Spark}
2025-10-30 23:22:08 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@264ca065{/executors,null,AVAILABLE,@Spark}
2025-10-30 23:22:08 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@69587b7a{/executors/json,null,AVAILABLE,@Spark}
2025-10-30 23:22:08 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@7d6c1c20{/executors/threadDump,null,AVAILABLE,@Spark}
2025-10-30 23:22:08 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@182e0984{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-10-30 23:22:08 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@3d864bea{/executors/heapHistogram,null,AVAILABLE,@Spark}
2025-10-30 23:22:08 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@5eb831ab{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2025-10-30 23:22:08 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4798ff2e{/static,null,AVAILABLE,@Spark}
2025-10-30 23:22:08 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@2d03a0ea{/,null,AVAILABLE,@Spark}
2025-10-30 23:22:08 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@5e28a579{/api,null,AVAILABLE,@Spark}
2025-10-30 23:22:08 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@35477e5d{/metrics,null,AVAILABLE,@Spark}
2025-10-30 23:22:08 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@623122d3{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-10-30 23:22:08 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@52a36fd1{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-10-30 23:22:08 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@4175fce3{/metrics/json,null,AVAILABLE,@Spark}
2025-10-30 23:22:10 INFO  SharedState:190 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-10-30 23:22:10 INFO  SharedState:190 - Warehouse path is 'file:/C:/Users/user/DataGripProjects/innowise_trainee/TASKS/task_5/spark-warehouse'.
2025-10-30 23:22:10 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@2894796b{/SQL,null,AVAILABLE,@Spark}
2025-10-30 23:22:10 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@3a965ee0{/SQL/json,null,AVAILABLE,@Spark}
2025-10-30 23:22:10 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@2258ab5f{/SQL/execution,null,AVAILABLE,@Spark}
2025-10-30 23:22:10 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@2e744ff0{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-10-30 23:22:10 INFO  ContextHandler:907 - Started o.s.j.s.ServletContextHandler@1527360c{/static/sql,null,AVAILABLE,@Spark}
2025-10-30 23:22:19 WARN  WindowExec:244 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
2025-10-30 23:22:19 WARN  WindowExec:244 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
2025-10-30 23:22:19 WARN  WindowExec:244 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
2025-10-30 23:22:19 INFO  CodeGenerator:190 - Code generated in 194.5158 ms
2025-10-30 23:22:19 INFO  CodeGenerator:190 - Code generated in 194.4369 ms
2025-10-30 23:22:19 INFO  CodeGenerator:190 - Code generated in 194.4907 ms
2025-10-30 23:22:19 INFO  CodeGenerator:190 - Code generated in 194.5153 ms
2025-10-30 23:22:19 INFO  DAGScheduler:190 - Registering RDD 8 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 0
2025-10-30 23:22:19 INFO  DAGScheduler:190 - Got map stage job 2 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:22:19 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 0 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:22:19 INFO  DAGScheduler:190 - Parents of final stage: List()
2025-10-30 23:22:19 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:22:19 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[8] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:22:19 INFO  MemoryStore:190 - MemoryStore started with capacity 434.4 MiB
2025-10-30 23:22:19 INFO  MemoryStore:190 - Block broadcast_0 stored as values in memory (estimated size 16.4 KiB, free 434.4 MiB)
2025-10-30 23:22:19 INFO  MemoryStore:190 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 8.4 KiB, free 434.4 MiB)
2025-10-30 23:22:19 INFO  SparkContext:190 - Created broadcast 0 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:22:19 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[8] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:22:19 INFO  TaskSchedulerImpl:190 - Adding task set 0.0 with 1 tasks resource profile 0
2025-10-30 23:22:19 INFO  DAGScheduler:190 - Registering RDD 10 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 1
2025-10-30 23:22:19 INFO  DAGScheduler:190 - Got map stage job 1 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:22:19 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 1 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:22:19 INFO  DAGScheduler:190 - Parents of final stage: List()
2025-10-30 23:22:19 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:22:19 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 1 (MapPartitionsRDD[10] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:22:19 INFO  MemoryStore:190 - Block broadcast_1 stored as values in memory (estimated size 15.8 KiB, free 434.4 MiB)
2025-10-30 23:22:19 INFO  MemoryStore:190 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 434.4 MiB)
2025-10-30 23:22:19 INFO  SparkContext:190 - Created broadcast 1 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:22:19 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[10] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:22:19 INFO  TaskSchedulerImpl:190 - Adding task set 1.0 with 1 tasks resource profile 0
2025-10-30 23:22:19 INFO  TaskSetManager:190 - Starting task 0.0 in stage 0.0 (TID 0) (localhost,executor driver, partition 0, PROCESS_LOCAL, 9643 bytes)
2025-10-30 23:22:19 INFO  DAGScheduler:190 - Registering RDD 11 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 3
2025-10-30 23:22:19 INFO  DAGScheduler:190 - Got map stage job 0 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:22:19 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 2 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:22:19 INFO  DAGScheduler:190 - Parents of final stage: List()
2025-10-30 23:22:19 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:22:19 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 2 (MapPartitionsRDD[11] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:22:19 INFO  MemoryStore:190 - Block broadcast_2 stored as values in memory (estimated size 15.8 KiB, free 434.3 MiB)
2025-10-30 23:22:19 INFO  TaskSetManager:190 - Starting task 0.0 in stage 1.0 (TID 1) (localhost,executor driver, partition 0, PROCESS_LOCAL, 9643 bytes)
2025-10-30 23:22:19 INFO  MemoryStore:190 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.3 MiB)
2025-10-30 23:22:19 INFO  SparkContext:190 - Created broadcast 2 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:22:19 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[11] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:22:19 INFO  TaskSchedulerImpl:190 - Adding task set 2.0 with 1 tasks resource profile 0
2025-10-30 23:22:19 INFO  Executor:190 - Running task 0.0 in stage 0.0 (TID 0)
2025-10-30 23:22:19 INFO  TaskSetManager:190 - Starting task 0.0 in stage 2.0 (TID 2) (localhost,executor driver, partition 0, PROCESS_LOCAL, 9643 bytes)
2025-10-30 23:22:19 INFO  DAGScheduler:190 - Registering RDD 9 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 2
2025-10-30 23:22:19 INFO  Executor:190 - Running task 0.0 in stage 1.0 (TID 1)
2025-10-30 23:22:19 INFO  DAGScheduler:190 - Got map stage job 3 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:22:19 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 3 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:22:19 INFO  DAGScheduler:190 - Parents of final stage: List()
2025-10-30 23:22:19 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:22:19 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 3 (MapPartitionsRDD[9] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:22:19 INFO  MemoryStore:190 - Block broadcast_3 stored as values in memory (estimated size 15.8 KiB, free 434.3 MiB)
2025-10-30 23:22:19 INFO  Executor:190 - Running task 0.0 in stage 2.0 (TID 2)
2025-10-30 23:22:19 INFO  MemoryStore:190 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.3 MiB)
2025-10-30 23:22:19 INFO  SparkContext:190 - Created broadcast 3 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:22:19 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[9] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:22:19 INFO  TaskSchedulerImpl:190 - Adding task set 3.0 with 1 tasks resource profile 0
2025-10-30 23:22:19 INFO  TaskSetManager:190 - Starting task 0.0 in stage 3.0 (TID 3) (localhost,executor driver, partition 0, PROCESS_LOCAL, 9643 bytes)
2025-10-30 23:22:20 INFO  Executor:190 - Running task 0.0 in stage 3.0 (TID 3)
2025-10-30 23:22:20 INFO  CodeGenerator:190 - Code generated in 17.6319 ms
2025-10-30 23:22:20 INFO  CodeGenerator:190 - Code generated in 18.4579 ms
2025-10-30 23:22:20 INFO  CodeGenerator:190 - Code generated in 17.6418 ms
2025-10-30 23:22:20 INFO  CodeGenerator:190 - Code generated in 30.4869 ms
2025-10-30 23:22:20 INFO  CodeGenerator:190 - Code generated in 49.3439 ms
2025-10-30 23:22:20 INFO  SecurityManager:190 - Changing view acls to: user
2025-10-30 23:22:20 INFO  SecurityManager:190 - Changing modify acls to: user
2025-10-30 23:22:20 INFO  SecurityManager:190 - Changing view acls groups to: user
2025-10-30 23:22:20 INFO  SecurityManager:190 - Changing modify acls groups to: user
2025-10-30 23:22:20 INFO  SecurityManager:190 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: user groups with view permissions: EMPTY; users with modify permissions: user; groups with modify permissions: EMPTY; RPC SSL disabled
2025-10-30 23:22:20 INFO  JDBCRDD:184 - closed connection
2025-10-30 23:22:20 INFO  JDBCRDD:184 - closed connection
2025-10-30 23:22:20 INFO  JDBCRDD:184 - closed connection
2025-10-30 23:22:20 INFO  JDBCRDD:184 - closed connection
2025-10-30 23:22:20 INFO  Executor:190 - Finished task 0.0 in stage 1.0 (TID 1). 2107 bytes result sent to driver
2025-10-30 23:22:20 INFO  TaskSetManager:190 - Finished task 0.0 in stage 1.0 (TID 1) in 925 ms on localhost (executor driver) (1/1)
2025-10-30 23:22:20 INFO  TaskSchedulerImpl:190 - Removed TaskSet 1.0 whose tasks have all completed, from pool
2025-10-30 23:22:20 INFO  DAGScheduler:190 - ShuffleMapStage 1 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 998 ms
2025-10-30 23:22:20 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:22:20 INFO  DAGScheduler:190 - running: HashSet(ShuffleMapStage 0, ShuffleMapStage 2, ShuffleMapStage 3)
2025-10-30 23:22:20 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:22:20 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:22:20 INFO  Executor:190 - Finished task 0.0 in stage 0.0 (TID 0). 2150 bytes result sent to driver
2025-10-30 23:22:21 INFO  TaskSetManager:190 - Finished task 0.0 in stage 0.0 (TID 0) in 1126 ms on localhost (executor driver) (1/1)
2025-10-30 23:22:21 INFO  TaskSchedulerImpl:190 - Removed TaskSet 0.0 whose tasks have all completed, from pool
2025-10-30 23:22:21 INFO  DAGScheduler:190 - ShuffleMapStage 0 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 1339 ms
2025-10-30 23:22:21 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:22:21 INFO  DAGScheduler:190 - running: HashSet(ShuffleMapStage 2, ShuffleMapStage 3)
2025-10-30 23:22:21 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:22:21 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:22:21 WARN  WindowExec:244 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
2025-10-30 23:22:21 WARN  WindowExec:244 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
2025-10-30 23:22:21 INFO  Executor:190 - Finished task 0.0 in stage 2.0 (TID 2). 2107 bytes result sent to driver
2025-10-30 23:22:21 INFO  TaskSetManager:190 - Finished task 0.0 in stage 2.0 (TID 2) in 1164 ms on localhost (executor driver) (1/1)
2025-10-30 23:22:21 INFO  TaskSchedulerImpl:190 - Removed TaskSet 2.0 whose tasks have all completed, from pool
2025-10-30 23:22:21 INFO  DAGScheduler:190 - ShuffleMapStage 2 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 1185 ms
2025-10-30 23:22:21 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:22:21 INFO  DAGScheduler:190 - running: HashSet(ShuffleMapStage 3)
2025-10-30 23:22:21 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:22:21 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:22:21 WARN  WindowExec:244 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
2025-10-30 23:22:21 WARN  WindowExec:244 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
2025-10-30 23:22:21 INFO  Executor:190 - Finished task 0.0 in stage 3.0 (TID 3). 2107 bytes result sent to driver
2025-10-30 23:22:21 INFO  TaskSetManager:190 - Finished task 0.0 in stage 3.0 (TID 3) in 1175 ms on localhost (executor driver) (1/1)
2025-10-30 23:22:21 INFO  TaskSchedulerImpl:190 - Removed TaskSet 3.0 whose tasks have all completed, from pool
2025-10-30 23:22:21 INFO  DAGScheduler:190 - ShuffleMapStage 3 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 1190 ms
2025-10-30 23:22:21 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:22:21 INFO  DAGScheduler:190 - running: HashSet()
2025-10-30 23:22:21 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:22:21 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:22:21 INFO  ShufflePartitionsUtil:190 - For shuffle(0, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:22:21 WARN  WindowExec:244 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
2025-10-30 23:22:21 WARN  WindowExec:244 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
2025-10-30 23:22:21 INFO  ShufflePartitionsUtil:190 - For shuffle(2, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:22:21 INFO  SparkContext:190 - Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:22:21 INFO  DAGScheduler:190 - Got job 4 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:22:21 INFO  DAGScheduler:190 - Final stage: ResultStage 5 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:22:21 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 4)
2025-10-30 23:22:21 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:22:21 INFO  DAGScheduler:190 - Submitting ResultStage 5 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:22:21 INFO  MemoryStore:190 - Block broadcast_4 stored as values in memory (estimated size 8.6 KiB, free 434.3 MiB)
2025-10-30 23:22:21 INFO  MemoryStore:190 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 434.3 MiB)
2025-10-30 23:22:21 INFO  SparkContext:190 - Created broadcast 4 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:22:21 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[13] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:22:21 INFO  TaskSchedulerImpl:190 - Adding task set 5.0 with 1 tasks resource profile 0
2025-10-30 23:22:21 INFO  TaskSetManager:190 - Starting task 0.0 in stage 5.0 (TID 4) (localhost,executor driver, partition 0, ANY, 9827 bytes)
2025-10-30 23:22:21 INFO  Executor:190 - Running task 0.0 in stage 5.0 (TID 4)
2025-10-30 23:22:21 INFO  SparkContext:190 - Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:22:21 INFO  DAGScheduler:190 - Got job 5 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:22:21 INFO  DAGScheduler:190 - Final stage: ResultStage 7 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:22:21 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 6)
2025-10-30 23:22:21 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:22:21 INFO  DAGScheduler:190 - Submitting ResultStage 7 (MapPartitionsRDD[15] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:22:21 INFO  MemoryStore:190 - Block broadcast_5 stored as values in memory (estimated size 8.6 KiB, free 434.3 MiB)
2025-10-30 23:22:21 INFO  MemoryStore:190 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.3 KiB, free 434.3 MiB)
2025-10-30 23:22:21 INFO  SparkContext:190 - Created broadcast 5 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:22:21 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[15] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:22:21 INFO  TaskSchedulerImpl:190 - Adding task set 7.0 with 1 tasks resource profile 0
2025-10-30 23:22:21 INFO  TaskSetManager:190 - Starting task 0.0 in stage 7.0 (TID 5) (localhost,executor driver, partition 0, ANY, 9827 bytes)
2025-10-30 23:22:21 INFO  Executor:190 - Running task 0.0 in stage 7.0 (TID 5)
2025-10-30 23:22:21 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (23.9 KiB) non-empty blocks including 1 (23.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:22:21 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (13.8 KiB) non-empty blocks including 1 (13.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:22:21 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 30 ms
2025-10-30 23:22:21 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 30 ms
2025-10-30 23:22:21 INFO  Executor:190 - Finished task 0.0 in stage 7.0 (TID 5). 12409 bytes result sent to driver
2025-10-30 23:22:21 INFO  Executor:190 - Finished task 0.0 in stage 5.0 (TID 4). 8757 bytes result sent to driver
2025-10-30 23:22:21 INFO  TaskSetManager:190 - Finished task 0.0 in stage 7.0 (TID 5) in 104 ms on localhost (executor driver) (1/1)
2025-10-30 23:22:21 INFO  TaskSchedulerImpl:190 - Removed TaskSet 7.0 whose tasks have all completed, from pool
2025-10-30 23:22:21 INFO  TaskSetManager:190 - Finished task 0.0 in stage 5.0 (TID 4) in 122 ms on localhost (executor driver) (1/1)
2025-10-30 23:22:21 INFO  TaskSchedulerImpl:190 - Removed TaskSet 5.0 whose tasks have all completed, from pool
2025-10-30 23:22:21 INFO  DAGScheduler:190 - ResultStage 7 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 114 ms
2025-10-30 23:22:21 INFO  DAGScheduler:190 - Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2025-10-30 23:22:21 INFO  TaskSchedulerImpl:190 - Canceling stage 7
2025-10-30 23:22:21 INFO  TaskSchedulerImpl:190 - Killing all running tasks in stage 7: Stage finished
2025-10-30 23:22:21 INFO  DAGScheduler:190 - ResultStage 5 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 146 ms
2025-10-30 23:22:21 INFO  DAGScheduler:190 - Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2025-10-30 23:22:21 INFO  TaskSchedulerImpl:190 - Canceling stage 5
2025-10-30 23:22:21 INFO  TaskSchedulerImpl:190 - Killing all running tasks in stage 5: Stage finished
2025-10-30 23:22:21 INFO  DAGScheduler:190 - Job 4 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 163.4157 ms
2025-10-30 23:22:21 INFO  DAGScheduler:190 - Job 5 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 132.538 ms
2025-10-30 23:22:21 INFO  CodeGenerator:190 - Code generated in 12.5052 ms
2025-10-30 23:22:21 INFO  MemoryStore:190 - Block broadcast_6 stored as values in memory (estimated size 1025.6 KiB, free 433.3 MiB)
2025-10-30 23:22:21 INFO  MemoryStore:190 - Block broadcast_7 stored as values in memory (estimated size 1031.8 KiB, free 432.3 MiB)
2025-10-30 23:22:21 INFO  MemoryStore:190 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 13.0 KiB, free 432.3 MiB)
2025-10-30 23:22:21 INFO  MemoryStore:190 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 432.3 MiB)
2025-10-30 23:22:21 INFO  SparkContext:190 - Created broadcast 6 from $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:22:21 INFO  SparkContext:190 - Created broadcast 7 from $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:22:21 WARN  WindowExec:244 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
2025-10-30 23:22:21 WARN  WindowExec:244 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
2025-10-30 23:22:21 WARN  WindowExec:244 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
2025-10-30 23:22:21 WARN  WindowExec:244 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
2025-10-30 23:22:21 INFO  ShufflePartitionsUtil:190 - For shuffle(3, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:22:21 INFO  CodeGenerator:190 - Code generated in 22.6079 ms
2025-10-30 23:22:21 INFO  DAGScheduler:190 - Registering RDD 18 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 4
2025-10-30 23:22:21 INFO  DAGScheduler:190 - Got map stage job 6 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:22:21 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 9 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:22:21 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 8)
2025-10-30 23:22:21 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:22:21 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 9 (MapPartitionsRDD[18] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:22:21 INFO  MemoryStore:190 - Block broadcast_8 stored as values in memory (estimated size 17.1 KiB, free 432.3 MiB)
2025-10-30 23:22:21 INFO  MemoryStore:190 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 432.3 MiB)
2025-10-30 23:22:21 INFO  SparkContext:190 - Created broadcast 8 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:22:21 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[18] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:22:21 INFO  TaskSchedulerImpl:190 - Adding task set 9.0 with 1 tasks resource profile 0
2025-10-30 23:22:21 INFO  TaskSetManager:190 - Starting task 0.0 in stage 9.0 (TID 6) (localhost,executor driver, partition 0, ANY, 9816 bytes)
2025-10-30 23:22:21 INFO  Executor:190 - Running task 0.0 in stage 9.0 (TID 6)
2025-10-30 23:22:21 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (45.8 KiB) non-empty blocks including 1 (45.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:22:21 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 2 ms
2025-10-30 23:22:21 INFO  CodeGenerator:190 - Code generated in 22.4069 ms
2025-10-30 23:22:21 INFO  CodeGenerator:190 - Code generated in 25.0744 ms
2025-10-30 23:22:21 INFO  Executor:190 - Finished task 0.0 in stage 9.0 (TID 6). 4177 bytes result sent to driver
2025-10-30 23:22:21 INFO  TaskSetManager:190 - Finished task 0.0 in stage 9.0 (TID 6) in 169 ms on localhost (executor driver) (1/1)
2025-10-30 23:22:21 INFO  TaskSchedulerImpl:190 - Removed TaskSet 9.0 whose tasks have all completed, from pool
2025-10-30 23:22:21 INFO  DAGScheduler:190 - ShuffleMapStage 9 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 185 ms
2025-10-30 23:22:21 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:22:21 INFO  DAGScheduler:190 - running: HashSet()
2025-10-30 23:22:21 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:22:21 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:22:21 WARN  WindowExec:244 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
2025-10-30 23:22:21 WARN  WindowExec:244 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
2025-10-30 23:22:21 INFO  ShufflePartitionsUtil:190 - For shuffle(4, 1, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:22:22 INFO  CodeGenerator:190 - Code generated in 101.898 ms
2025-10-30 23:22:22 INFO  CodeGenerator:190 - Code generated in 14.8263 ms
2025-10-30 23:22:22 INFO  CodeGenerator:190 - Code generated in 12.4524 ms
2025-10-30 23:22:22 INFO  DAGScheduler:190 - Registering RDD 25 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 5
2025-10-30 23:22:22 INFO  DAGScheduler:190 - Got map stage job 7 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:22:22 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 13 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:22:22 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 11, ShuffleMapStage 12)
2025-10-30 23:22:22 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:22:22 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 13 (MapPartitionsRDD[25] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:22:22 INFO  MemoryStore:190 - Block broadcast_9 stored as values in memory (estimated size 80.6 KiB, free 432.2 MiB)
2025-10-30 23:22:22 INFO  MemoryStore:190 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 32.8 KiB, free 432.1 MiB)
2025-10-30 23:22:22 INFO  SparkContext:190 - Created broadcast 9 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:22:22 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[25] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:22:22 INFO  TaskSchedulerImpl:190 - Adding task set 13.0 with 1 tasks resource profile 0
2025-10-30 23:22:22 INFO  TaskSetManager:190 - Starting task 0.0 in stage 13.0 (TID 7) (localhost,executor driver, partition 0, ANY, 10295 bytes)
2025-10-30 23:22:22 INFO  Executor:190 - Running task 0.0 in stage 13.0 (TID 7)
2025-10-30 23:22:22 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (67.3 KiB) non-empty blocks including 1 (67.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:22:22 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 1 ms
2025-10-30 23:22:22 INFO  CodeGenerator:190 - Code generated in 14.7894 ms
2025-10-30 23:22:22 INFO  CodeGenerator:190 - Code generated in 53.4017 ms
2025-10-30 23:22:22 INFO  CodeGenerator:190 - Code generated in 6.4657 ms
2025-10-30 23:22:22 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:22:22 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 0 ms
2025-10-30 23:22:22 INFO  CodeGenerator:190 - Code generated in 8.8365 ms
2025-10-30 23:22:22 INFO  CodeGenerator:190 - Code generated in 6.6809 ms
2025-10-30 23:22:22 INFO  CodeGenerator:190 - Code generated in 6.4041 ms
2025-10-30 23:22:22 INFO  CodeGenerator:190 - Code generated in 53.8172 ms
2025-10-30 23:22:22 INFO  CodeGenerator:190 - Code generated in 13.3502 ms
2025-10-30 23:22:22 INFO  CodeGenerator:190 - Code generated in 7.312 ms
2025-10-30 23:22:22 INFO  CodeGenerator:190 - Code generated in 8.2653 ms
2025-10-30 23:22:22 INFO  CodeGenerator:190 - Code generated in 8.0979 ms
2025-10-30 23:22:22 INFO  Executor:190 - Finished task 0.0 in stage 13.0 (TID 7). 10696 bytes result sent to driver
2025-10-30 23:22:22 INFO  TaskSetManager:190 - Finished task 0.0 in stage 13.0 (TID 7) in 572 ms on localhost (executor driver) (1/1)
2025-10-30 23:22:22 INFO  TaskSchedulerImpl:190 - Removed TaskSet 13.0 whose tasks have all completed, from pool
2025-10-30 23:22:22 INFO  DAGScheduler:190 - ShuffleMapStage 13 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 587 ms
2025-10-30 23:22:22 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:22:22 INFO  DAGScheduler:190 - running: HashSet()
2025-10-30 23:22:22 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:22:22 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:22:22 WARN  WindowExec:244 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
2025-10-30 23:22:22 WARN  WindowExec:244 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
2025-10-30 23:22:22 INFO  ShufflePartitionsUtil:190 - For shuffle(5, advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-10-30 23:22:22 INFO  HashAggregateExec:190 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-10-30 23:22:22 INFO  CodeGenerator:190 - Code generated in 37.7582 ms
2025-10-30 23:22:22 INFO  DAGScheduler:190 - Registering RDD 29 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) as input to shuffle 6
2025-10-30 23:22:22 INFO  DAGScheduler:190 - Got map stage job 8 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:22:22 INFO  DAGScheduler:190 - Final stage: ShuffleMapStage 18 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:22:22 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 17)
2025-10-30 23:22:22 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:22:22 INFO  DAGScheduler:190 - Submitting ShuffleMapStage 18 (MapPartitionsRDD[29] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:22:22 INFO  MemoryStore:190 - Block broadcast_10 stored as values in memory (estimated size 80.1 KiB, free 432.2 MiB)
2025-10-30 23:22:22 INFO  MemoryStore:190 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 31.9 KiB, free 432.2 MiB)
2025-10-30 23:22:22 INFO  SparkContext:190 - Created broadcast 10 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:22:22 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[29] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:22:22 INFO  TaskSchedulerImpl:190 - Adding task set 18.0 with 1 tasks resource profile 0
2025-10-30 23:22:22 INFO  TaskSetManager:190 - Starting task 0.0 in stage 18.0 (TID 8) (localhost,executor driver, partition 0, ANY, 9797 bytes)
2025-10-30 23:22:22 INFO  Executor:190 - Running task 0.0 in stage 18.0 (TID 8)
2025-10-30 23:22:23 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (10.2 KiB) non-empty blocks including 1 (10.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:22:23 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 1 ms
2025-10-30 23:22:23 INFO  CodeGenerator:190 - Code generated in 22.2249 ms
2025-10-30 23:22:23 INFO  CodeGenerator:190 - Code generated in 5.8772 ms
2025-10-30 23:22:23 INFO  CodeGenerator:190 - Code generated in 6.8735 ms
2025-10-30 23:22:23 INFO  Executor:190 - Finished task 0.0 in stage 18.0 (TID 8). 12035 bytes result sent to driver
2025-10-30 23:22:23 INFO  TaskSetManager:190 - Finished task 0.0 in stage 18.0 (TID 8) in 109 ms on localhost (executor driver) (1/1)
2025-10-30 23:22:23 INFO  TaskSchedulerImpl:190 - Removed TaskSet 18.0 whose tasks have all completed, from pool
2025-10-30 23:22:23 INFO  DAGScheduler:190 - ShuffleMapStage 18 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 159 ms
2025-10-30 23:22:23 INFO  DAGScheduler:184 - looking for newly runnable stages
2025-10-30 23:22:23 INFO  DAGScheduler:190 - running: HashSet()
2025-10-30 23:22:23 INFO  DAGScheduler:190 - waiting: HashSet()
2025-10-30 23:22:23 INFO  DAGScheduler:190 - failed: HashSet()
2025-10-30 23:22:23 WARN  WindowExec:244 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
2025-10-30 23:22:23 WARN  WindowExec:244 - No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
2025-10-30 23:22:23 INFO  CodeGenerator:190 - Code generated in 11.5303 ms
2025-10-30 23:22:23 INFO  CodeGenerator:190 - Code generated in 9.0164 ms
2025-10-30 23:22:23 INFO  SparkContext:190 - Starting job: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768
2025-10-30 23:22:23 INFO  DAGScheduler:190 - Got job 9 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) with 1 output partitions
2025-10-30 23:22:23 INFO  DAGScheduler:190 - Final stage: ResultStage 24 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768)
2025-10-30 23:22:23 INFO  DAGScheduler:190 - Parents of final stage: List(ShuffleMapStage 23)
2025-10-30 23:22:23 INFO  DAGScheduler:190 - Missing parents: List()
2025-10-30 23:22:23 INFO  DAGScheduler:190 - Submitting ResultStage 24 (MapPartitionsRDD[35] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768), which has no missing parents
2025-10-30 23:22:23 INFO  MemoryStore:190 - Block broadcast_11 stored as values in memory (estimated size 85.3 KiB, free 432.1 MiB)
2025-10-30 23:22:23 INFO  MemoryStore:190 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 33.3 KiB, free 432.0 MiB)
2025-10-30 23:22:23 INFO  SparkContext:190 - Created broadcast 11 from broadcast at DAGScheduler.scala:1676
2025-10-30 23:22:23 INFO  DAGScheduler:190 - Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[35] at $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) (first 15 tasks are for partitions Vector(0))
2025-10-30 23:22:23 INFO  TaskSchedulerImpl:190 - Adding task set 24.0 with 1 tasks resource profile 0
2025-10-30 23:22:23 INFO  TaskSetManager:190 - Starting task 0.0 in stage 24.0 (TID 9) (localhost,executor driver, partition 0, ANY, 9808 bytes)
2025-10-30 23:22:23 INFO  Executor:190 - Running task 0.0 in stage 24.0 (TID 9)
2025-10-30 23:22:23 INFO  ShuffleBlockFetcherIterator:190 - Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-10-30 23:22:23 INFO  ShuffleBlockFetcherIterator:190 - Started 0 remote fetches in 2 ms
2025-10-30 23:22:23 INFO  CodeGenerator:190 - Code generated in 11.0862 ms
2025-10-30 23:22:23 INFO  CodeGenerator:190 - Code generated in 8.044 ms
2025-10-30 23:22:23 INFO  CodeGenerator:190 - Code generated in 5.7999 ms
2025-10-30 23:22:23 INFO  CodeGenerator:190 - Code generated in 7.8873 ms
2025-10-30 23:22:23 INFO  CodeGenerator:190 - Code generated in 12.2572 ms
2025-10-30 23:22:23 INFO  CodeGenerator:190 - Code generated in 5.0251 ms
2025-10-30 23:22:23 INFO  CodeGenerator:190 - Code generated in 7.4727 ms
2025-10-30 23:22:23 INFO  Executor:190 - Finished task 0.0 in stage 24.0 (TID 9). 13543 bytes result sent to driver
2025-10-30 23:22:23 INFO  TaskSetManager:190 - Finished task 0.0 in stage 24.0 (TID 9) in 159 ms on localhost (executor driver) (1/1)
2025-10-30 23:22:23 INFO  TaskSchedulerImpl:190 - Removed TaskSet 24.0 whose tasks have all completed, from pool
2025-10-30 23:22:23 INFO  DAGScheduler:190 - ResultStage 24 ($anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768) finished in 173 ms
2025-10-30 23:22:23 INFO  DAGScheduler:190 - Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
2025-10-30 23:22:23 INFO  TaskSchedulerImpl:190 - Canceling stage 24
2025-10-30 23:22:23 INFO  TaskSchedulerImpl:190 - Killing all running tasks in stage 24: Stage finished
2025-10-30 23:22:23 INFO  DAGScheduler:190 - Job 9 finished: $anonfun$withThreadLocalCaptured$2 at CompletableFuture.java:1768, took 178.7579 ms
2025-10-30 23:22:23 INFO  CodeGenerator:190 - Code generated in 10.3996 ms
2025-10-30 23:22:35 INFO  SparkContext:184 - Invoking stop() from shutdown hook
2025-10-30 23:22:35 INFO  SparkContext:190 - SparkContext is stopping with exitCode 0 from run at Executors.java:572.
2025-10-30 23:22:35 INFO  Server:479 - Stopped Server@104c717b{STOPPING}[11.0.24,sto=30000]
2025-10-30 23:22:35 INFO  Server:135 - Shutdown Server@104c717b{STOPPING}[11.0.24,sto=30000]
2025-10-30 23:22:35 INFO  AbstractConnector:431 - Stopped Spark@72112998{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-10-30 23:22:35 INFO  SparkUI:190 - Stopped Spark web UI at http://127.0.0.1:4040
2025-10-30 23:22:35 INFO  MapOutputTrackerMasterEndpoint:184 - MapOutputTrackerMasterEndpoint stopped!
2025-10-30 23:22:35 INFO  MemoryStore:184 - MemoryStore cleared
2025-10-30 23:22:35 INFO  BlockManager:184 - BlockManager stopped
2025-10-30 23:22:35 INFO  BlockManagerMaster:184 - BlockManagerMaster stopped
2025-10-30 23:22:35 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:184 - OutputCommitCoordinator stopped!
2025-10-30 23:22:35 WARN  SparkEnv:258 - Exception while deleting Spark temp dir: C:\Users\user\AppData\Local\Temp\spark-92e8ff0e-800e-4abe-9426-dc298da73ff3\userFiles-24065cfc-f47f-40ca-9654-744718290a45
java.io.IOException: Failed to delete: C:\Users\user\AppData\Local\Temp\spark-92e8ff0e-800e-4abe-9426-dc298da73ff3\userFiles-24065cfc-f47f-40ca-9654-744718290a45\postgresql-42.7.3.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:155) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:131) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2395) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2297) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at scala.util.Try$.apply(Try.scala:217) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:1570) [?:?]
2025-10-30 23:22:35 INFO  SparkContext:184 - Successfully stopped SparkContext
2025-10-30 23:22:35 INFO  ShutdownHookManager:184 - Shutdown hook called
2025-10-30 23:22:35 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\artifacts-ad69b5a8-6c3d-4afb-985c-8557ddd63ffb
2025-10-30 23:22:35 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-92e8ff0e-800e-4abe-9426-dc298da73ff3\userFiles-24065cfc-f47f-40ca-9654-744718290a45
2025-10-30 23:22:35 ERROR ShutdownHookManager:278 - Exception while deleting Spark temp dir: C:\Users\user\AppData\Local\Temp\spark-92e8ff0e-800e-4abe-9426-dc298da73ff3\userFiles-24065cfc-f47f-40ca-9654-744718290a45
java.io.IOException: Failed to delete: C:\Users\user\AppData\Local\Temp\spark-92e8ff0e-800e-4abe-9426-dc298da73ff3\userFiles-24065cfc-f47f-40ca-9654-744718290a45\postgresql-42.7.3.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:155) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:70) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:67) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:67) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at scala.util.Try$.apply(Try.scala:217) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:1570) [?:?]
2025-10-30 23:22:35 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-e3870b65-32a3-404d-89c1-6cd65bca8bd4
2025-10-30 23:22:35 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-92e8ff0e-800e-4abe-9426-dc298da73ff3\pyspark-9af9860a-33c4-4658-ae7d-a2585bd3ca9f
2025-10-30 23:22:35 INFO  ShutdownHookManager:190 - Deleting directory C:\Users\user\AppData\Local\Temp\spark-92e8ff0e-800e-4abe-9426-dc298da73ff3
2025-10-30 23:22:35 ERROR ShutdownHookManager:278 - Exception while deleting Spark temp dir: C:\Users\user\AppData\Local\Temp\spark-92e8ff0e-800e-4abe-9426-dc298da73ff3
java.io.IOException: Failed to delete: C:\Users\user\AppData\Local\Temp\spark-92e8ff0e-800e-4abe-9426-dc298da73ff3\userFiles-24065cfc-f47f-40ca-9654-744718290a45\postgresql-42.7.3.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:155) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120) ~[spark-common-utils_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:70) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:67) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:67) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18) ~[scala-library-2.13.16.jar:?]
	at scala.util.Try$.apply(Try.scala:217) ~[scala-library-2.13.16.jar:?]
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184) ~[spark-core_2.13-4.0.1.jar:4.0.1]
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.base/java.lang.Thread.run(Thread.java:1570) [?:?]
